\documentclass[12pt]{book}
\usepackage{graphicx}
\usepackage[bookmarks=true]{hyperref}
\usepackage{makeidx}
\usepackage{theorem}
%\usepackage{times}                % times font
\usepackage{type1cm}               % traditional font - quite thin for screen reading
\renewcommand{\ttdefault}{cmtt}    % smaller tt-font
\newcommand{\docversion}{4.7.2}
\usepackage{alltt}
\makeindex
\input{genericmac}
\input{mac}
\newcommand{\rhoword}{\rho_{\rm w}}
\title{Programming with Regions in the MLKit\\[5mm]
\large {\sc Revised for version \docversion}}
\author{Mads Tofte \and Lars Birkedal \and Martin Elsman \and
\and Niels Hallenberg \and Tommy H\o jfeld Olesen \and
Peter Sestoft}
\date{September 16, 2022 \\[3cm] \includegraphics[width=.7\textwidth]{mlkit-logo}}
\raggedbottom

{\theorembodyfont{\rmfamily} \newtheorem{example}{Example}}

\begin{document}
\maketitle

\pagestyle{headings}
\begin{center}
\bf Values and their Representation
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
integer&64 bits, untagged. Unboxed (i.e., not region allocated). One bit is used for tagging when GC is enabled. \cr
real   &64 bits, untagged. Boxed (i.e., allocated in region)\cr
string &Unbounded size. Allocated in region.\cr
bool   &one 64-bit word. Unboxed.\cr
$\alpha$ list & {\tt nil} and {\tt ::} cells unboxed (i.e., not region allocated). Auxiliary
                pairs in one region; elements
                in zero or more regions. Size of
                auxiliary pairs: two 64-bit words (three when GC is enabled).\cr
%$\alpha$ tree & A tree and its subtrees reside in one region.
%                Elements in one region (if not unboxed).\cr
{\tt exn}&Exception values are boxed and are always stored in a global region.\cr
{\tt fn $\pat$ =>~$\exp$}&An anonymous function is represented by a
                boxed, untagged closure. Its size is one 64-bit word plus one word for each free
                variable of the function. Free region variables also count as variables.
                One extra word is used when GC is enabled.\cr
\boxml{fun $f$ $\ldots$} & Mutually recursive region-polymorphic functions
               share the same closure, which is region-allocated, untagged,
               and whose size (in words) is the number of variables
               that occur free in the recursive declaration. One extra word is used when GC is enabled.\cr}
\hrule
\bigskip

\begin{center}
\bf Regions and their Representation
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
Finite (\boxml{$\rho$:$n$})& Region whose size can be determined at compile time. During
         compilation, a finite region size is given as a
         non-negative integer. After multiplicity
         inference, this integer indicates the number of times a value (of
         the appropriate type) is written into the region. Later, after
         physical size inference, the integer indicates the physical
         region size in words. At runtime, a finite region is allocated
         on the runtime stack.\cr
Infinite (\boxml{$\rho$:INF})& All other regions. At runtime, an infinite region
         consists of a stack allocated region descriptor, which contains pointers
         to the beginning and the end of a linked list of fixed size region
         pages.\cr }
\hrule
\medskip


\begin{center}
\bf Storage Modes (only significant for infinite regions)
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
{\tt atbot} & Reset region, then store value.\cr
{\tt sat}   & Determine actual storage mode ({\tt attop}/{\tt atbot})
              at runtime.\cr
{\tt attop} & Store at top of region, without destroying any values
              already in the region.\cr}
\hrule
\medskip

\tableofcontents
%---------------------------------------------------------
\chapter*{Preface}
%---------------------------------------------------------
The MLKit is a compiler infrastructure for
%
\index{Standard ML}%
%
the Standard ML programming language \cite{mthm97}. The MLKit supports
all of Standard ML, including Modules and most parts of the SML Basis
Library \cite{basislib2004}.  The MLKit features a region-based native
backend that generates efficient x64 machine code. This version of the
compiler is also named MLKit with Regions. The MLKit also features a
%
\index{JavaScript backend}%
%
JavaScript backend, which generates code for execution in web
browsers. The MLKit with Regions, which this report is about, is
intended for the development of stand-alone applications that must be
reliable, fast, and space efficient.

There has always been a tension between high-level features in
programming languages and the programmer's legitimate need to
understand programs at the operational level. Very likely, if a
resource conscious programmer is forced to make a choice between the
two, he will choose the latter.

The MLKit with Regions is the result of a research and development
effort, which was initiated at the University of Copenhagen in 1992.
The goal of the project has been to develop implementation technology
that combines the advantages of using a high-level programming
language, in this case Standard ML, with a model of computation that
allows programmers to reason about how much space and time their
programs use.

In most call-by-value languages, it is not terribly hard to give a
model of time usage that is good enough for elementary reasoning.

For space, however, the situation is much less satisfactory. Part of
the reason is that many programs must recycle memory while running.
For all such programs, the mechanisms that reclaim memory inevitably
become part of the reasoning.  This is true irrespective of whether
memory recycling is done by a
\index{stack}%
stack mechanism or by pointer tracing garbage collection.

In the stack discipline, every point of allocation is matched by a
point of deallocation and these points are obvious from the
program. By contrast, garbage collection techniques usually separate
allocation, which is done by the programmer, from deallocation, which
is done by a garbage collector.  The advantage of using reference
tracing
\index{garbage collection}%
garbage collection techniques is that they apply to a wide range of
high-level concepts now found in programming languages, for example
recursive data types, higher-order functions, exceptions, references,
and objects. The disadvantage is that it is becoming increasingly
difficult for the programmer to reason about lifetimes. Lifetimes may
depend on subtle details in the compiler and in the garbage collector.
Thus, it is hard to model memory in a way that is useful to
programmers. Also, compilers offer little assistance for reasoning
about lifetimes.

In this report, we describe how Standard ML can be equipped with a different memory
management discipline, namely a {\em region-based} memory model.  Like
the stack discipline, the region discipline is, in essence, simple and
platform-independent. Unlike the traditional stack discipline,
however, the region discipline also applies to recursive data types,
references, and higher-order functions, for which one has hitherto
mostly used reference tracing garbage collection techniques.

The reader we have in mind is a person with a Computer Science
background who is interested in developing reliable and efficient
applications written in Standard ML. Also, the report may be of
interest to researchers of programming languages, since the MLKit
with Regions is a fairly bold exercise in program analysis. We should
emphasize, however, that this report is very much intended as a user's
guide, not a scientific publication.

This report consists of three parts:
\begin{description}
\item[Part I, Overview:] This part gives an overview of the ideas
  that underlie programming with regions in the MLKit.
\item[Part II, Understanding Regions:] The second part of the report
  systematically presents the language constructs of the Standard ML
  Language, showing for each construct how it can be used when
  programming with regions.
\item[Part III, System Reference:] In this part, we explain how to
  interact with the system, how to use the region profiler and how to
  call C functions from the MLKit.
\end{description}

The present report describes the
\index{MLKit!Version \docversion}%
MLKit Version~{\docversion}. This version of the MLKit extends, and differs from, the MLKit
Version~4.3.0 by the following features:

\begin{enumerate}
\item Type variables are no longer associated with region variables,
  which simplifies region types significantly and eases the
  implementation.
\item The machinery for ensuring that no dangling pointers are
  dereferenced during a garbage collection has been fixed.
\item A move to machine code generation for the x86\_64
  architecture. The port also features register allocation for
  floating point registers, holding intra-procedural values of type \texttt{real}.

\item Additional Standard ML Basis Library features, including support
  for socket programming (e.g., structure \texttt{Socket}) and general
  Unix programming (structure \texttt{Unix}).

\item Support for generational garbage collection as a generalisation
  of the ordinary pointer-tracing garbage collector that can be used
  as an add-on to region-based memory management.

\item A large number of bug-fixes, performance improvements, and
  general new features, such as colorful region profile graphs...
\end{enumerate}

Further, Version~4.3.0 extends Version~4 with the following features:
\begin{enumerate}
\item Support for compiling
\index{ML Basis Files}%
ML Basis Files. ML Basis Files allows for
  expressing source dependencies, exactly (as a directed acyclic
  graph). ML Basis Files thus provides a mechanism for programming
  ``in the very large''.

\item File-based
\index{separate compilation}%
separate compilation, based on ML Basis Files.
\item An updated Standard ML Basis Library conforming to the
  specification published in \cite{basislib2004}.
\item Untagged representation of heap-allocated pairs, triples, and
  Standard ML references, even when garbage collection is enabled.
\end{enumerate}

MLKit Version~4 extends
MLKit Version~3 with the following features:
\begin{enumerate}
\item Support for pointer tracing garbage collection. Pointer tracing
  garbage collection works well together with the region memory model.
  While most de-allocations can be efficiently performed by region
  de-allocation, there are some uses of memory for which life time
  prediction is difficult. In these cases pointer tracing garbage
  collection does a good job in collaboration with region memory
  management \cite{hallenberg99,het02}.
\item An x86 native backend. The
  \index{backend!native}%
  backend support has switched from HP PA-RISC to Linux on x86
  architectures.

\item A \index{backend!bytecode}% \index{bytecode}% bytecode
  backend. To improve portability of programs, MLKit Version 4
  featured a bytecode backend, which generated code for execution
  on a stack machine with region primitives. The stack
  machine closely resembles the stack machine used in the OCaml and
  Moscow ML compilers.
\end{enumerate}

The
\index{MLKit!Version 3}%
MLKit Version~3 extends the MLKit Version~2 with support for the
Standard ML Modules language. The
\index{MLKit!Version 2}%
MLKit Version~2 is a further development of the
\index{MLKit!Version 1}%
MLKit Version~1, which was developed at Edinburgh University and
University of Copenhagen \cite{brtt93}.  We hope you will enjoy using
the MLKit as much as we have enjoyed developing it. If
your experience with the MLKit gives rise to comments and suggestions,
specifically with relation to the goals and visions expressed here,
please feel free to write.  Further information is available at the
MLKit
\index{web site}%
Github web site:
\begin{tabbing}
\hskip2cm\url{https://github.com/melsman/mlkit}
\end{tabbing}

\begin{flushright}
September, 2001\\[5mm]
Mads Tofte, Lars Birkedal, Martin Elsman, Niels Hallenberg, \\
Tommy H\o jfeld Olesen, and Peter Sestoft \\[5mm]
Revised 2002, 2004, 2005, 2021 by Martin Elsman
\end{flushright}

\newpage

\section*{Contributions}
Many people have contributed to the development of the MLKit,
including Peter Bertelsen, Lars Birkedal, Martin Elsman, Niels
Hallenberg, Tommy H\o jfeld Olesen, Nick Rothwell, Mads Tofte, David
N.\@ Turner, Peter Sestoft, and Carsten Varming.

People who have contributed with bug reports and patches include, but
are not limited to (in alphabetical order) Johnny Andersen, Troels
Henriksen, Koshy A Joseph, Ken Friis Larsen, Philip Munksgaard,
Henning Niss, Daniel Wang, and Stephen Weeks.

\section*{License}
The MLKit compiler and tools are released under the GNU General Public
License:

{\sc
\begin{quote}
  This program is free software; you can redistribute it and/or
  modify it under the terms of the GNU General Public License as
  published by the Free Software Foundation; either version 2 of the
  License, or (at your option) any later version.

  This program is distributed in the hope that it will be useful, but
  WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program; if not, write to the Free Software
  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
\end{quote}
}

Parts of the MLKit (the runtime system and the Basis Library) is
distributed under the MIT licence:
{\sc
\begin{quote}
The MIT License

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
\end{quote}
}

For details, see the file \texttt{doc/license/MLKit-LICENSE} in the
source distribution.

%==============================

\part{Overview}

%---------------------------------------------------------
\chapter{Region-Based Memory Management}
\label{intro.sec}
%---------------------------------------------------------
Region-Based Memory Management is a technique for managing
memory for programs that use dynamic data structures, such as lists,
trees, pointers, and function closures.

\section{%
%Prevailing Approaches to
Dynamic Memory Management}
Many programming languages rely on a memory model consisting of a {\em
  stack}
\index{stack}%
and a
\index{heap}%
{\em heap}. Typically, the stack holds temporary values, activation
records, arrays, and in general, values whose lifetime is closely
connected to procedure activations and whose size can be determined at
the latest when creation of the value begins.  The heap is what holds
all the other values. In particular, the heap holds values whose size
can grow dynamically, such as lists and trees. The heap also holds
values whose lifetime does not follow procedure activations closely
(for example lists and, in functional languages, function closures and
suspensions).

The beauty of the stack discipline (apart from the fact that it is
often very efficient in practice) is that it couples allocation points
and de-allocation points in a manner that is intelligible to the
programmer. C programmers appreciate that whatever memory is allocated
for local variables in a procedure ceases to exist (and take up
memory) when the procedure returns.
\index{C}%
C programmers also know that counting from one to some large number,
$N$, is not best done by making $N$ recursive C procedure calls,
because that would use stack space proportional to $N$.

By contrast, programmers have much less help when it comes to managing
the heap.  Two approaches prevail. The first approach is that the
programmer manages memory herself, using explicit allocation and
de-allocation instructions (e.g.,
\index{malloc@\texttt{malloc}}%
{\tt malloc} and
\index{free@\texttt{free}}%
{\tt free} in C). For non-trivial programs this can be a very
significant burden, because it is, in general, very hard to make sure
that none of the values that reside in the memory that one wishes to
de-allocate are not needed for the rest of the computation.  This puts
the programmer in a difficult position. If one is too eager to reclaim
memory in the heap, the program might crash under some peculiar
circumstances, which might be hard to find during debugging.  If one
is too conservative reclaiming memory, the program might leak space,
that is, it might use more memory than expected, perhaps eventually,
exhaust the memory of the machine.

The other prevailing approach is to use automatic garbage collection
in the heap.  Some implementors of some languages even dispense with
the stack entirely, relying only on a heap with garbage collection.
Garbage collection techniques separate allocation, which is done by
the programmer, from de-allocation, which is done by the garbage
collector.  At first, this might seem like the perfect solution: no
longer does the programmer have to worry about whether memory that is
being reclaimed really is dead, for the garbage collector only
reclaims memory that cannot be reached by the rest of the
computation. However, reality is less perfect. Garbage collectors are
typically based on the idea that if data is reachable via pointers
(starting from the stack and other root data) then those data must be
kept. Consequently, programs have to be written with care to avoid
hanging on to too many pointers. Space conscious programmers (and
language implementors) can work their way around these problems, for
example by assigning {\tt nil} to pointers that are no longer used.
However, such tricks often rely on assumptions about the code that
cannot be checked by the compiler and that are likely to be
invalidated as the program evolves.


\section{Checked De-Allocation of Memory}
\label{checked.sec}
Regions offer an alternative to the two approaches to memory
management discussed in the previous section.  The runtime model is
very simple, at least in principle.  The store consists of a
\index{region stack}%
stack of
\index{region}%
{\em regions}, see Figure~\ref{stacks.fig}.
\begin{figure}[t]
\hrule
\begin{center}
\begin{picture}(70,50)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,5){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,35){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,10){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\put(60,5){\makebox(0,0){$\ldots$}}
\end{picture}
\end{center}
\caption{The store is a stack of regions; every region
is depicted by a box in the picture.}
\vskip5mm
\hrule
\label{stacks.fig}
\end{figure}
Regions hold values, for example tuples, records, function closures,
references, and values of recursive types (such as lists and trees).
All values, except those that fit within one machine word (for example
integers), are stored in regions.

The size of a region
\index{region size}%
is not necessarily known when the region is allocated.  Thus a region
can grow gradually (and many regions can grow at the same time) so one
might think of the region stack as a stack of heaps. However, the
region stack really is a stack in the sense that (a) if region $r_1$
is allocated before region $r_2$ then $r_2$ is de-allocated before
$r_1$ and (b) when a region is de-allocated, all the memory occupied
by that region is reclaimed in one constant time operation.

Values that reside in one region are often, but not always, of the
same type. A region can contain pointers to values that reside in the
same region or in other regions. Both forward pointers (i.e., pointers
from a region into a region closer to the stack top) and backwards
pointers (i.e., pointers to an older region) occur.

As mentioned in the preface, the present version of the MLKit
supports reference-tracing
\index{garbage collection}%
garbage collection in combination with region memory management
\cite{hallenberg99}. While most de-allocations can be efficiently
performed by region de-allocation, there are some uses of memory for
which it is difficult to predict when memory can be de-allocated.  In
these cases reference-tracing garbage collection does a good job in
combination with region de-allocation.

In many cases however, one can do just fine without reference-tracing
garbage collection. Without reference-tracing garbage collection the
region stack is the only form of memory management provided. Is the
region model really general enough to fit a wide variety of
computations?

First notice that the pure
\index{stack}%
stack discipline (a stack, but no heap) is a special case of the
region stack. Here the size of a region is known at the latest when
the region is allocated. Another special case is when one has just one
region in the region stack and that region grows dynamically.  This
case can be thought of as a
\index{heap}%
heap with no garbage collection, which again would not be sufficient.

But when one has many regions, one obtains the possibility of
distinguishing between values according to what region they reside in.
The MLKit has operations for allocating, de-allocating, and extending
regions. But it also has an explicit operation for
\index{region!resetting}%
resetting an existing region, that is, reclaiming all the memory
occupied by the region without eliminating the region from the region
stack.  This primitive, simple as it is, enables one to cope with most
of those situations where lifetimes simply are not nested.
Figure~\ref{slideshow.fig} shows a possible progression of the region
stack.

\begin{figure}
\hrule \medskip
\begin{center}
\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,5){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,35){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,10){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\put(60,5){\framebox(10,20){}}
\put(65,0){\makebox(0,0){$\boxml{r}_4$}}
\end{picture}
\medskip

(a)
\medskip

\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,15){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,35){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,0){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\put(60,5){\framebox(10,30){}}
\put(65,0){\makebox(0,0){$\boxml{r}_4$}}
\put(75,5){\framebox(10,20){}}
\put(80,0){\makebox(0,0){$\boxml{r}_5$}}
\end{picture}
\medskip

(b)
\medskip

\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,35){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,35){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,5){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\end{picture}
\medskip

(c)
\medskip
\end{center}
\caption{Further development of the region stack: (a) after allocation of
$\boxml{r}_4$;
(b) after growth of $\boxml{r}_1$ and $\boxml{r}_4$, resetting of $\boxml{r}_3$ and allocation of $\boxml{r}_5$;
(c) after popping of $\boxml{r}_4$ and $\boxml{r}_5$ but extension of $\boxml{r}_1$ and $\boxml{r}_3$.}
\vskip5mm
\hrule
\label{slideshow.fig}
\end{figure}

In the MLKit the vast majority of region management is done
automatically by the compiler and the runtime system.  Indeed, with
one exception, source programs are written in Standard ML, with no
added syntax or special directives. The exception has to do with
resetting of regions. The MLKit provides two built-in functions
\index{resetRegions@$\resetr$}%
\index{forceResetting@$\resetf$}%
($\resetr$ and $\resetf$), which instruct the program to reset
regions. Here $\resetr$ is a safe form of resetting where the compiler
only inserts region resetting instructions if it can prove that they
are safe; it prints thorough explanations of why it thinks resetting
might be unsafe otherwise. The function $\resetf$ is for potentially
unsafe resetting of regions, which is useful in cases where the
programmer jolly well knows that resetting is safe even if the
compiler cannot prove it. The function $\resetf$ is the only way we
allow users to make decisions that can make the program crash; many
programs do not need $\resetf$ and hence cannot crash (unless we have
bugs in our system).

All other region directives, including directives for allocation and
de-allocation of regions, are inferred automatically by the compiler.
This happens through a series of fairly complex program analyses and
transformations (in the excess of twenty-five passes involving three
typed intermediate languages). These analyses are formally defined and
the central one, called
\index{region inference}%
{\em region inference}, has been proved correct for a skeletal
language. Although the formal rules that govern region inference and
the other program analyses are complex, we have on purpose restricted
attention to program analyses that we feel capture natural programming
intuitions.  Moreover, the MLKit implementation is such that, with one
exception\footnote{The exception has to do with exceptions. When an
  exception is raised, a search down the stack for a handler takes
  place; this search is not constant time and it involves popping of
  regions on the way. However, the number of region operations is
  bounded by the number of handlers that appear on the stack.}, every
region directive takes constant time and constant space to execute.
The fact that we avoid interrupting program execution for unbounded
lengths of time gives a nice smooth experience when programs are run
and should make the scheme attractive for real-time programming.

To help programmers get used to the idea of programming with regions,
the MLKit can print region-annotated programs, that is, source programs
it has annotated with region directives. Also, it provides a
\index{region profiling}%
{\em region profiler\/} for examining run-time behavior.  The region
profiler gives a graphical representation of region sizes as a
function of time. This tool makes it possible to see what regions use
the most space and even to relate memory consumption back to
individual allocation points in the (annotated) source program.

To sum up, the key advantages obtained by using regions compared to more
traditional memory management schemes are
\begin{enumerate}
\item safety of de-allocation is checked by the compiler
\item the compiler can in many cases spot potential space leaks
\item region management is under the control of the user, provided one
  understands the principles of region inference
\item each of the region operations that are inserted use constant
  time and constant space at runtime
\item it is possible to relate runtime space consumption to allocation
  points in the source program; we have found region profiling to be a
  powerful tool for eliminating space leaks
\end{enumerate}
Regions are not a magic wand to solve all memory management problems.
Rather, the region scheme encourages a particular discipline of
programming. The purpose of this report is to lay out this discipline.

\section{Example: the Game of Life}
\label{life.sec}
\index{Life!game of}%
To illustrate the general flavor of region-based memory management,
let us consider the problem of implementing the game of Life. The game
takes place on a board that resembles a chess board, except that the
size of the board can grow as the game evolves. Thus every position
has eight neighboring positions (perhaps after extension of the
board).  At any point in time, every position is either {\em alive} or
{\em dead}. A snapshot of the game consisting of the board together
with an indication of which positions are alive is called a {\em
  generation}. The rules of the game specify how to progress from one
generation to the next. Consider generation $n$ from which we want to
create generation $n+1$ ($n\geq0$). Let $(i,j)$ be a position on the
board, relative to some fixed point $(0,0)$ in the plane. Assume
$(i,j)$ is alive in generation $n$. Then $(i,j)$ stays alive in
generation $n+1$ if and only if it has two or three live neighbors in
generation $n$. Assume $(i,j)$ is dead at generation $n$. Then it is
born in generation $n+1$ if and only if it has precisely three live
neighbors at generation $n$. We assume that only finitely many
positions are alive initially. An example of two generations of Life
is shown below:
\begin{verbatim}
                    0
                   0 0
                  0   00        0
       00         0   00     0000   0
       00         0   00    0000    0
                   0 0      0  0        00
                    0       0000        00
                             0000


                    0
                   0000
                  00 0 0      0 0
       00        000 0  0   0   0
       00         00 0 0    0
                   0000    0    0       00
                    0       0           00
                            0   0
                              00
\end{verbatim}

To represent the game board, we need a data structure that can grow
dynamically (so a two-dimensional array of fixed size is not
sufficient).  A simple solution is to represent a generation by a list
of integer pairs, namely the positions that are alive. Since we want
to give all pairs belonging to one generation the same lifetime (in
the computer memory, that is!)  it is natural to store all the integer
pairs belonging to one generation in the same region. Indeed region
inference forces this decision upon us, as it happens, since it
requires that all elements belonging to the same list lie in the same
region. (Different lists can lie in different regions, however.)

Thus, after having built the initial generation, we expect the region
stack to look like this
\begin{center}
\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{$l_n$: list of integer pairs representing generation $n$.}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\end{picture}
\end{center}
The computation of the next generation involves a considerable amount
of list computation.  Chris Reade has expressed the key part of the
computation as shown in Figure~\ref{xavier.fig}.
\begin{figure}
\hrule \medskip
\begin{verbatim}
  let val living = alive gen
      fun isalive x = member eq_int_pair_curry living x
      fun liveneighbours x = length(filter isalive (neighbours x))
      fun twoorthree n = n=2 orelse n=3
      val survivors = filter (twoorthree o liveneighbours) living
      val newnbrlist =
        collect (fn z => filter (fn x => not(isalive x))
                         (neighbours z)
                ) living
      val newborn = occurs3 newnbrlist
  in
     mkgen (survivors @ newborn)
  end
\end{verbatim}
\caption{An excerpt of (a modified version of)
Chris Reade's Game of Life program.}
\medskip

\hrule
\label{xavier.fig}
\end{figure}
Despite the extensive use of higher-order functions here, there is a
great deal of stack structure in this computation. For example, the
{\tt survivors} list can be allocated in a local region which can be
de-allocated after the list has been appended (\boxml{@}) to the {\tt
  newborn} list. The computation of {\tt survivors}, in turn, involves
the creation of a closure for \boxml{(twoorthree o liveneighbours)}
and additional creation of closures as part of the computation of the
application of {\tt filter}. Each time {\tt liveneighbours} is called
(by {\tt filter}) additional temporary values are created.  All of
this data should live shorter than {\tt survivors} itself.  The
details of these lifetimes are determined automatically by the region
inference algorithm, which ensures that when the above expression
terminates it will simply have created a list containing the live
positions of the new generation.

But now we have a design choice. Should we put the new generation in
the same region as the previous region or should we arrange that it is
put in a separate region? Piling all generations on top of each other
in the same region would clearly be a waste of space: only the most
recent generation is ever needed. Similarly, giving each generation a
separate region on the region stack is no good either, because it
would make the stack grow infinitely (although this could be
alleviated somewhat by resetting all regions except the topmost one).
The solution is simple, however: use two regions, one for the current
generation and one for the new generation. When the new generation has
been created, reset the region of the old region and copy the contents
of the new region into the old region. This effect is achieved by
organizing the main loop of the program as follows:
\begin{verbatim}
     local
  (*1*) fun nthgen'(p as(0,g)) = p
  (*2*)   | nthgen'(p as(i,g)) =
  (*3*)       nthgen' (i-1, let val g' = nextgen  g
  (*4*)                     in  show g;
  (*5*)                         resetRegions g;
  (*6*)                         copy g'
  (*7*)                     end)
     in
  (*8*) fun iter n = #2(nthgen'(n,gun()))
     end
\end{verbatim}
Here \boxml{nthgen'}
\index{nthgen@\texttt{nthgen}}%
is the main loop of the program. It takes a pair as argument; the
first component of the pair indicates the number of iterations
desired, while the second, \boxml{g}, is the current generation. The
use of the {\tt as} pattern in line 1 forces the argument and the
result of \boxml{nthgen'} to be in the same regions. Such a function
is called a
\index{region endomorphism}%
{\em region endomorphism}. In line 3, we compute a fresh generation,
which lies in fresh regions, as it happens. Having printed the
generation (line 4) we then reset the regions containing {\tt g}. The
compiler checks that this is safe. Then, in line 6 we copy {\tt g'}
and the target of this copy must be the regions of {\tt g}, because
\boxml{nthgen'} is a region endomorphism (see
Figure~\ref{doublecopy.fig}).  All in all, we have achieved that at
most two generations are live at the same time (a fact that can be
checked by inspecting the region-annotated code, if one feels
passionately about it).\footnote{The source file for the life program
  is \boxml{kitdemo/life.sml}. Running programs is described in
  Section~\ref{tryit.sec}. When run with n=10000 under Linux on an x64
  box, the memory consumption (resident memory, measured using {\tt
    top}) quickly reaches 500Kb and
  stays there for the remaining generations.}

\begin{figure}
\hrule
\begin{center}
\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{$l_n$: list of integer pairs representing generation $n$.}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\end{picture}
\medskip

(a)
\medskip

\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{$l_n$}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\put(50,5){\framebox(45,25){\parbox{4cm}{$l_{n+1}$: list of integer pairs representing generation $n+1$.}}}
\put(70,0){\makebox(0,0){$\boxml{r1}$}}
\end{picture}
\medskip

(b)
\medskip

\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{copy of $l_{n+1}$}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\end{picture}
\medskip

(c)
\medskip

\end{center}
\caption{ Using double-copying in the game of Life:
(a) generation number $n$ resides in region \boxml{r0}; (b)
 generation $(n+1)$ has been built in \boxml{r1};
(c) region \boxml{r0} has been reset, the new generation
copied into \boxml{r0} and \boxml{r1} has been de-allocated.}
\vskip5mm
\hrule
\label{doublecopy.fig}
\end{figure}

The above device, which we refer to as
\index{double copying}%
{\em double copying}, can be seen as a much expanded version of what
is often called ``tail recursion optimisation''.  In the case of
regions, not just the stack space, but also region space, is re-used.
Indeed, double copying is similar to invoking a copying garbage
collector on specific regions that are known not to have live pointers
into them.  But by doing the copying ourselves, we have full control
over when it happens, we know that the cost of copying will be
proportional to the size of the generation under consideration and
that all other memory management is done automatically by the region
mechanism. Because each of the region management directives that the
compiler inserts in the code are constant time and space operations,
we have now avoided unpredictable interruptions due to memory
management. This avoidance of unpredictable interruptions might not be
terribly important for the purpose of the game of Life, but if we were
writing control software for the ABS brakes of a car, having control
over all costs, including memory management, would be crucial!

% left lower right upper
\newcommand{\includerp}[1]{\includegraphics[trim=12mm 25mm 37mm 37mm, clip, width=\textwidth]{#1}}
%\newcommand{\includerp}[1]{\includegraphics[trim=16mm 27mm 41mm 41mm, clip, width=\textwidth]{#1}}

\begin{figure}
\includerp{life80.pdf}
\caption{A region profile of two hundred
  generations of the ``Game of Life'', showing region sizes as a
  function of time (80 snapshots).}
\label{lifeprof80.fig}
\end{figure}

Region profiles for two hundred generations of {\tt life} starting
from the configuration shown earlier appear in
Figures~\ref{lifeprof80.fig} and \ref{lifeprof200.fig}.  The highest
amount of memory used for regions during the computation is
45KiB. Figure~\ref{lifeprof200.fig}, which has data collected from 200
snapshots of the computation, clearly shows that most of the 45KiB are
reclaimed between every two generations of the game. It turns out that
the game essentially stabilizes with a small number of live positions
on the board after roughly 150 generations.  This stabilisation is
clearly reflected in the region profile.

\begin{figure}
\includerp{life200.pdf}
\caption{Region profile of two hundred
  generations of the ``Game of Life'', showing region sizes as a
  function of time (200 snapshots).}
\label{lifeprof200.fig}
\end{figure}

Figure~\ref{lifeprof80.fig} is from the same computation, but it only
includes data from 80 snapshots. In the figures, we can see that the
largest region is \boxml{r154413}. To find out what this region
contains, however, one needs to know about the methods described in
Part~\ref{understanding.sec}.

\section{Try it!}
This section tells you how to repeat the profiling experiment shown
above.

Compile the SML program \boxml{kitdemo/life.sml} as follows. First,
make a personal copy of the {\tt kit/kitdemo} directory, place
yourself in it, and execute the command:\footnote{We assume that the
  MLKit compiler command \texttt{mlkit} is somehow available through
  your {\tt PATH} environment variable.}
\begin{verbatim}
  $ mlkit -no_gc -prof life.sml
\end{verbatim}
The option \texttt{-prof} enables region profiling and the option
\texttt{-no\_gc} disables reference tracing garbage collection. After
the MLKit has compiled the program \boxml{life.sml}, the executable
life program is available as \boxml{kitdemo/run}.

Next, you may execute \boxml{run}, as follows:
\begin{verbatim}
  $ ./run -microsec 500
\end{verbatim}
This command will make a profiling snapshot every 500 microseconds (i.e.,
every half millisecond). If you are satisfied with less fine-grained
information, choose a larger number; it will speed up execution. If
you just type
\begin{verbatim}
  ./run
\end{verbatim}
there will be one snapshot per second.

Finally, you create a PostScript file and convert it into a pdf-file as
follows:\footnote{The program {\tt rp2ps} can be found in the {\tt
    kit/bin} directory.}
\index{rp2ps@\texttt{rp2ps}}%
\begin{verbatim}
  $ rp2ps -region -name 'Game of life - 200 snapshots' -sampleMax 80
  $ ps2pdf region.ps region.pdf
\end{verbatim}
The option \boxml{-sampleMax $N$} instructs \boxml{rp2ps} to show at
most $N$ snapshots (evenly distributed over the duration of the
computation).

%--------------------------------------------------
\chapter{Making Regions Concrete}
%--------------------------------------------------
In this chapter, we give a brief overview of how the abstract memory
model presented in the last chapter is mapped down to conventional
memory. In doing so, we shall introduce notation and concepts that
will be used extensively in what follows.


\section{Finite and Infinite Regions}
\label{fininf.sec}
Not every region has the property that its size is known at
compile-time, or even when the region is first allocated at runtime.
As we have seen, one typical use of a region is to hold a list, and in
general there is no way of knowing how long a given list is going to
be.


For efficiency reasons, however, the MLKit distinguishes between two
kinds of regions: those regions whose size it can determine at
compile-time and those it cannot.
\index{region size}%
These regions are referred to as
\index{region size!finite}%
{\em finite} and
\index{region size!infinite}%
{\em infinite} regions, respectively.\footnote{``finite'' and
  ``unbounded'' would have been better terms, but it is too late to
  change that.}  Finite regions are always allocated on the
\index{runtime stack}%
runtime stack.  An infinite region is represented as a linked list of
fixed-size
\index{region pages}%
pages.  The runtime system maintains a free list of such pages. An
infinite region is represented by a
\index{region descriptor}%
{\em region descriptor}, which is a record kept on the runtime stack.
The region descriptor contains two pointers: one to the first and one
to the last region page in the linked list that represents the region.
Allocating an infinite region involves getting a page from the
\index{free list}%
free list and pushing a region descriptor onto the
runtime stack. Popping a region is done by appending the region pages
of the region and the free list (this is done in constant time) and
then popping the region descriptor off the runtime stack.

At runtime, every region is represented by a 64-bit entity, called a
\index{region name}%
{\em region name}. If the region is finite, the region name is a
pointer into the stack, namely to the beginning of the region. If the
region is infinite, the region name is a pointer to the region
descriptor of the region.

The \index{multiplicity}{\em multiplicity} of a region is a statically
determined upper bound on the number of times a value is put into the
region. The MLKit operates with three multiplicities: 0, 1 and $\infty$,
ordered by $0<1<\infty$. Multiplicities annotate binding occurrences
of region variables. An expression of the form
$$\boxml{let region $\rho:m$ in $e$ end}$$
where $m$ is a multiplicity,
gives rise to an allocation of a region, which is finite if $m<\infty$, and
infinite otherwise.

\section{Runtime Types of Regions}
\label{runtimetypes.sec}
Every region has a \index{runtime type}% runtime type. The following
runtime types exist: {\sc pair\_rt}, {\sc array\_rt}, {\sc ref\_rt},
{\sc triple\_rt}, {\sc string\_rt}, {\sc top\_rt}, and {\sc
  bot\_rt}. Not surprisingly, regions of runtime type {\sc string\_rt}
contain values of ML type {\tt string}. Regions of runtime type {\sc
  pair\_rt}, {\sc array\_rt}, {\sc ref\_rt}, and {\sc triple\_rt}
contain pairs, arrays, references, and triples, respectively.  Regions
with runtime type {\sc top\_rt} can contain all other forms of
allocated values, that is, constructed values, such as tuples (that
are not pairs or triples), records (that do not contain two or three
fields), and function closures. Regions of runtime type {\sc bot\_rt}
are not present at runtime and are associated only with so-called
\emph{explicit region variables}, which we shall not discuss in this
document.

It is often, but not always, the case that all values that reside in
the same region have the same type (considered as representations of
ML values).

\section{Allocation and De-Allocation of Regions}
\label{aldeal.sec}
The analysis that decides when regions should be allocated and
de-allocated is called {\em region inference}. Region inference
inserts several forms of memory management directives as directives
into the program.  The target language of region inference is called
\index{RegExp@$\RegExp$}%
$\RegExp$.

In $\RegExp$, region allocation and de-allocation are explicit, they
are always paired, and they follow the syntactical structure of the
source program.  If $e$ is an expression in $\RegExp$, then so is
\index{let region@\texttt{let region}}%
$$\boxml{let region $\rho$ in $e$ end}$$
Here $\rho$ is a
\index{region variable}%
{\em region variable}. At runtime, first a region is allocated and
bound to $\rho$. Then $e$ is evaluated, presumably using the region
bound to $\rho$ for storing values. Upon reaching {\tt end}, the
program pops the region.

Region inference also decides, for each value-producing expression,
into which region (identified by a region variable) the value will be
put.

We emphasize that region variables and {\tt region} bindings are
not present in source programs. The source language is unadulterated
Standard ML, so programs that run on the MLKit should be easy to port to
any other Standard ML implementation.

%Conceptually, there is also a normal runtime stack, which holds temporary values,
%return addresses and so on, but in practice the two stacks are merged into one, which
%we refer to as the runtime stack.

\section{Two Backends}
\index{backend!native}%
\index{backend!bytecode}%
%
The MLKit provides two different backends, one that generates native
code for the x64 architecture (running Linux or macOS), the {\em
  native backend\/} and one that generates JavaScript
\cite{10.1145/2093328.2093336}.\footnote{Previous versions of the
  MLKit also supported a bytecode backend that allowed for generated
  bytecode to be executed by a region based abstract machine
  \cite{kam02} and which was used in the context of a web-server
  plugin for Standard ML code \cite{eh03,smlserver07}; support for this backend has terminated, however.}

Whereas the native x64 backend makes use of regions as its basic
memory management discipline, SMLtoJs compiles Standard ML programs to
JavaScript and makes use of JavaScript's garbage collection mechanisms
for allocating and deallocating memory. In this report, we shall only
be concerned about the native backend, for which the linear address
space is partitioned into a stack and a heap, which holds region
pages, all of the same size.\footnote{With the exception that objects
  that do not fit into a page are allocated using \texttt{malloc} and
  freed with \texttt{free}.}

For the x64 native backend, programs compile into a sequence of
instructions, for example for moving word-size data between two
registers or between a register and a memory location.  More complex
operations, such as function application, are expressed by sequences
of more detailed instructions. The native backend implements Iterated
Register Allocation \cite{appel96} for assigning machine registers to
temporary variables, using the runtime stack for spilling.  Although
register allocation as well as other issues, such as the interaction
between hardware cache strategies and code selection, are important
for generating efficient code on modern architectures, we do not
want to go to that level of detail here. Our primary concern is with
establishing a model that the user can safely use as a worst-case
model of what happens at runtime.

\section{Boxed and Unboxed Values}
\label{boxing.sec}
\index{boxing}%
\index{value!boxed}%
\index{value!unboxed}%
As is common with implementations of programming languages, we
distinguish between {\em boxed\/} and {\em unboxed\/} representation
of values.  An {\em unboxed\/} value is one that is stored in a
register or a machine word. A {\em boxed value\/} is one that is
represented by a word-size pointer to the value itself, which is
stored in one or more regions.

The MLKit uses unboxed representation for integers, booleans, words, the
unit value, and characters.  The MLKit uses boxed representation for
pairs, records (with at least one element), reals, exception values,
function closures, and constructed values (i.e., data types, except
lists and booleans).

A boxed value may reside in a finite or an infinite region.  Unboxed
values are not stored in regions, except when they are part of a boxed
value. For example, the integer \boxml{3} by itself is stored as the
(binary representation) of the value 3 in a register or in a machine
word. However, the pair \boxml{(3,4)} is represented as a pointer to
two consecutive words in a region, the first of which contains the
binary representation of 3 and the second of which contains the binary
representation of 4.

\section{Intermediate Languages}
The MLKit native compiler compiles Standard ML programs via a sequence
of typed intermediate languages into x64 machine code.

The intermediate languages that we shall refer to in the following are
(in the order in which they are used in the compilation process):
\begin{description}
\item[\Lam:]
  \index{Lambda@$\Lam$}%
  A lambda-calculus like intermediate language. The main difference
  between the Standard ML Core Language and $\Lam$ is that $\Lam$ only
  has trivial patterns and allows functions to take
\index{arguments!multiple}%
\index{multiple function arguments}%
\index{function arguments!multiple}%
  multiple arguments.
\item[\RegExp:]
  \index{RegExp@$\RegExp$}%
  Same as \Lam, but with explicit region annotations (such as the {\tt
    region} bindings mentioned in Section~\ref{aldeal.sec}). Region
  variables have their runtime type (Section~\ref{runtimetypes.sec})
  as an attribute, although, for brevity, the pretty printer omits
  runtime types when printing expressions, unless instructed
  otherwise.
\item[\MulExp:]
  \index{MulExp@$\MulExp$}%
  Same as $\RegExp$, but now every binding region variable occurrence
  is also annotated with a multiplicity (Section~\ref{fininf.sec}) in
  addition to a runtime type.  Again, the default is that the runtime
  type is not printed.  The terms of $\MulExp$ are polymorphic in the
  information that annotate the nodes of the terms. That way,
  $\MulExp$ can be used as a common intermediate language for a number
  of the internal analyses of the compiler, which add more and more
  information on the syntax tree.  The analysis that computes
  multiplicities is called the
  \index{multiplicity analysis}%
  {\em multiplicity analysis}.
\end{description}
%The MLKit compiles SML records into $\Lam$-tuples and compiles
%SML-matches and other constructs containing patterns
%into simpler $\Lam$-constructs.

The MLKit contains a
\index{Lambda optimiser}%
$\Lam$ optimiser, which will happily rewrite $\Lam$ terms when it is
clear that this rewrite results in faster programs (as long as the
rewrite cannot lead to increased space usage).

Region inference takes $\Lam$ to be the source language. Region
inference happens after the $\Lam$ optimiser has had a go at the
$\Lam$ term.  Therefore, it was not really true when we said that
region inference simply annotates source programs; we ignored the
translation from SML to $\Lam$ and the $\Lam$ optimiser. Thus, one has
to get used to (mostly minor) differences between the source language
and the intermediate languages of the compiler if one wants to read
programs in their intermediate forms. Moreover,
\index{Standard ML!Modules}%
Modules Language constructs are eliminated during compilation from the
intermediate languages (see Chapter~\ref{mlb_and_modules.chap}
for details of compiling with Modules in the MLKit).

When we want to show the result of the analyses, we usually show a
$\MulExp$ expression.

\section{The Runtime System}
The
\index{runtime system}%
runtime system is written in C. It is small (less than 30Kb of code
when compiled).  It contains operations for allocating and
de-allocating regions, extending regions, obtaining more space from
the operating system, recording region profiling information, and
performing low-level operations for use by the Standard ML Basis
Library.

It is possible to call
\index{C!calling}%
C functions from MLKit code if you use the native backend.  The MLKit
takes care of the memory allocation, by allocating regions for the
result of the call before the call and de-allocating the regions at
some point after the call.  The C functions can build ML data
structures such as lists through abstract operations provided by the
MLKit runtime system. See Chapter~\ref{ccall.sec} for further details.

\section{Compiling Programs with the MLKit}
\label{tryit.sec}

The MLKit is a
\index{batch compilation}%
batch compiler. Thus, executing a program consists of first compiling
the program and then running the generated target program. Because the
MLKit stores files in the directories where your source files are
located, you should make a personal copy of these directories.  Before
you try any of the examples below, make a personal copy of the {\tt
  kitdemo} directory, which is part of the distribution, and run the
MLKit on your own copy.

\section{Compiling with the MLKit Compiler}

The mechanism the MLKit provides for compiling programs is to give the
program source(s) as argument to the MLKit command
\index{mlkit@\texttt{mlkit}!executable}%
\texttt{mlkit}.  Together with the sources, a series of options may be
passed to the \texttt{mlkit} command. Let us assume that the UNIX
command \texttt{mlkit} is available on your system.\footnote{The {\tt
    README} file in the distribution tells you how to install the
  MLKit.}

Compiling an
\index{MLB-file}%
MLB-file (which may list several SML source files) is
similar to compiling a single SML source file. However, we shall
postpone the in-depth discussion of how to compile MLB-files to
Chapter~\ref{mlb_and_modules.chap}.

As an example, to compile the file \boxml{projection.sml} located in
the \texttt{kitdemo} directory, first go to this directory and execute
the following command:
\begin{verbatim}
  $ mlkit -no_gc projection.sml
\end{verbatim}
Execution of this command will result in an executable file
\texttt{run}, placed in the \texttt{kitdemo} directory.

To see some internal representations of the \texttt{projection.sml}
program, as produced during compilation, try pass the command-line
options \boxml{--print\_types} and
\boxml{--print\_drop\_regions\_expression} to the \texttt{mlkit}
command, as follows:
\begin{verbatim}
  $ rm -rf MLB
  $ mlkit -no_gc \
          -print_types \
          -print_drop_regions_expression \
          projection.sml
\end{verbatim}
Removing the \texttt{MLB} directory is necessary to avoid the MLKit to
recognise that it can reuse the previous result of compiling the
\texttt{projection.sml} program.  A shorter version of the compilation
command is
\begin{verbatim}
  $ mlkit -no_gc -Ptypes -Pdre projection.sml
\end{verbatim}
To get more information about which options you can pass to the MLKit
at the command-line, try executing \boxml{mlkit -help}. The output of
executing this command is shown in Appendix~\ref{mlkithelp.app}.

\section{Running Compiled Programs}
If no errors were found during compilation, the MLKit produces a
\index{target program}%
{\em target program} in the form of an executable file, called {\tt
  run}. The MLKit places {\tt run} in the working directory.

Running the target program is done from the UNIX shell by typing
\index{run@\texttt{run}}%
\begin{verbatim}
  $ ./run
\end{verbatim}
For small programs, the file will probably be around 50Kb large, even
for the trivial examples considered in this chapter.  This is because
it contains the MLKit runtime system and compiled code for the parts of
the SML Basis Library that are needed for linking.

Running the programs presented in this chapter is not particularly
exciting, because none of them produce output! However, as an
exercise, try compile and execute the
\index{hello world@\texttt{hello world}}%
{\tt helloworld.sml} program, which, like all other example files in
this document, is located in the
\index{kitdemo directory@\texttt{kitdemo} directory}%
{\tt kitdemo} directory.


\part{The Language Constructs of SML}
\label{understanding.sec}

%---------------------------------------------------------
\chapter{Records and Tuples}
\label{records.sec}
%---------------------------------------------------------
In this chapter we describe construction of
\index{record}%
records and selection of record components. We also use records to
introduce
\index{type!region-annotated}%
{\em region-annotated types} and
\index{effect}%
{\em effects}, which are crucial for understanding when regions are
allocated and de-allocated.

\section{Syntax}
As part of the SML to
\index{Lambda@$\Lam$}%
$\Lam$ translation, all SML records and SML tuples are compiled into
$\Lam$ tuples. The components of $\Lam$ tuples are numbered from left
to right, starting from 0.  Selection is a primitive operation, both
in $\Lam$ and in the other intermediate languages. This primitive is
printed using SML notation \boxml{\#$i$}. Components are numbered from
0: the $i$th components of a tuple of type
$\tau_1\ast\ldots\ast\tau_n$ is accessed by \boxml{\#$i$}, for $0\leq
i\leq n-1$.

The tuple constructor in $\Lam$ is written as in SML:
$$\boxml{(}e_1\boxml{,}\ldots\boxml{,}e_n\boxml{)}$$
However, the corresponding expression in $\RegExp$ and $\MulExp$ takes the form
$$\boxml{(}e_1\boxml{,}\ldots\boxml{,}e_n\boxml{)}\,\at\,\rho$$
\index{at@\texttt{at}}%
where $\rho$ is a
\index{region variable}%
region variable indicating where the tuple should be put.  In the case
$n=0$, the $\at\,\rho$ is not printed, because the empty tuple is not
allocated; it is just a constant that fits in a
\index{register}%
register at runtime.

Records are evaluated left to right.

\section{Example: Basic Record Operations}
\label{proj.ex}
Consider the source program
\begin{verbatim}
  val xy = ((),())
  val x = #1 xy;
\end{verbatim}
Here is the resulting $\MulExp$ program:\footnote{Program
  \boxml{kitdemo/projection.sml}. Running programs is described in
  Section~\ref{tryit.sec}.}
\begin{verbatim}
  let val xy = ((), ())at r4;
      val x = #0 xy
  in {|xy: (_,r4), x: _|}
  end
\end{verbatim}
There are several things to notice from this example.
\begin{enumerate}
\item The $\MulExp$ program contains a free region variable, {\tt r4}.
  Notice that the construction of the pair {\tt xy} has been annotated
  by ``{\tt at r4}'', indicating where the pair should be put;
\item The expression \verb+{|xy: (_,r4), x: _|}+ is an example of a
  \index{frame}%
  {\em frame expression}. A frame enumerates the components that are
  exported from a compilation unit.  A frame is similar to a record,
  except that its components are variables, each annotated with a type
  scheme and a region variable, if the value is boxed. (In records, the components can only
  have types, not general type schemes.) In the example, the type of
  the frame is \verb+{|xy: (unit*unit, r4), x: unit|}+.
    % (Regions of unboxed elements are not printed, since unboxed values
    % are not allocated in regions.)
  The type shows that, after the program unit has been evaluated,
  \boxml{xy} will reside in \boxml{r4}.  In the the above example,
  printing of types was suppressed. Thus types were abbreviated to
  \boxml{\_}.
\end{enumerate}
\section{Region-Annotated Types}
\label{reganntypes.sec}
ML type inference infers a type for every expression in the program.
Region inference extends this idea by inferring for each expression a
\index{type with place}%
\index{region-annotated type}%
{\em (region-annotated) type with place}. We use $\mu$ to range over
types with places
$$\mu ~~ ::= ~~ (\tau,\rho)~~|~~\tau$$
where $\tau$ is a {\em region-annotated type},
which again can contain other region-annotated types with places. The
region-annotated type with place of an expression is the ML type of
the expression decorated with extra region information; every type
constructor that represents boxed values (e.g., pairs and strings) is
paired with a region variable, indicating where the value is to be put
at runtime. Type constructors that represents unboxed values (e.g.,
integers and booleans) are not paired with a region.
\index{boxing}%
\index{value!boxed}%
\index{value!unboxed}%

Here are some examples of region-annotated types with places:
\begin{description}
\item[\fbox{$\boxml{unit}$}] The type of 0-tuples.  Integers,
  booleans, and 0-tuples are represented
  \index{boxing}%
  unboxed at runtime (rather than being stored in regions), see
  Section~\ref{boxing.sec}.
\item[\fbox{$(\boxml{string}, \rho)$}] The type of strings in region
  $\rho$.
\item[\fbox{$\bigl(\boxml{int} \ast (\boxml{string}, \rho_1),
    \rho_2\bigr)$}] The type of pairs in $\rho_2$ whose first
  component is an integer and whose second component is a string in
  region $\rho_1$.
\end{description}

One can get the MLKit to print the region-annotated types with places
that it infers for binding occurrences of variables.  The above
example then becomes
\begin{verbatim}
  let val xy:(unit*unit,r4) = ((), ())at r4;
      val x:unit = #0 xy
  in {|xy: (unit*unit,r4), x: unit|}
  end
\end{verbatim}

\section{Effects and \texttt{let region}}
\label{effects.sec}
We now describe the general principle that the MLKit uses to decide when
it is safe to put
\index{let region@\texttt{let region}}%
\boxml{region} binding around an expression.

Here is an example of an SML program that first creates a pair and
then selects a component of the pair, after which the pair is
garbage:\footnote{Program \boxml{kitdemo/elimpair.sml}.}
\begin{verbatim}
  val n = let
             val pair = if true then (3+4, 4+5)
                        else (4, 5)
          in
             #1 pair
          end
\end{verbatim}
The MLKit compiles the declaration into the $\MulExp$ program shown in
Figure~\ref{elimpair.fig}.  The compiler compiles the program as it
is, without reducing the conditional to its {\tt then} branch.
\begin{figure}
\hrule\medskip
\begin{verbatim}
   let val n =
         let region r13:1;
             val pair = case true of
                          true => (3 + 4, 4 + 5)at r13
                        | _ => (4, 5)at r13
         in  #0 pair
         end
   in  {|n: _|}
   end
\end{verbatim}
\caption{Region inference decides that the pair is to be allocated
  in a local, finite region; the region will be de-allocated as soon
  as the pair becomes garbage.}
\medskip\hrule
\label{elimpair.fig}
\end{figure}
During evaluation, a region (denoted by {\tt r13}) is introduced before
the pair is allocated; it remains on the region stack until the
projection of the pair is evaluated, after which the region is
de-allocated.

The ``{\tt :1}'' on the binding occurrences of {\tt r13} is a
multiplicity indicating that there is only one store operation into
the region. (The
\index{multiplicity analysis}%
multiplicity analysis has discovered that there is at most one store
from the {\tt then} branch and at most one store from the {\tt else}
branch and that at most one of the branches will be chosen.) Thus, the
pair will be allocated in a little region on the runtime stack.

But how does the MLKit know that it is safe to
\index{region!de-allocation}%
de-allocate {\tt r13} when the
\index{region@\texttt{region}}%
region goes out of scope?

The answer lies in the fact that the MLKit infers for every expression
not just a region-annotated type with place, but also a so-called
\index{effect}%
{\em effect}.  An effect is a finite set of
\index{effect!atomic}%
atomic effects. Two forms of atomic effect are
\index{put@{$\Put$}}%
$\Put(\rho)$ and
\index{get@{$\Get$}}%
$\Get(\rho)$, where $\rho$ as usual ranges over region variables. The
atomic effect $\Put(\rho)$ indicates that a value is being stored in
region $\rho$ and $\Get(\rho)$ indicates that a value is being read
from region $\rho$.  In our example, the region inference algorithm
considers the sub-expression ($e_0=$)
\begin{verbatim}
  let val pair = case true of
                    true => (3 + 4, 4 + 5)at r13
                  | _ => (4, 5)at r13
  in  #0 pair
  end
\end{verbatim}
and finds that it has region-annotated type $\boxml{int}$ and effect
$\{\Put(\boxml{r13}), \Get(\boxml{r13})\}$.

Whenever a region variable occurs free in the effect of an expression
but occurs free neither in the region-annotated type with place of the
expression nor in the type of any program variable that occurs free in
the expression then that region variable denotes a region that is used
only locally within the expression.  That this is true is of course
far from trivial, but it has been proved for a skeletal version of
$\RegExp$.  Consequently, when this condition is met, the region
inference algorithm wraps a
\index{let region@\texttt{let region}}%
\texttt{region} binding of the region variable around that expression.

In our example, there are no free variables in $e_0$; moreover,
$\boxml{r13}$ occurs in the effect of $e_0$ but not in the
region-annotated type with place of $e_0$. Thus, the region inference
algorithm inserts a \texttt{region} binding of $\boxml{r13}$ around
$e_0$.

\section{Runtime Representation}
A
\index{record!runtime representation of}%
record with 0 components (the value of type
\index{unit@\texttt{unit}}%
{\tt unit}) is represented unboxed.  A record with $n$ components
($n\geq 1$) is represented boxed, as a pointer to precisely $n$ words
in a region.\footnote{When garbage collection (GC) is enabled, $n+1$
  words are used to hold a record with $n$ components.}  Notice that
records are not tagged. Avoiding tags is possible when the reference
tracing garbage collector is disabled, because
\index{equality!polymorphic}%
polymorphic equality is compiled into
\index{equality!monomorphic}%
monomorphic equality functions that do not have to examine the type of
objects at runtime \cite{ElsmanTIC98}.

$\Lam$, $\RegExp$, and $\MulExp$ allow one to express unboxed tuples,
also in the case of function calls and returns. For functions that
take a tuple as parameter, the MLKit passes the argument tuple unboxed
\index{arguments!multiple}%
\index{multiple function arguments}%
\index{function arguments!multiple}%
\index{record!unboxed}%
if it can see that the boxed representation of the tuple is not needed
by the function. The MLKit does not at present unbox records returned
from functions. See Section~\ref{region-polymorphic-functions.sec} on
page~\pageref{region-polymorphic-functions.sec} for details about
unboxed function arguments.

A tuple is not allocated until its components have been evaluated.

When reference-tracing garbage collections is enabled, records and
tuples are tagged unless they are of size two or three (pairs or
triples), in which case they will reside in regions of runtime type
{\sc pair\_rt} or {\sc triple\_rt}, respectively. Such regions are
treated specially by the reference-tracing garbage collector.

%---------------------------------------------------------
\chapter{Basic Values}
%---------------------------------------------------------
In this chapter we describe how basic values such as integers, reals,
strings, and booleans are represented in the MLKit. The MLKit complies to
the Definition of Standard ML (Revised)
\index{Standard ML!{1997 revision}}%
and to large parts of the Standard ML Basis
Library;\footnote{See the MLKit web site for a link to the Standard ML
  Basis Library.}
\index{Standard ML!{Basis Library}}%
\index{Basis Library}%
that is, as a programmer, you can refer to components of the Standard
ML Basis Library through the
\index{initial basis}%
{\em initial basis}, in which all programs are compiled.  Throughout
this chapter, we introduce some of the top-level bindings that are
provided by the initial basis.

\section{Integers and Words}
\label{integers.sec}
Values of type
\index{integer}%
{\tt int} are represented as unboxed 64-bit signed integers. When
reference tracing garbage collection is enabled in the MLKit, one bit is
used for tagging, thus in this case values of type {\tt int} are
really 63-bit signed integers; Chapter~\ref{gc.chap} describes how to
compile programs with garbage collection enabled. The structure {\tt
  Int} provides many useful operations on integers of type {\tt
  int}.\footnote{To see what operations are available in the {\tt Int}
  structure, consult the file {\tt basis/INTEGER.sml}.}  The MLKit
also defines the structures
\index{Int31 structure@{\tt Int31} structure}%
{\tt Int31},
\index{Int32 structure@{\tt Int32} structure}%
{\tt Int32},
\index{Int63 structure@{\tt Int63} structure}%
{\tt Int63}, and
\index{Int64 structure@{\tt Int64} structure}%
{\tt Int64} for operations on 31-bit, 32-bit integers, 63-bit, and 64-bit integers. When garbage collection is enabled, values of type {\tt
  Int64.int} and {\tt Int32.int} (for historical reasons) are represented boxed, whereas values of type {\tt
  Int31.int} and {\tt Int63.int} are represented unboxed. When garbage
collection is enabled, the structure {\tt Int} is identical to the
structure {\tt Int63}. When garbage collection is disabled, the
structure {\tt Int} is identical to the structure {\tt Int64}.

The following operations on integers are pre-defined at top level:
\index{=@\texttt{=}}%
\index{<>@\texttt{<>}}%
\index{<@\texttt{<}}%
\index{>@\texttt{>}}%
\index{<=@\texttt{<=}}%
\index{>=@\texttt{>=}}%
\index{+@\texttt{+}}%
\index{-@\texttt{-}}%
\index{div@\texttt{div}}%
\index{mod@\texttt{mod}}%
\index{*@\texttt{*}}%
\index{~@\verb+~+}%
\index{abs@\texttt{abs}}%
\begin{verbatim}
  infix  4 = <> < > <= >=
  infix  6 + -
  infix  7 div mod  *
  val ~ :  int -> int
  val abs: int -> int
\end{verbatim}

In fact, these operations are overloaded and will work on values of
other integer types as well, even on values of type {\tt IntInf.int},
which denotes arbitrarily-sized integers.

Operations on 8-bit, 31-bit, 32-bit, 63-bit, and 64-bit unsigned words are available
in the structures
\index{Word8 structure@{\tt Word8} structure}%
{\tt Word8},
\index{Word31 structure@{\tt Word31} structure}%
{\tt Word31},
\index{Word32 structure@{\tt Word32} structure}%
{\tt Word32},
\index{Word63 structure@{\tt Word63} structure}%
{\tt Word63}, and
\index{Word64 structure@{\tt Word64} structure}%
{\tt Word64}.

Similarly as for integers, when garbage collection is enabled, the
structure {\tt Word} is identical to the structure {\tt Word63} and
values of type {\tt Word64.word} are represented boxed. Contrary,
when garbage collection is disabled, the structure {\tt Word} is
identical to the structure {\tt Word64} and values of type {\tt
  Word64.word} are represented unboxed.

\section{Reals}
The
\index{initial basis}%
initial basis provides the following top-level operations on reals:
\index{=@\texttt{=}}%
\index{<>@\texttt{<>}}%
\index{<@\texttt{<}}%
\index{>@\texttt{>}}%
\index{<=@\texttt{<=}}%
\index{>=@\texttt{>=}}%
\index{+@\texttt{+}}%
\index{-@\texttt{-}}%
\index{*@\texttt{*}}%
\index{/@\texttt{/}}%
\index{~@\verb+~+}%
\index{abs@\texttt{abs}}%
\index{real@\texttt{real}}%
\index{trunc@\texttt{trunc}}%
\index{floor@\texttt{floor}}%
\index{ceil@\texttt{ceil}}%
\index{round@\texttt{round}}%
\begin{verbatim}
  infix  4 < > <= >=
  infix  6 + -
  infix  7  * /
  val ~ : real -> real
  val abs: real -> real
  val real: int -> real
  val trunc : real -> int
  val floor : real -> int
  val ceil : real -> int
  val round : real -> int
\end{verbatim}
Values of type {\tt real} are implemented as 64-bit floating point
numbers.  They are always boxed when they appear in data structures, that is, they are each represented as a pointer to
a 64-bit
\index{alignment}%
word, which reside in a region of runtime type {\sc top\_rt}.

A real constant $c$ in the source program is translated into an
expression of the form
\index{at@\texttt{at}}%
$c\at\rho$, where $\rho$ is a region variable, indicating the region
into which the real will be stored.

The structures {\tt Real} and {\tt Math} provide other useful
operations on reals.\footnote{Consult the files {\tt
    basis/REAL.sml} and {\tt basis/MATH.sml}.}

The MLKit will do its best to eliminate regions holding reals by
unboxing reals and representing them in floating point registers or on
the runtime stack.

\section{Characters and Strings}
The
\index{initial basis}%
initial basis provides the following top-level operations on characters and strings:
\index{=@\texttt{=}}%
\index{^@\verb+^+}%
\index{ord@\texttt{ord}}%
\index{chr@\texttt{chr}}%
\index{str@\texttt{str}}%
\index{size@\texttt{size}}%
\index{explode@\texttt{explode}}%
\index{implode@\texttt{implode}}%
\index{concat@\texttt{concat}}%
\index{substring@\texttt{substring}}%
\begin{verbatim}
  infix  4 =
  infix  6 ^
  val ord: char -> int
  val chr: int -> char
  val str: char -> string
  val size: string -> int
  val explode: string -> char list
  val implode: char list -> string
  val ^ : string * string -> string
  val concat: string list -> string
  val substring: string * int * int -> string
\end{verbatim}
Characters are represented as 64-bit words, although only 8 bits are
used to store the character. Characters are always unboxed, also when
garbage collection is enabled.

A string is represented by a 64-bit pointer into an infinite region. A
string is stored in a region page if it fits in the page; otherwise,
it is allocated using {\tt malloc} and linked with the region so that
it can be {\tt free}ed when the region is deallocated. The internal
string representation is completely transparent to the programmer, who
does not have to worry about the actual size of region
pages. Characters of a string takes up only 8 bits of memory each. The
size of a string is kept along with the characters that make up the
string. For compatibility with many C routines, the character sequence
is null-terminated.

Calls of {\tt ord}, {\tt chr}, {\tt str}, and {\tt size} take constant
time and space.  Calls of {\tt explode}, {\tt implode}, {\tt concat},
{\tt substring}, and \verb+^+ take time and space proportional to the
sum of the size of their input and their output.

The string and character operations can raise exceptions, as detailed in the
Standard ML Basis Library documentation.

The structures {\tt Char}, {\tt String}, {\tt CharVector}, {\tt Byte},
and {\tt StringCvt} provide other useful operations on characters and
strings.\footnote{Consult {\tt basis/CHAR.sml}, {\tt
    basis/STRING.sml}, {\tt basis/MONO\_VECTOR.sml}, {\tt
    basis/BYTE.sig} and {\tt basis/STRING\_CVT.sml}.}

\section{Booleans}
The boolean values {\tt true} and {\tt false} are represented as
64-bit words, although only one bit is used to denote the value.
Booleans are unboxed. The
\index{initial basis}%
initial basis provides the following top-level operations on
booleans:
\index{=@\texttt{=}}%
\index{not@\texttt{not}}%
\begin{verbatim}
  infix 4 =
  val not: bool -> bool
\end{verbatim}
The structure {\tt Bool} provides other useful operations on
booleans.\footnote{Consult the file {\tt basis/BOOL.sig}.}

%---------------------------------------------------------
\chapter{Lists}
\label{lists.sec}\index{list}
%---------------------------------------------------------
Section~\ref{lsyn.sec} gives a summary of the list concept in Standard
ML, introduces the notion of the \emph{auxiliary pairs} of a list and
presents the syntax of constructors and de-constructors in the
intermediate languages.  Section~\ref{listtypes.sec} introduces
region-annotated list types and show how they correspond to the layout
of lists in memory.  Section~\ref{listexamples.sec} gives a small
example.

\section{Syntax}
\label{lsyn.sec}
In Standard ML, all lists are constructed
from the two constructors
\index{::@\texttt{::}}%
\boxml{::} (read: cons) and
\index{nil@\texttt{nil}}%
{\tt nil}.  As a shorthand, one can write
$\boxml{[}\exp_1\boxml{,}\cdots \boxml{,}\exp_n\boxml{]}$ for
$$ \exp_1\boxml{::}\; \cdots\; \boxml{::} \exp_n\boxml{::}\boxml{nil}$$
which in turn is short for
$$
\boxml{op ::($\exp_1$, $\cdots$, op ::($\exp_n$,nil)$\cdots$)}$$
where $\exp$ ranges over expressions.  The type schemes of {\tt nil}
and {\tt cons} are
$$\boxml{nil}\mapsto\forall\alpha.\alpha\,\boxml{list}\qquad
\boxml{::} \mapsto\forall\alpha.\alpha\ast\alpha\,\boxml{list}\to\alpha\,\boxml{list}
$$
Notice that {\tt ::} is always applied to a pair. The construction
of the pair and the application of {\tt ::} should, in principle, not
be confused: the pair and the constructed value are in principle
separate values inasmuch as they have different type.  For example,
the declaration
\begin{verbatim}
  val p = (2, nil)
  val mylist = (op ::) p
  val n = #1 p
\end{verbatim}
is legal in Standard ML. We refer to the pairs to which {\tt ::} is
applied as
\index{pair!auxiliary}%
{\em auxiliary pairs (of the list data type)}.

Decomposition of list values in Standard ML is done by
\index{pattern matching}%
pattern matching.  A pattern can extract the pair to which {\tt ::} is
applied. Pattern matching on pairs can then give access to the
components of the pair.
\begin{verbatim}
  val abc = ["a", "b", "c"]
  val op :: p = abc    (* binds p to the pair ("a", ["b","c"]) *)
  val (x::y::_) = abc  (* binds x to "a" and y to "b" *)
\end{verbatim}
In the last declaration, the pattern \boxml{(x::y::\_)} is short for
the pattern
$$\boxml{(op ::(x, op ::(y, \_)))}$$
which combines decomposition of
constructed values with decomposition of pairs.

The intermediate languages $\Lam$, $\RegExp$, and $\MulExp$ have
SML-like constructs for applying constructors, but they decompose
constructed values by applying a
\index{decon@\texttt{decon}}%
de-constructor primitive, not by pattern
matching.
\index{at@\texttt{at}}%
\begin{center}
\begin{tabular}{|c|c|}\hline
$\Lam$, $\RegExp$, or $\MulExp$ & \\ \hline
\boxml{nil}   &  create {\tt nil} value \\
$\boxml{::}\,(e)$ & create {\tt ::} (cons) value \\
$\boxml{decon\_::}\,(e)$ & cons decomposition \\
\hline
\end{tabular}
\end{center}
In $\Lam$, which has essentially the same type system as SML,
$\boxml{decon\_::}$, the decomposition function for {\tt ::}, has type
$\forall\alpha.\alpha\,\boxml{list}\to\alpha\ast\alpha\,\boxml{list}$.
In addition, $\Lam$, $\RegExp$, and $\MulExp$ have a simple case
construct:
$$\boxml{(case $e$ of :: => $e_1$ | \_ => $e_2$)}$$
where $e$ must have list type.

\section{Physical Representation}
\label{ublists.sec}
The empty list is represented by an odd, unboxed integer.  A non-empty
list is represented as a pointer to a pair of two words in a region,
the first of which contains the head of the list and the second of
which contains the representation of the tail of the list. In other
words, the physical representation does not distinguish a {\tt ::}
cell from the auxiliary pair to which \boxml{::} is applied. Since
\boxml{nil} is represented by an odd number and since word addresses
are always even, \boxml{nil} can be distinguished from the
representation of a non-empty list.

As a consequence, there is no cost involved in applying \boxml{::} to
an auxiliary pair or in applying the decomposition operator
\boxml{decon\_::} to a non-empty list.

\section{Region-Annotated List Types}
\label{listtypes.sec}
In Standard ML, all elements of a given list must have the same type.
We extend this constraint to region inference by saying that all
element values in the same list must reside in the same region(s) and that all
auxiliary pairs of the same list must reside in the same region.
\begin{figure}
\hrule

\begin{center}
\begin{picture}(75,35)(0,0)
\put(0,0){\framebox(30,10){\boxml{"a"}}}
\put(0,10){\framebox(30,10){\boxml{"b"}}}
\put(0,20){\framebox(30,10){\boxml{"c"}}}
%
\put(40,0){\framebox(30,10){$(\qquad,\boxml{nil})$}}
\put(40,10){\framebox(30,10){$(\qquad,\boxml{::})$}}
\put(40,20){\framebox(30,10){$(\qquad,\boxml{::})$}}
%
\put(50,5){\vector(-1,1){20}}
\put(50,15){\vector(-1,0){20}}
\put(50,25){\vector(-1,-1){20}}
%
\put(60,15){\line(3,0){15}}
\put(60,25){\line(3,0){15}}
%
\put(75,15){\line(0,-1){7}}
\put(75,25){\line(0,-1){7}}
%
\put(75,18){\vector(-1,0){5}}
\put(75,8){\vector(-1,0){5}}
%
\put(15,-5){\hbox{$\rho_1$}}
\put(55,-5){\hbox{$\rho_2$}}
\end{picture}
\end{center}
\caption{Layout of the list
  $\boxml{["a","b","c"]}:((\boxml{string},\rho_1),[\rho_2])\boxml{list}$
  in memory. The auxiliary pairs of the list reside in $\rho_2$.  Each
  auxiliary pair takes up two words; the constructors {\tt ::} (cons)
  and {\tt nil} are represented unboxed.}  \medskip

\hrule
\label{listregions.fig}
\end{figure}

Thus, region inference does not distinguish between a list and its
\index{list!tail}%
\index{list!auxiliary pairs}%
\index{auxiliary pairs}%
tail.  Indeed, a typical use of an infinite region is to hold all the
auxiliary pairs of a list. For an example,
Figure~\ref{listregions.fig} shows how the list \boxml{["a","b","c"]}
is laid out in memory.

In general, the
\index{type!region-annotated}%
\index{list!region-annotated type}%
region-annotated type of a list takes the form
$$(\mu,[\rho])\boxml{list}$$
where $\mu$ is the region-annotated
type with place of the members of the list and where $\rho$ is the region where
the auxiliary pairs of the list are stored.  For example, the region-annotated type
$$((\boxml{string},\rho_1),[\rho_2])\boxml{list}$$
classifies lists
that have their auxiliary pairs in a region $\rho_2$ and strings in a
region $\rho_1$.

Notice that the \boxml{list} type constructor is not paired with a
region variable.  The reason is that the physical representation of
lists treats the constructors as unboxed in the sense described in
Section~\ref{ublists.sec}.

Very importantly, not all lists need to live in the same regions.
Formally, {\tt nil} and {\tt ::} have the following region-annotated
type schemes:
\begin{eqnarray*}
\boxml{nil} & \mapsto & \forall\alpha\rho.(\alpha,[\rho])\boxml{list}\\
\boxml{::}  & \mapsto & \forall\alpha\rho\epsilon.(\alpha\ast(\alpha,[\rho])\boxml{list},\rho)
\ar{\epsilon.\emptyset} (\alpha,[\rho])\boxml{list}
\end{eqnarray*}
Despite its verbosity, the type scheme for {\tt ::} deserves careful
study. It is polymorphic not just in types (signified by the bound
type variable $\alpha$) but also in the region signified by the bound
region variables $\rho$, and, in the case of \texttt{::}, in the effect signified by the
\index{effect variable}%
\emph{effect variable} $\epsilon$.
The $\epsilon.\emptyset$ appearing on the function arrow is called an
\index{arrow effect}%
{\em arrow effect}.  Occurring in a function type, an arrow effect
describes the effect of applying the function.  In this case, the
effect is empty, as only unboxed values are manipulated by {\tt ::}.
The effect variable $\epsilon$ is used for expressing dependencies
between effects (examples follow in Chapter~\ref{hof.sec}). Due to the
fact that the variables are universally quantified, every occurrence
of a list can, potentially, be in its own regions. But notice that the
type of {\tt ::} forces the element, which is consed onto the list, to
be in the same regions as the already existing elements of the list.
Similarly, the type forces the auxiliary pairs to be in one region
($\rho$).

\section{Example: Basic List Operations}
\label{listexamples.sec}
The MLKit compiles the program\footnote{Program \texttt{kitdemo/onetwothree.sml}.}
\begin{verbatim}
  let val l = [1, 2, 3];
      val (x::_) = l
  in x end
\end{verbatim} 
into the $\RegExp$ program shown in Figure~\ref{listprint.fig}.
\begin{figure}
\hrule \medskip
\begin{verbatim}
   let val it =
         let region r9:INF;
             val l = [1,2,3] at r9
         in  case l of :: => let val v91 = decon_:: l
                             in #0 v91
                             end
                | _ => raise Bind
         end
   in  {|it: _|}
   end
\end{verbatim}
\caption{Example showing construction and de-construction of a small list.
Layout of the list {\tt l} is analogous to Figure~\ref{listregions.fig}.
The infinite region {\tt r9} holds the auxiliary pairs of the list.
}
\label{listprint.fig}
\medskip

\hrule
\end{figure}


%---------------------------------------------------------
\chapter{First-Order Functions}
%---------------------------------------------------------
In this chapter, we shall treat
\index{function}%
\index{function!first-order}%
functions that are declared with
%\index{fun@\texttt{fun}}
{\tt fun} and that are first-order (i.e., that neither take functions
as arguments nor produce functions as results). Higher-order functions
are treated in Chapter~\ref{hof.sec}.  Region polymorphism works
uniformly over all types; we use lists as an example of the general
scheme.

\section{Region-Polymorphic Functions}
\label{region-polymorphic-functions.sec}
\index{region polymorphism|(}%
It would be a serious limitation if all lists produced by a series of
calls to a function were stored in the same region, for then all those
lists would have to be kept alive till the last time one of them were
used. The solution that the MLKit offers to this problem is {\em
  region-polymorphic functions}, that is, functions that are passed
regions at runtime.

When one declares a function that, when called, produces a fresh list,
then the region inference algorithm will automatically insert extra
\index{region parameter!formal}%
formal region parameters in the function declaration.  At every place
one refers to the function, for example because one calls the
function, the region inference algorithm inserts
\index{region parameter!actual}%
actual region parameters that tell the function where to put its
result. This is all done automatically; the user does not have to
introduce region parameters or pass them as arguments. Even so, it is
useful to understand the general principle, so that one can make good
use of region polymorphism.

The syntax of a (single) function declaration in $\MulExp$ is:
\begin{tabbing}
\ \ \ \ \ \=\tt fun $f$ $\at\,\rho_0$ [$\rho_1$, $\cdots$, $\rho_k$] ($x_1,\cdots,x_n$) = $e$
\end{tabbing}
Here $\rho_0$ denotes the region in which the closure for $f$ is
stored, $\rho_1, \ldots,\rho_k$ are the
\index{region parameter!formal}%
{\em formal region parameters}, $x_1,\cdots,x_n$ are
value parameters, and $e$ is the body of the function.
A call to $f$ takes the form
\begin{tabbing}
\ \ \ \ \ \=\tt $f$  [$\rho_1'$, $\cdots$, $\rho_k'$] <$e_1',\cdots,e_n'$>
\end{tabbing}
where \boxml{[$\rho_1'$, $\cdots$, $\rho_k'$]} are
\index{region parameter!actual}%
{\em actual region parameters} and $e_1',\cdots,e_n'$ are expressions
denoting the arguments to the call. Notice that region parameters are
enclosed in brackets (\boxml{[ ]}); this should not cause confusion
with ML lists, because $\RegExp$ and $\MulExp$ do not use
\index{[ ]@\texttt{[ ]}}%
brackets for lists. In the special case $k=0$, no region parameters
are passed to the function, and we shall often omit the brackets in
this case.

Also notice that, unlike for Standard ML, functions are allowed to be
passed multiple value arguments; see below. In the case $n=1$, we
often omit the surrounding brackets $\verb+<+ \cdots \verb+>+$.

In the special case $k=0$, no region parameters are passed to the
function, and we shall often omit the brackets in this case.

Different calls of $f$ can use different actual regions; this feature
is essential for obtaining good separation of lifetimes.  For an
example, consider the following program:
\begin{verbatim}
  fun fromto(a, b) = if a>b then []
                     else a :: fromto(a+1, b)
  val l = #1(fromto(1,10), fromto(100,110));
\end{verbatim}
The corresponding $\MulExp$ program is shown in
Figure~\ref{fromto.fig}.
\begin{figure}[htb]
\hrule
\medskip
\begin{verbatim}
   let fun fromto at r1 [r14:INF] (v93, v94) =
           case v93 > v94 of
              true => nil
            | _ => :: (v93, fromto[r14] <v93 + 1, v94>)at r14;
       val l = let region r24:INF, r28:1
               in #0 (fromto[r4] <1, 10>,
                      fromto[r24] <100, 110>)at r28
               end
   in  {|fromto: (_,r1), l: _|}
   end
\end{verbatim}
\caption{The region-annotated version of {\tt fromto} shows that {\tt fromto}
  is region-polymorphic. (Program: \boxml{kitdemo/fromto.sml}, printed
  by passing the option {\tt -print\_drop\_regions\_expression} to the
  MLKit compiler.)}  \medskip

\hrule
\label{fromto.fig}
\end{figure}

There are several things to notice about the region annotated program.
First, notice that the function {\tt fromto} represents its argument
\boxml{(a,b)}
\index{arguments!multiple}%
\index{multiple function arguments}%
\index{function arguments!multiple}%
unboxed; the MLKit figures out that the function does not
use the boxed representation of the argument and transforms all calls
to the function to pass the argument unboxed (on the runtime stack and
in registers if possible).

Second, notice that \boxml{r14} is a formal region parameter of {\tt
  fromto} and that \boxml{r14} is passed along in the recursive call
\boxml{fromto[r14] <v93 + 1, v94>}. Here the notation \boxml{<v93 + 1, v94>}
denotes the passing of the unboxed record to the function {\tt
  fromto}.

\index{fromto@\texttt{fromto}}%
Finally, notice that the regions that hold the two lists generated by
this program are distinct.  The list that escapes to top level is
stored in the global region {\tt r4}, whereas the list that does not
escape is stored in the local region {\tt r24}.

\section{Region-Annotated Type Schemes}
\label{regtych.sec}
A
\index{type scheme!region-annotated}%
\index{region-annotated type scheme}%
{\em (region-annotated) type scheme\/} takes the form
$$\sigma::=\lsigma$$
where $\alpha_1,\ldots,\alpha_n$ are type variables,
$\rho_1,\ldots,\rho_k$ are region variables,
$\epsilon_1,\ldots,\epsilon_m$ are
\index{effect variable!bound}%
effect variables, and $\tau$ is a region-annotated type.

The types of \boxml{nil} and \boxml{::} in Section~\ref{listtypes.sec} are examples of
\index{region polymorphism}%
region-annotated type schemes.

There is a close connection between, on the one hand, the formal and
actual
\index{region parameter}%
region parameters found in $\RegExp$ (and $\MulExp$) programs, and, on
the other hand, the region-annotated type schemes that the region inference
algorithm assigns to recursively declared functions. The formal region
parameters of a function stem from the bound region variables of the
region-annotated type scheme of that function.  The actual region parameters
which annotate a call of the function are the region variables to
which the bound region variables are instantiated at that particular
application.

For example, the region-annotated type scheme of {\tt fromto} from
Figure~\ref{fromto.fig} is
$$\forall\rho_{14}\epsilon. [\boxml{int}, \boxml{int} ]
\ar{\epsilon.\{\Put(\rho_{14})\}} (\boxml{int},[\rho_{14}])\boxml{list}$$
where we use the syntax $[\tau_1, \ldots, \tau_n], n \geq 1$ to denote
an unboxed tuple of types $\tau_1, \ldots,\tau_n$. This syntax is not
to be confused with the auxiliary region variables of type
constructors (e.g., the list $[\rho_{14}]$ in the region-annotated type
scheme of {\tt fromto}.)

At the last call of {\tt fromto} in Figure~\ref{fromto.fig},
the type scheme is instantiated to the region-annotated type
$$[\boxml{int}, \boxml{int}] \ar{\epsilon'.\{\Put(\rho_{24})\}}
(\boxml{int},[\rho_{24}])\boxml{list}$$

The instantiation of bound variables of the type scheme that yields
this region-annotated type is
$$\{\rho_{14}\mapsto\rho_{24}, \epsilon\mapsto\epsilon'\}$$
In general,
the actual region parameters that annotate a call of a
region-polymorphic function are obtained from the range of the
substitution by which the type scheme of the function is instantiated
at that application.

\index{type scheme with place!region-annotated}%
\index{region-annotated type scheme with place}%
Region-polymorphic functions also have to be allocated somewhere.
Therefore, the region information associated with a region-polymorphic
function is a {\em (region-annotated) type scheme with place}, that
is, a pair $(\sigma,\rho)$.  Indeed, every binding of a variable to a
boxed value (whether the binding is done by {\tt fun}, {\tt let}, or
{\tt fn}) associates a region-annotated type scheme with place to the
binding occurrence.  (In the case of {\tt let}, the type scheme will
have no quantified region and effect variables, however, and in the
case of {\tt fn}, the type scheme will have no quantified variables at
all.)  In the following, when we refer to ``the region-annotated type
(scheme) with place'' of some variable, we mean the region-annotated
type (scheme) with place that is associated with the binding
occurrence of the variable. The region type scheme should be clearly
distinguished from instances of the type scheme, which decorate
non-binding occurrences of the variable.

The region-annotated type scheme with place of a variable bound to an
unboxed value is always on the form $\sigma$ (no specified place), where
$\sigma$ is the region-annotated type scheme associated with the
variable (see Section~\ref{reganntypes.sec}).

\section{Endomorphisms and Exomorphisms}
The {\tt fromto} function from Section~\ref{regtych.sec} has the
property that it can put its result in regions that are separate from
the regions where its argument lies. This is not surprising, if one
looks at the declaration of the function; it creates a brand new list
that does not share with the argument {\tt (a,b)}, except for the
integers {\tt a} and {\tt b}, which may end up in the list.  The
freshness of the generated list is evident from the region type scheme
of the function; the region variable in the result type does not
appear in the argument type.

Not all region-polymorphic functions create brand new values. Very
often, a region-polymorphic function simply adds values to regions
that are determined by the argument to the function. A good example is
the list append function from the initial basis:\footnote{File {\tt
    kitdemo/append.sml}.}
\begin{verbatim}
  infixr 5 @
  fun [] @ ys = ys
    | (x::xs) @ ys = x :: (xs @ ys)
  val l = [1] @ [2,3]
\end{verbatim}
Append successively conses the elements of the first list onto the
second list.  Thus, \boxml{ys} and \boxml{xs @ ys} must be in the same
regions. However, the auxiliary pairs of \boxml{xs} and \boxml{ys}
need not be in the same regions, although the elements of \boxml{xs}
and \boxml{ys} clearly must be in the same regions, because they end
up in the same list. These properties of the append function \boxml{@}
are summarized in its inferred region-annotated type scheme:
$$\begin{array}{c}\forall\alpha\rho_{15}\rho_{16}\epsilon.
   [ (\alpha,[\rho_{16}])\boxml{list},
      (\alpha,[\rho_{15}])\boxml{list} ]
\ar{\epsilon.\{\Get(\rho_{16}),\Put(\rho_{15})\}} (\alpha,[\rho_{15}])\boxml{list}\end{array}
$$
When one writes a function it is a good idea to consider whether one
wants the function to create values in fresh regions or whether one
wants it to add values to existing regions.  Adding to existing
regions can of course make these regions too large and long-lived,
because the entire region will be alive for as long as one of the
values in the region may be needed in the future.

\begin{figure}[htb]
\hrule
\medskip
\begin{verbatim}
   let fun @ at r1 [r15:INF] (v96, v129) =
           case v96 of
             nil => v129
           | _ =>
             let val v98 = decon_:: v96;
                 val v99 = #0 v98;
                 val v100 = #1 v98
             in  :: (v99, @[r15] <v100, v129>)at r15
             end;
       val l = let region r27:INF
               in @[r4] <[1] at r27, [2,3] at r4>
               end
   in  {|@: (_,r1), l: _|}
   end
\end{verbatim}
\caption{The region-annotated version of {\tt append}.}
\medskip
\hrule
\label{append.fig}
\end{figure}

The MulExp version of the append function is listed in
Figure~\ref{append.fig}. At the application of \boxml{@}, the region
annotated type scheme for \boxml{@} is instantiated to the region annotated type
$$[ (\boxml{int},[\rho_{27}])\boxml{list},
      (\boxml{int},[\rho_4])\boxml{list} ]
\ar{\epsilon'.\{\Get(\rho_{27}),\Put(\rho_4)\}} (\boxml{int},[\rho_4])\boxml{list} $$

To avoid passing regions that are never used, the MLKit introduces only
formal region variables for those bound region variables in the type
scheme for which there appears at least one
\index{put@{$\Put$}}%
$\Put$ effect in the type of the function.  Reading a value is done
simply by following a pointer to the value, irrespective of what
region the value resides in, whereas storing a value in a region uses
the name (see Section~\ref{fininf.sec}) of the region.  This omitting
of region parameters explains why $\rho_{16}$ does not become a formal
region parameter of \boxml{@} and why $\rho_{27}$ is not passed to
\boxml{@} at the call site. This optimisation, which is called
\index{region!dropping of}%
{\em dropping of regions}, is the key reason why the MLKit takes the
trouble to distinguish between $\Put$ and
\index{get@{$\Get$}}%
$\Get$ \label{bother-to-distinguish-get-n-put}effects.

Here are two more examples to highlight the difference between
functions that can put values in fresh regions and functions that add
values to existing regions:
\begin{verbatim}
  fun cp1 [] = []
    | cp1 (x::xs) = x :: cp1 xs
  fun cp2 (l as []) = l
    | cp2 (x::xs) = x :: cp2 xs
\end{verbatim}
Here \boxml{cp1} can copy the auxiliary pairs of a list into a fresh
region, whereas \boxml{cp2} always copies the auxiliary pairs of a
list into the same region:
\begin{eqnarray*}
\boxml{cp1}&\mapsto&\forall\alpha\rho\rho'\epsilon.
     (\alpha,[\rho])\boxml{list} \ar{\epsilon.\{\Get(\rho),
           \Put(\rho')\}} (\alpha,[\rho'])\boxml{list}\\
\boxml{cp2}&\mapsto&\forall\alpha\rho\epsilon.
     (\alpha,[\rho])\boxml{list} \ar{\epsilon.\{\Get(\rho),
           \Put(\rho)\}} (\alpha,[\rho])\boxml{list}
\end{eqnarray*}
As we saw in Section~\ref{life.sec}, there are cases where it is
useful to copy a list from one region into another region, so as to
make it possible to de-allocate the old region. This copying can be
used as a kind of programmer-controlled garbage collection in cases
where garbage has accumulated in the original region.

Because it is often useful to distinguish between functions that can
put their result into fresh regions and functions that simply add to
regions determined by their value argument, we shall refer informally
to the former functions as
\index{region exomorphism}%
{\em region exomorphisms} and the latter as
\index{region endomorphism}%
{\em region endomorphisms}. Notice that this is not a clear-cut
distinction, however. Often, functions have both an endomorphic and an
exomorphic side to them. Also notice that even a region exomorphic
function can be forced to act as an endomorphism by the calling
context. As an example, consider the expression
$$\boxml{if true then cp1 l else l}$$
Because the two branches of the
conditional are required to have the same region-annotated type with
place, \boxml{l} and \boxml{cp1 l} are forced to be in the same
regions.

%mael
\section{Polymorphic Recursion}

\label{polyrec.sec}
A
\index{recursion!polymorphic}%
recursive region-polymorphic function
\begin{tabbing}
\ \ \ \ \ \=\tt fun $f$ $\at\,\rho_0$ [$\rho_1$, $\cdots$, $\rho_k$] ($x_1,\cdots,x_n$) = $e$
\end{tabbing}
may call itself inside its own body ($e$) with regions that are different
from its own formal region parameter ({\tt [$\rho_1$, $\cdots$, $\rho_k$]}).
This feature is called {\it polymorphic recursion in regions}, named after
polymorphic recursion, the analogous concept for types.
Polymorphic recursion in regions is vital for achieving good
memory management in connection with recursion.
Unfortunately, it is also makes  the region inference problem considerably more
challenging, but that is a different story \cite{tofbir98}.

We now show a typical use of polymorphic recursion in regions, namely
merge sorting of lists. The basic idea of merge sort is simple: first
split the input list into two lists $l$ and $r$ of roughly equal
length.  Then sort $l$ and $r$ recursively and merge the results into
a single sorted list.  When programming with regions, we need to plan
which of these lists we want to reside in the same regions. We do not
want to waste space. In particular, if $n$ is the length of the list,
it would be quite irresponsible to use $O(n\hbox{log}\,n)$ space, say.
Let us aim at arranging that the sorting function is a region
exomorphism that does not produce any values in its result regions
except the sorted list. To sort $n$ elements, we shall need $n$ list
cells (to hold the input list) plus roughly $2\times(n/2)$ list cells
to hold $l$ and $r$, the two lists that arise from splitting the input
list. To sort $l$ recursively, we need space for the two lists
obtained by splitting $l$ and so on. The space consumption grows to a
maximum of $3n$ list cells (including the $n$ cells to hold the
input), before any merging is done.  By the time all of $l$ is sorted,
that is, just before $r$ is sorted recursively, we have the following
lists: the input ($n$ cells), $l$ ($n/2$ cells), $l$ sorted ($n/2$
cells), $r$ ($n/2$ cells). Continuing this way, at the rightmost merge
of two lists of length at most one, approximately $4n$ list cells are
live.  Then a series of final merges occur.  Code that uses these
ideas is listed in
\index{cp@\texttt{cp}}%
\index{msort@\texttt{msort}}%
\index{merge sort}%
\index{projects!compiling}%
\index{projects!running}%
Figure~\ref{msort.fig}.\footnote{MLB-file {\tt kitdemo/msort.mlb}, file
  {\tt kitdemo/msort.sml}. To compile the project, go to the
  \boxml{kitdemo} directory and execute \boxml{"mlkit msort.mlb"} from
  the shell. The MLKit places an executable file \boxml{run} in the
  \boxml{kitdemo} directory. For an in-depth description of how to
  compile and run MLB-files and SML-files, see
  Chapter~\ref{mlb_and_modules.chap}.}
\begin{figure}[hbt]
\hrule
\medskip
\begin{verbatim}
  fun cp [] =[]
    | cp (x::xs)= x :: cp xs

  (* exomorphic merge *)
  fun merge(xs, []):int list = cp xs
    | merge([], ys) = cp ys
    | merge(l1 as x::xs, l2 as y::ys) =
          if x<y then x :: merge(xs, l2)
          else y :: merge(l1, ys)

  (* splitting a list *)
  fun split(x::y::zs, l, r) = split(zs, x::l, y::r)
    | split([x], l, r) = (x::l, r)
    | split([], l, r) = (l, r)

  (* exomorphic merge sort *)
  fun msort []  = []
    | msort [x] = [x]
    | msort xs = let val (l, r) = split(xs, [], [])
                 in merge(msort l, msort r)
                 end;
\end{verbatim}
\caption{Merge sorting of lists.}
\label{msort.fig}
\medskip\hrule
\end{figure}

The exomorphic merge function is a bit inefficient in that it copies
one argument when the other is empty, but the exomorphism ensures that
$\boxml{msort l}$ and $\boxml{msort r}$ are not forced into the same
regions. The polymorphic recursion in regions makes it possible for
\boxml{xs}, \boxml{l}, \boxml{r}, \boxml{msort l}, and \boxml{msort r}
all to be in distinct regions. For example, in the call \boxml{msort
  l}, the polymorphic recursion makes it possible for \boxml{l} to be
in a region different from \boxml{xs} and it also makes it possible for
the result of the call to be in a region different from the result of
\boxml{msort xs}.

Based on the above analysis we conclude that the space required by
\boxml{msort xs} is approximately $4nc_1+c_2{\rm log}_2n$ plus the extra
stack space required for the final merges, where $n$ is
the length of \boxml{xs}, $c_1$ is the size of a list cell (2 words in this
case) and $c_2$ is the space on the runtime stack used by one recursive call
of {\tt msort} (probably less than 10 words).

Because \boxml{merge} is not tail-recursive, a merge requires space
both for its two input lists, for its output list, and for temporaries stored on the stack.  When one of the
lists becomes empty, \boxml{merge} calls \boxml{cp}, which allocates
less for each iterative call than \boxml{merge} does. Each return from
\boxml{merge} allocates a list cell (two words), so the maximum space
usage is reached when the last element of the result of the merge is
constructed (which happens when the recursion is deepest). Here the
space used is (we show $n = 200,000$ list elements as an example)
\begin{center}
\begin{tabular}{lrr}
{\bf data} & {\bf size (words)} &$n=200,000$\\
input list& $2n$ & 3,200,000 bytes\\
$l$ & $n$ & 1,600,000 bytes\\
$l$ sorted & $n$ & 1,600,000 bytes\\
$r$ & $n$ & 1,600,000 bytes\\
$r$ sorted & $n$ & 1,600,000 bytes\\
result list & $2n$ & 3,200,000 bytes\\ \hline
total in regions& $8n$ & 12,800,000 bytes
\end{tabular}
\end{center}

It turns out that each iterative call of \boxml{merge} pushes three
registers on the stack, so that stack size will be approximately
$3\times 8\times n$ bytes, which for $n=200,000$ is 4,800,000 bytes,
just before the merged list is constructed, bottom-up. The total space
consumption for sorting 50,000 integers should therefore be roughly
14,400,000 bytes (i.e., 12,800,000-3,200,000+4,800,000).

To check the above analysis, we sorted 200,000 integers with the region
profiler enabled.  As one sees in Figures~\ref{msortregion.fig} and
\ref{msortstack.fig}, the space usage found by region profiling
correspond well to the results of our analysis.
\begin{figure}%[t]
\includerp{msortregion.pdf}
\caption{Region profiling of {\tt msort} sorting 200,000 integers. The
  high-level mark denotes the maximum amount of memory allocated in
  regions and on the stack. Notice that the amount of memory used in
  regions and the amount of memory used on the stack may not top on
  the same time, which shows by the high-level mark being lower than
  the sum of the maximum stack usage and the maximum memory used in
  regions.}
\label{msortregion.fig}
\end{figure}

\begin{figure}%[t]
\includerp{msortstack.pdf}
\caption{Stack profiling of {\tt msort} sorting 200,000 integers.}
\label{msortstack.fig}
\end{figure}

In Chapter~\ref{storagemodes.sec}, we shall see how one can use
resetting of regions to reduce the space usage drastically, to roughly
$2nc_1$.
\index{region polymorphism|)}%

%---------------------------------------------------------
\chapter{Value Declarations}
\label{valdecl.sec}
%---------------------------------------------------------

Although region inference is based on types and effects, it is also to
some extent syntax dependent. That is, two programs that are
equivalent in their input-output behavior can easily have very
different memory behavior. In this chapter, we discuss how to write
\index{declaration!value}%
declarations so as to obtain good results with region inference. The
region inference rules that underlie the MLKit with Regions are
related to the scope rules of ML, so we start by a (very informal)
summary of the scope rules of ML declarations.

\section{Syntax}
A Standard ML {\em value declaration} binds a value to a value
\index{scope rules|(}%
variable. For example, the result of evaluating the value declaration
\begin{verbatim}
  val x = 3 + 4
\end{verbatim}
is the
\index{environment}%
environment $\{\boxml{x}\mapsto 7\}$. More generally, evaluation of a
value binding \boxml{val $\id$ = $\exp$} proceeds as follows. Assume
the result of evaluating $\exp$ is a value, $v$.  Then the result of
evaluating \boxml{val $\id$ = $\exp$} is the environment $\{\id\mapsto
v\}$.

The value declaration is just one form of Core Language declaration
(the others being type and exception declarations). We use $\dec$ to
range over declarations. Declarations can be
combined in several ways. For example,
\index{declaration!sequential}%
$$\dec_1\boxml{;}\dec_2$$
is a {\em sequential declaration}. The
identifiers declared by this declaration are the identifiers that are
declared by $\dec_1$ or $\dec_2$; moreover, identifiers declared in
$\dec_1$ may be referenced in $\dec_2$. The
\index{;@\texttt{;}}%
semicolon is associative. Thus, in a sequence
$\dec_1\boxml{;}\ldots\boxml{;}\dec_n$ of declarations, identifiers
declared in $\dec_i$ may be referenced in $\dec_{i+1},\ldots ,\dec_n$
($1\leq i\leq n$).

The Core Language has two forms of
\index{declaration!local}%
\index{let@\texttt{let}}%
local declarations. The expression
$$\boxml{let $\dec$ in $\exp$ end}$$
declares identifiers whose scope
does not extend beyond $\exp$. Similarly, the declaration
\index{local@\texttt{local}}%
$$\boxml{local $\dec_1$ in $\dec_2$ end}$$
first declares identifiers
(in $\dec_1$) whose scope does not extend beyond $\dec_2$ and then
uses these declarations to perform the declarations in $\dec_2$. An
identifier is declared by the entire local construct if and only if it
is declared by $\dec_2$.

%\section{On the Relationship between Scope and Lifetime}
%changed to make title a one-liner
\section{Scope Versus Lifetime}
\label{scope.sec}
Scope
\index{lifetime|(}%
is a syntactic concept: a declaration of an identifier contains a
binding occurrence of the identifier; the scope of the declaration is
the part of the ensuing program text whose free occurrences of that
identifier are bound by that binding occurrence. By contrast,
lifetime, as we use the word, is a dynamic concept. A value is
``live'' if and only if the remainder of the computation uses it (or
part of it). The traditional
\index{stack}%
stack discipline couples these two concepts very closely. For example,
in the pure stack discipline, the evaluation of
$$\boxml{let $\dec$ in $\exp$ end}$$
in an environment $E$ proceeds as
follows. First evaluate $\dec$ to yield an environment, $E_1$. Then
evaluate $\exp$, in the environment $E$ extended with $E_1$, to yield
value $v$. Then $v$ is the result of evaluating the {\tt let}
expression in $E$. In implementation terms: first push an environment
$E_1$ onto the stack, use it to evaluate the expression in the scope
of the declaration, and then pop the stack. That this idea works in
\index{block structure}%
block-structured languages hinges on a number of carefully made
language design decisions. In functional and object-oriented
languages, memory cannot be managed that simply. The problem is that
while environments can be managed in a stack-like manner, the values
in the range of the environment cannot (unless one uses regions, that
is). For example consider the ML expression:
\begin{verbatim}
  local
     val private = [2,3,5,7,11,13]
  in
     fun smallPrime(n:int): bool =
            List.member n private
  end
\end{verbatim}

Although the scope of the declaration is only the declaration of
\index{smallPrime@\texttt{smallPrime}}%
{\tt smallPrime}, {\tt private} is accessed (at runtime) whenever {\tt
  smallPrime} is called.  Thus, the lifetime of the list of small
primes is at least as long as the lifetime of the {\tt smallPrime}
function itself.

The region discipline still has a coupling between scope and
lifetimes, but, because we want to be able to handle recursive data
types and higher-order functions, the coupling is less tight.  The
ground rule of region inference
\index{region inference!ground rule}%
\index{let region@\texttt{let region}}%
is that as long as a value variable is in scope, the value bound to it
at runtime will remain allocated. More precisely:
\begin{quote}
  Ground Rule: The region rules forbid transforming an expression
  $\exp$ into \boxml{let region $\rho$ in $\exp$ end} if $\exp$ is in
  the scope of an identifier that has $\rho$ free in its
  region-annotated type scheme with place.
\end{quote}
For an example, consider
\begin{verbatim}
  let
     val list = [1,2,3]
     val n = length list
     val r = sin(real n)
  in
     cos(r)
  end
\end{verbatim} 
At runtime, the list bound to {\tt list} is not used (i.e., it is not
live) after its length has been computed; similarly, the value of {\tt
  n} is not live after it has been converted to a floating point
number, and so on. In short, at runtime, we have a sequence of short,
non-overlapping lifetimes.

With region inference, however, the list bound to {\tt list} will stay
allocated throughout the evaluation of the remainder of the {\tt let}
expression.\footnote{One can force de-allocation of the list by
  inserting $\boxml{val \_ = \resetr(list)}$ after the declaration of
  {\tt n}; but, as we shall see, there are less draconian ways of
  achieving the same result.}

For a more interesting example of the consequences of the Ground Rule,
consider the following declarations, taken from a program that
computes prime numbers using the
\index{Sieve of Eratosthenes}%
Sieve of Eratosthenes:
\begin{verbatim}
  fun cp [] = []
    | cp (x::xs) = x :: cp xs

  fun sift (n, []) = []
    | sift (n, (x::xs)) = if x mod n = 0 then sift(n,xs)
                          else x::sift(n,xs)
  fun sieve(a as ([], p)) = a
    | sieve(x::xs, p) = let val rest = sift(x,xs)
                        in sieve(cp rest,x::p)
                        end
\end{verbatim}
Here {\tt sift(n, l)} produces a list of the numbers from {\tt l} that
are not divisible by \boxml{n}; {\tt sieve(xs, p)} repeatedly calls
{\tt sift}, adding primes to the front of {\tt p}, until the list of
numbers remaining in the sieve becomes empty. The programmer has
employed the copying technique suggested in Section~\ref{life.sec} to
avoid that the lists that are bound to {\tt rest} during the repeated
filtering all are put in the same region. The programmer's intention
is that the {\tt cp rest} should overwrite {\tt x::xs} by a copy of
{\tt rest}, so that space consumption would be bounded by a constant
times the size of the input.  But it does not work as intended;
because {\tt rest} is in scope at the recursive application of {\tt
  sieve}, the list that is bound to {\tt rest} will stay allocated for
the duration of that call, which is in fact the remainder of the
entire computation!

In many cases, the solution is simply to shorten the scope of the
declaration.  In the above example, a good solution is to move the
application of {\tt sieve} outside the {\tt let}:
\begin{verbatim}
  fun sieve (a as ([], p)) = a
    | sieve (x::xs, p) =
          sieve let val rest = sift(x,xs)
                in (cp rest,x::p)
                end
\end{verbatim}

That the copying really overwrites the input list relies, in part, on
region resetting (Chapter~\ref{storagemodes.sec}).  But it also relies
on region polymorphism and on the Ground Rule.  Rewriting the
application of \boxml{sieve} ensures that the list bound to {\tt
  rest} will not live to see the recursive call of {\tt sieve}.
Unless forced by context to do otherwise, {\tt sift} will create a
list using fresh regions. Because {\tt cp} is also
\index{region exomorphism}%
exomorphic, there will be no sharing between {\tt rest} and the other
lists. The region variable that denotes the region that holds the
auxiliary pairs of {\tt rest} appears in the effect of the (revised)
{\tt let} expression. However, this region variable does not occur
free in the region-annotated type scheme with place of any value
variable in scope at that point, not even in the region-annotated type
scheme with place of {\tt sieve}, which only has the region that
contains {\tt sieve} itself free in its region-annotated type scheme
with place.  Consequently, region inference wraps the {\tt let}
expression by a {\tt region} declaration of the region variable in
question:
\begin{verbatim}
  fun sieve (a as ([], p)) = a
    | sieve (x::xs, p) =
        sieve let region r10
                  val rest = sift[r10](x,xs)
              in (cp rest,x::p)
              end
\end{verbatim}

\section{Shortening Lifetime}
Informally, region inference forces the lifetime of an identifier to
be at least its scope. Improving memory performance therefore
sometimes requires making scopes of identifiers smaller.  Useful
\index{program transformation}%
\index{lifetime|)}%
\index{lifetime!shortening}%
program transformations include:

\subsubsection*{Inwards let floating}
\begin{quote}
\index{let floating}%
Transform
$$\boxml{let val $\id_1$ = $\exp_1$ val $\id_2$ = $\exp_2$ in $\exp$ end}$$
into
$$\boxml{let val $\id_2$ = let val $\id_1$ = $\exp_1$ in $\exp_2$ end in $\exp$ end}$$
provided $\id_1$ does not occur free in $\exp$.
\end{quote}

\subsubsection*{Application extrusion:}
\begin{quote}
\index{application extrusion}%
Transform
$$\boxml{let $\dec$ in $f$($\exp$) end}$$
into
$$\boxml{$f$ let $\dec$ in $\exp$ end}$$
provided $f$ is an identifier that is not declared by $\dec$.
\end{quote}

Application extrusion is particularly useful
in connection with
\index{tail recursion}%
tail recursion; the reader will see it employed several times in what
follows.
\index{scope rules|)}%

%---------------------------------------------------------
\chapter{Static Detection of Space Leaks}
\label{spaceleak.sec}
%---------------------------------------------------------

``Space leak'' is the informal term used when a program uses much more
memory than one would expect, typically because of memory not being
re-cycled as early as it should (or not at all).

If a region-polymorphic function with region-annotated type scheme
$\sigma$ has a $\Put$ effect on a region variable that is not amongst the
bound region variables of $\sigma$, then one quite possibly has a
space leak; every application of the function may write values into a
region that is the same for all calls of the function. For example,
consider the source program\footnote{Program
  \boxml{kitdemo/escape.sml}.}
\begin{verbatim}
  fun g () =
    let val x = [5,7]
        fun f y = (if y>3 then x@x else x;
                   5)
    in f 1; f 4
    end
\end{verbatim} 
Here \boxml{f} has type $\boxml{int}\to\boxml{int}$; yet, when the
expression \boxml{y>3} evaluates to \boxml{true}, an append operation
is performed that produces a list in the same region as {\tt x}. The
first call of $\boxml{f}$ will not cause the append operation to be
called, but the second one will. One can say that \boxml{f} has a
space leak in that it can write values into a more global region,
namely a region that is allocated at the beginning of the body of {\tt
  g}. The sequence of calls to {\tt f} accumulates copies of {\tt x@x}
in that region, although none of these lists are accessible anywhere.
In this particular case, the values are not even part of the result
type of {\tt f}, so the writing is a side-effect at the implementation
level, even though there are no references in the program.

The region-annotated type scheme inferred for \boxml{f} is
$$\forall\epsilon.\boxml{int} \ar{\epsilon.\{\Put(\rho_{11})\}} \boxml{int}$$
where the region-annotated type of \boxml{x} is
$$(\boxml{int},[\rho_{11}])\boxml{list}$$
Here we see that
$\rho_{11}$ is free in the region-annotated type scheme and appears
with a $\Put$ effect.

\section{Warnings About Space Leaks}
The MLKit can be instrumented to issue a warning each time it meets a
function that is declared using {\tt fun} and has a free $\Put$ effect
occurring somewhere in its type scheme. The way to tell the MLKit to
issue the warnings is by passing the option
\index{put-effect!escaping}%
\texttt{-warn\_on\_escaping\_puts} to the MLKit compiler. In practice, this warning
mechanism is a valuable device for predicting space leaks.  The
region-annotated version of our example function {\tt g} is listed in
Figure~\ref{escape_mulexp.fig}. During compilation of {\tt g}, the MLKit
issues the following warning:\footnote{To provoke the warning, one has
  to disable in-lining in the
  \index{optimiser}%
  {\Lam} optimiser; this is done by passing the option
  \texttt{-maximum\_inline\_size 0} to the MLKit compiler together
  with the option \texttt{-warn\_on\_escaping\_puts}.}
\begin{figure}
\hrule
\medskip
\begin{verbatim}
   let fun g at r1 [] (v86) =
           let region r11:INF;
               val x = [5,7] at r11;
               region r18:1;
               fun f at r18 [] (y) =
                   let val _ = case y > 3 of
                                  true => @[r11] <x, x>
                                | _ => x
                   in 5
                   end;
               val _ = f[] 1
           in  f[] 4
           end
   in  {|g: (_,r1)|}
   end
\end{verbatim}
\caption{The region-annotated version of {\tt g}.}
\medskip
\hrule
\label{escape_mulexp.fig}
\end{figure}
\begin{small}
\begin{verbatim}
 *** Warnings ***
f has a type scheme with escaping put effects on region(s):
r11, which is also free in the type schemes with places of :  x
\end{verbatim}
\end{small}
We are told that the program might space leak in region \boxml{r11}.
Looking at the function \boxml{f}, we see that this region is an
actual region parameter to \boxml{@}. It follows that the problem is
the call to \boxml{@}.

\section{Fixing Space Leaks}
Often one can fix a space leak by delaying the creation of the value
that causes the space leak. In the above example, we can move the
construction of the list into \boxml{f}:\footnote{Program
  \boxml{kitdemo/escape1.sml}.}
\begin{verbatim}
  fun g () =
    let fun mk_x () = [5,7]
        fun f y = let val x = mk_x()
                  in if y>3 then x@x else x; 5
                  end
    in f 1; f 4
    end
\end{verbatim}
Of course, this means that the list will be reconstructed upon each
application of \boxml{f}. Another solution is to move the creation of
the list as close to the calls as possible and then pass the list as
an extra argument:\footnote{Program \boxml{kitdemo/escape2.sml}.}
\begin{verbatim}
  fun g () =
    let fun f (x,y) = (if y>3 then x@x else x; 5)
    in let val x = [5,7]
       in  f(x,1); f(x,4)
       end
    end
\end{verbatim}
Both solutions stop warnings from being printed, but the second
solution is better than the first: \boxml{f} still has a $\Put$ effect on
the regions containing \boxml{x}, but the difference is that these are
now represented by bound region variables in the type scheme of
\boxml{f}. This quantification has the advantages that (1) allocation
of space for the list is delayed until the list is actually used and
(2), the list can be de-allocated after the calls have been made
(whereas in the original version, \boxml{x} occurs free in the
declaration of \boxml{f} and will be kept alive as long as \boxml{f}
can be called.)

At other times, there is no clean way of avoiding escaping $\Put$
effects.  One example is found in the
\index{TextIO@\texttt{TextIO}}%
\index{openIn@\texttt{openIn}}%
\index{openOut@\texttt{openOut}}%
{\tt TextIO} structure of the Basis Library:
\begin{verbatim}
  exception CannotOpen
  fun raiseIo fcn nam exn =
    raise IO.Io {function = fcn^"", name = nam^"", cause = exn}

  fun openIn (f: string) : instream =
    {ic=prim("openInStream", (f,CannotOpen)),
     name=f} handle exn => raiseIo "openIn" f exn

  fun openOut(f: string): outstream =
    {oc=prim("openOutStream", (f,CannotOpen)),
     name=f} handle exn => raiseIo "openOut" f exn
\end{verbatim}
As explained in Chapter~\ref{exceptions.sec},
when a unary exception constructor is applied to a value, both the
argument value and the resulting constructed value are forced into
a particular global region. Thus, the application
$$\verb+IO.Io {function = fcn^"", name = nam^"", cause = exn}+$$
has a
potential space leak in it; every time we apply the exception
constructor, the resulting exception value will be put into a global
region. This particular space leak is perhaps not something that would
keep one awake at night, because most programs do not make a large
number of failed attempts to open files, but it is useful to be warned
about this potential problem.  Notice, however, that the string
arguments to {\tt raiseIo} are copied inside the body of {\tt
  raiseIo}, so that they are not forced to be placed in the global
string region.

%---------------------------------------------------------
\chapter{References}
\label{refs.sec}
%---------------------------------------------------------
Section~\ref{refbasics.sec} gives a brief summary of references in
Standard ML; it may be skipped by readers who know SML.  Thereafter,
we discuss runtime representation of references and region-annotated
reference types.

\section{References in Standard ML}
\label{refbasics.sec}
A reference is a memory address (pointer).  Standard ML has three
built-in operations on
\index{reference}%
references
\index{ref@\texttt{ref}}%
\index{"!@\texttt{"!}}%
\index{:=@\texttt{:=}}%
\medskip

\halign{\indent\tt#\ \hfil&\quad$#$\hfil\ &\quad#\hfil\cr
ref & \forall\alpha.\alpha\to\alpha\,\REF & create reference\cr
!   & \forall\alpha.\alpha\,\REF\to\alpha & de-referencing\cr
:=  & \forall\alpha.\alpha\,\REF\ast\alpha\to\UNIT & assignment\cr}
\medskip

\noindent
If the type of a reference $r$ is $\tau\,\REF$ then one can store
values of type $\tau$ (only) at address $r$.  A reference is a value
and can therefore be bound to a value identifier by a {\tt val}
declaration. While the value stored at a reference may change, the
binding between variable and reference does not change. We show an
example, because this point can be confusing to programmers who are
familiar with mutable variables in languages like C and Pascal:
\begin{verbatim}
  val it = let val x: int ref = ref 3
               val y: bool ref = ref true
               val z: int ref = if !y then x else ref 5
           in z:= 6; !x
           end
\end{verbatim}
Because \boxml{!y} evaluates to true, {\tt z} becomes bound to the
same reference ($r$) as {\tt x}.  So, the subsequent assignment to
{\tt z} changes the contents of the store at address $r$ to contain 6.
Because {\tt x} and {\tt z} are aliases, the result of the {\tt let}
expression is the contents of the store at address $r$ (i.e., 6).

\section{Runtime Representation of References}
The MLKit translates an SML expression of the form $\boxml{ref
  $\exp$}$\/ into an expression of the form (assuming $\exp$
translates into $e$)
$$\boxml{ref $\at\,\rho~ e$}$$
which is evaluated as follows. First
$e$ is evaluated. Assume that this evaluation yields a value $v$. Here
$v$ may be a
\index{boxing}%
boxed or an unboxed value.  Next, a 64-bit word is allocated in the
region denoted by $\rho$; let $r$ be the address of this word. Then
$v$ is stored at address $r$ and $r$ is the result of the evaluation.

\begin{figure}
\hrule
\begin{center}
\begin{picture}(50,20)
\put(8,5){\hbox{$\ldots$}}
\put(20,5){\framebox(20,10){$v$}}
\put(15,8){\hbox{$r:$}}
\put(25,0){\boxml{r35}}
\put(8,0){\boxml{r34}}
\put(45,0){\boxml{r36}}
\put(45,5){\hbox{$\ldots$}}
\end{picture}
\end{center}
\caption{Creating a reference allocates one word in a region on the
  region stack. Here, the region is drawn as a finite region, but it
  could equally well be infinite.}
\label{refsv.fig}
\medskip
\hrule
\end{figure}


The situation is depicted in Figure~\ref{refsv.fig}. The value $v$ can
be unboxed as shown in Figure~\ref{refs.fig}. Or it may be boxed, in
which case $v$ is an address.

Notice that a reference really is a pointer in the implementation.  In
particular, a reference is not tagged, so the register allocator may
choose to store a particular reference in a register. The
content of the reference is also always one word, either an unboxed
value (e.g., an integer or a boolean) or a pointer (if the content is
boxed).  So the content of a reference is not tagged either.

De-referencing a reference $r$ is done by reading the content of the
memory location $r$.  Notice that de-referencing does not require
knowledge of what region the word with address $r$ resides in.

Assigning a value $v$ to a reference $r$ simply stores $v$ in the
memory at address $r$. When $v$ is an unboxed value, the assignment
can be regarded as copying $v$ into the memory cell $r$; otherwise $v$
is a pointer, which the assignment stores in the memory cell $r$.
Either way, assignment is a constant-time operation.

\section{Region-Annotated Reference Types}
The general
\index{type!region-annotated}%
form of a region-annotated reference type is:
$$(\mu\,\REF,\rho)$$
Informally, a reference $r$ has this type if it
is the address of a word in the region denoted by $\rho$ and,
moreover, $\mu$ is the region-annotated type with place of the
contents of that word.  For example, assume $\rho$ is bound to some
region name, say \boxml{r35}; then the evaluation of the declaration
~\boxml{val x = ref $\at\,\rho$ 3}~ results in the environment
$\{\boxml{x}\mapsto r\}$, where $r$ is the address of a word with
contents 3 residing in region \boxml{r35}, see Figure~\ref{refs.fig}.
The type of \boxml{x} is {\tt (int ref, $\rho$)}.

\begin{figure}
\hrule
\begin{center}
\begin{picture}(50,20)
\put(8,5){\hbox{$\ldots$}}
\put(20,5){\framebox(20,10){\boxml{3}}}
\put(15,8){\hbox{$r:$}}
\put(25,0){\boxml{r35}}
\put(8,0){\boxml{r34}}
\put(45,0){\boxml{r36}}
\put(45,5){\hbox{$\ldots$}}
\end{picture}
\end{center}
\caption{Creating a reference allocates one word in a region on the
  region stack. Here, the region is drawn as a finite region, but it
  could equally well be infinite.}
\label{refs.fig}
\medskip
\hrule
\end{figure}


References are treated like all other values by region inference.  The
region-annotated type schemes given to the three built-in operations
are: \medskip

\halign{\indent\tt#\ \hfil&\quad$#$\hfil\ &#\hfil\cr
ref & \forall\alpha\rho\epsilon.\alpha \ar{\epsilon.\{\Put(\rho)\}}(\alpha~\REF,\rho)\cr
!   &  \forall\alpha\rho\epsilon.(\alpha~\REF,\rho)\ar{\epsilon.\{\Get(\rho)\}} \alpha \cr
:=  & \forall\alpha\rho\epsilon.[(\alpha~\REF,\rho), \alpha] \ar{\epsilon.\{\Get(\rho)\}} \UNIT\cr}
\medskip

\noindent
The type scheme for \verb+:=+ has in it a $\Get$ effect on the region
holding the reference. Although the operator does not actually read
the value, the presence of the value is necessary for it to be updated.
Assigning a value $v$ to a reference $r$ does not make a copy of $v$
(unless $v$ is unboxed). Instead, \verb+:=+ updates the content of the reference $r$
to point to $v$.

The advantage of the chosen scheme for handling references is that
reference creation, de-referencing, and assignment all are
constant-time operations. The disadvantage is that if two values may
be assigned to the same reference, then they are forced to be in the
same regions (cf. the region-annotated type schemes given above).

If we compile the example from Section~\ref{refbasics.sec}, we get the
program shown in Figure~\ref{otherrefs.fig}.\footnote{Program
  \boxml{kitdemo/refs3.sml}.}
\begin{figure}
\hrule
\medskip
\begin{verbatim}
   let val it =
         let region r9:INF;
             val x = ref at r9 3;
             region r10:1;
             val y = ref at r10 true;
             val z = case !y of true => x | _ => ref at r9 5;
             val _ = (z := 6)
         in  !x
         end
   in  {|it: _|}
   end
\end{verbatim}
\caption{Region-annotated reference creation.}
\label{otherrefs.fig}
\medskip
\hrule
\end{figure}
The region denoted by {\tt r9} contains the memory word whose address
is bound to {\tt x} and {\tt z}, and whose contents is first 3, then
6.  The region denoted by {\tt r10} contains a single boolean.  Also
notice that the word containing 5 is designated {\tt r9}, because the
{\tt then} and {\tt else} branches must be given the same
region-annotated type with place. Finally, notice that all references
will be reclaimed automatically at the end of the {\tt let}
construct that bind \boxml{r9} and \boxml{r10}.

\section{Local References}
References \index{reference!local} that are created locally within a
function and that do not escape the function naturally reside in
regions that are local to the function body.  For example, the
declaration:\footnote{Program \boxml{kitdemo/refs1.sml}.}
\begin{verbatim}
  fun id x = let val r = ref x in !r end;
\end{verbatim}
is compiled into
\begin{verbatim}
  let fun id at r1 [] (x) =
        let region r11:1;
            val r = ref at r11 x
        in !r
        end
  in {|id: (_,r1)|}
  end
\end{verbatim}
Here {\tt r11} will be implemented as one word on the runtime stack.
The evaluation of ~~\boxml{ref at r11 x}~~ moves the argument
\boxml{x} to that word on the stack. At the end of the inner
\texttt{let}-scope, the word (i.e., region \texttt{r11}) is popped off the stack.

Now, let us turn to an example of a memory cell whose lifetime extends
the scope of its declaration, because it is accessible via a function
(in Algol terminology, the reference is an {\em own variable}
\index{variable!own}%
of the function.)\footnote{Program \boxml{kitdemo/refs2.sml}.}
\begin{verbatim}
  local
    val r = ref ([]:string list)
  in
    fun memo_id x = (r:= x:: !r; x)
  end
  val y = memo_id "abc"
  val z = memo_id "efg";
\end{verbatim}
Provided that in-lining by the optimiser is restricted to in-line only
those functions that are applied once,\footnote{To restrict the
  optimiser accordingly, provide the option
  \texttt{-maximum\_inline\_size 0} to the MLKit compiler.} this example
compiles into
\begin{verbatim}
   let val r = ref at r6 nil;
       fun memo_id at r1 [] (x) =
         let val _ = (r := :: (x, !r)at r4) in x end;
       val y = memo_id[] "abc"at r3;
       val z = memo_id[] "efg"at r3
   in  {|r: (_,r6), memo_id: (_,r1), y: (_,r3), z: (_,r3)|}
   end
\end{verbatim}
and the MLKit warns us that there is a possible space
leak:\footnote{Warnings are printed only if the option {\tt
    -warn\_on\_escaping\_puts} is passed to the MLKit compiler along
  with the option \texttt{-maximum\_inline\_size 0}. See
  Chapter~\ref{spaceleak.sec}.}
\begin{verbatim}
 *** Warnings ***
memo_id	 has a type scheme with escaping put effects on region(s):
r4, which is also free in the type schemes with places of :  r
\end{verbatim}

\section{Hints on Programming  with References}
There is no need to shy away from using references when programming
with regions. However, one needs to be aware of the restriction that
values that may be assigned to the same references are forced to live
in the same region, and that this region with all its values will be
alive for as long as the reference is live. If the contents type is
unboxed (e.g., {\tt int}), there is no problem, for in that case, no
region for the contents is allocated. But one should avoid creating
long-lived references that are assigned many different large values.

%---------------------------------------------------------
\chapter{Recursive Data Types}
\label{datatypes.sec}
%---------------------------------------------------------
This chapter describes how the MLKit treats recursive data types. We
have already seen how one recursive datatype, namely lists, is
handled. This chapter deals with the general case.
%Standard ML \index{tree!binary}
%permits the programmer to declare (possibly recursive) data types
%using the {\tt datatype} declaration.
%For example, one can declare a polymorphic, recursive
%data type for binary trees as
%follows:\index{tree@\texttt{tree}}\index{Lf@\texttt{Lf}}\index{Br@\texttt{Br}}\index{datatype@\texttt{datatype}}
%\begin{verbatim}
%       datatype 'a tree = Lf | Br of 'a * 'a tree * 'a tree;
%\end{verbatim}

\section{Spreading Data Types}
The MLKit performs an analysis called
\index{spreading}%
``spreading of data types''.  Spreading of datatypes analyses {\tt
  datatype} declarations.  This analysis of a {\tt datatype}
declaration uses information about the type constructors that appear
in the types of the constructors of the data type(s) introduced by the
declaration, but it does not use information about the use of the data
type.

Spreading determines (a) a so-called
\index{arity}%
arity of every type name that the data type declaration introduces and
(b) a region-annotated type scheme for every value constructor
introduced by the data type declaration.

In the Definition of Standard ML every type name has an attribute,
called its arity \cite[page 15]{mthm97}. The arity of a type name is the number
of type arguments it requires. For example, {\tt int} has arity 0
while the type name introduced by the following declaration of binary
trees has arity 1:
\index{tree@\texttt{tree}}%
\index{Lf@\texttt{Lf}}%
\index{Br@\texttt{Br}}%
\index{datatype@\texttt{datatype}}%
\begin{verbatim}
  datatype 'a tree = Lf | Br of 'a * 'a tree * 'a tree;
\end{verbatim}

The MLKit extends the notion of arity (in it's internal languages) to
account for regions and effects. For lists, for example, we need a
region for holding the pairs to which {\tt ::} is applied. For the
data type
\begin{verbatim}
  datatype 'a foo = A | B of ('a * 'a) * ('a * 'a)
\end{verbatim}
the type of {\tt B} introduces the possibility of three region
variables (one for each star). Region variables that are induced by
the types of constructors and that do not hold the constructed values
themselves are called
\index{region variable!auxiliary}%
{\em auxiliary region variables}. For example, the {\tt list} data
type:
\begin{verbatim}
  datatype 'a list = nil | op :: of 'a * 'a list
\end{verbatim}
has one auxiliary region variable, namely the region variable that
describes where the pairs of type {\tt 'a * 'a list} (i.e., the
auxiliary
\index{pair!auxiliary}%
pairs), reside.

Besides auxiliary regions, one sometimes needs auxiliary effects.  For
an example, consider:
\begin{verbatim}
  datatype V = N of int | F of V -> V
\end{verbatim}
Here one needs an arrow effect for the function type \boxml{V -> V}.
We refer to such an arrow effect as an
\index{arrow effect!auxiliary}%
{\em auxiliary arrow effect} of the data type in question.


We define the {\em (internal) arity} of a type name $t$ to be a triple
$(n,k,m)$ of non-negative integers, where $n$ is the usual Standard ML
arity of the type name, $k$ is the
\index{region arity}%
{\em region arity} of $t$, and $m$ is the
\index{effect arity}%
{\em effect arity} of $t$. The region and effect arities indicate the
number of auxiliary regions and arrow effects of the data type,
respectively.

For efficiency purposes, we have found it prudent to restrict the
maximal number of auxiliary regions a data type can have to one for
each kind of runtime type of regions and to restrict the maximal
number of auxiliary effects to 1.  Otherwise, the number of auxiliary
regions can grow exponentially in the size of the program:
\begin{verbatim}
  datatype t0 = C
  datatype t1 = C1 of t0 * t0
  datatype t2 = C2 of t1 * t1
  ...
\end{verbatim}
Here the number of auxiliary region variables would double for each
new data type declaration.  Furthermore, all type names introduced by
a {\tt datatype} declaration are given the same arity (a {\tt
  datatype} declaration can declare several types simultaneously).
%Within one constructor binding ({\it conbind\/}), all
%occurrences of the same type variable are paired with the same region variable.
%Different type variables are paired with different region variables.

Because of the limit on the number of auxiliary region variables,
spreading of data type declarations sometimes unifies two auxiliary
region variables that would otherwise be distinct; but it only unifies
auxiliary region variables that have the same runtime type. The
practical consequence of these restrictions is that applying a
constructor to a value $v$ sometimes forces identification of regions
of $v$ that hold otherwise unrelated parts of $v$.

The automatic memory management that we have discussed for lists
extends to other recursive data types without problems. For example,
binary trees are put into regions and are subsequently de-allocated
(in a constant time operation) when the region is popped. The next
section goes thorough an example to illustrate the point.

The MLKit attempts to use an unboxed representation for value
constructors when possible. We have already seen how cons (i.e.,
\texttt{::}) and \texttt{nil} use an unboxed representation (Chapter~\ref{lists.sec}). In
general, a value constructor of a type is represented unboxed if
(1) the type has at most three unary constructors and (2) each unary
constructor takes boxed arguments.

\section{Example: Balanced Trees}
Consider the program in Figure~\ref{balpre.fig}.\footnote{MLB-file:
  \boxml{kitdemo/trees.mlb}, file \boxml{kitdemo/trees.sml}.}
\begin{figure}
\hrule
\medskip
\begin{verbatim}
  datatype 'a tree = Lf | Br of 'a * 'a tree * 'a tree

  (* preorder traversal of tree *)

  fun preord (Lf, xs) = xs
    | preord (Br(x,t1,t2),xs) =
        x::preord(t1,preord(t2,xs))

  (* building a balanced binary tree
     from a list: *)

  fun balpre [] = Lf
    | balpre(x::xs) =
       let val k = length xs div 2
       in Br(x, balpre(take(xs, k)),
                balpre(drop(xs, k)))
       end

  (* preord o balpre is the identity: *)

  val it = print(implode(preord(balpre(explode
      "Greetings from the MLKit\n"),[])));
\end{verbatim}
\caption{Example showing recycling of memory used for an intermediate
  data structure. The function {\tt balpre} builds a balanced binary
  tree from a list and {\tt preord} then flattens the tree to a list
  (after which the tree is garbage).}
\medskip \hrule
\label{balpre.fig}
\end{figure}
We would hope that the balanced tree produced by {\tt balpre} is
removed after it has been collapsed into a list by {\tt preord}.  And
indeed it is. Here is the proof:
\begin{verbatim}
  val it =
    let region r257:INF
    in  print[]
        let region r259:INF
        in  implode[r257]
            let region r262:INF, r264:1
            in  preord[r259]
                (let region r267:INF
                 in  balpre[r262]
                     let region r270:1
                     in explode[r267]
                        "Greetings from the Kit\n"at r270
                     end
                 end,
                 nil
                )at r264
            end
        end
    end
\end{verbatim}
The exomorphic behavior of {\tt balpre} causes the tree to be
allocated in region {\tt r262}, which is
de-allocated after the call to {\tt preord}.

This is the kind of certainty about lifetimes we are aiming at.
Imagine, for example, that the trees under consideration were terms
representing different intermediate forms in a compiler. Then one
would like to know that (possibly large) syntax trees are not kept in
memory longer than needed.

%---------------------------------------------------------
\chapter{Exceptions}
\label{exceptions.sec}\index{exception}
%---------------------------------------------------------

Standard ML
\index{exception}%
\index{exception constructor}%
exception constructors are introduced by
\index{exception declaration}%
\index{exception@\texttt{exception}}%
{\em exception declarations}. The two most basic forms are
$$\boxml{exception {\it excon}}$$
and
$$\boxml{exception {\it excon} of {\it ty}}$$
for introducing nullary
and unary exception constructors, respectively.
%Unary exception constructors are typically
%used when one wants to raise an exception that contains a
%reason (represented by a value of type {\it ty}).

Exception declarations need not occur at top level. For example, a
function body may contain exception declarations.

\section{Exception Names}
Each evaluation of an exception declaration creates a fresh
\index{exception!generative}%
\index{exception name}%
{\em exception name\/} and binds it to the exception constructor. This
is sometimes referred to as the {\em generative\/} nature of Standard
ML exceptions.

In the MLKit, an exception name is implemented as a pointer to a pair
consisting of an integer and a string pointer; the string pointer
points to the name of the exception, which is a global constant in the
target program. The string is used for printing the name of the
exception if it ever propagates to top level. The memory cost of
creating the pair is, as always with pairs, two words.

\section{Exception Values}
Standard ML has a type
\index{exn@\texttt{exn}}%
{\tt exn} of
\index{exception value}%
{\em exception values}.  An exception value is either a
\index{exception value!nullary}%
{\em nullary\/} exception value or a
\index{exception value!constructed}%
{\em constructed\/} exception value. A nullary exception value is a
pointer to a word that points to an exception name. A constructed
exception value is a pair $(\ename,v)$ of an exception name $\ename$
and a value $v$; we refer to $v$ as the {\em argument\/} of $\ename$.
This representation of exception values allows for the exception name
of an exception value to be fetched in the same way irrespective of
whether the exception value is nullary or constructed.

Referring to a nullary exception constructor allocates no memory. By
contrast, applying a unary exception constructor to an argument
constructs a constructed exception value. The memory cost of such an
application is two words for holding the pair $(\ename, v)$.

The distinction between nullary and unary exception constructors is
important in the MLKit because our region inference analysis takes a
simple-minded approach to exceptions:
\begin{quote}
  All exception names and nullary exception values are put into a
  certain
  \index{region!global}%
  global region and thus never reclaimed automatically. A constructed
  exception value is put in a region that is live at least as long as
  the exception constructor is in scope.
\end{quote}
We therefore make the following recommendations:
\begin{enumerate}
\item Put exception declarations at top level, if possible.  That way,
  the memory required by exception names will be bounded by the
  program size.
\item Avoid applying unary exception constructors frequently; there is
  no harm in raising and handling constructed exception values
  frequently; it is the creation of many different constructed
  exception values that can lead to space leaks. Nullary constructors
  may be raised without incurring memory costs.
\end{enumerate}

\section{Raising Exceptions}
An expression of the form
\index{exception!raising}%
$$\boxml{raise {\it exp}}$$
is evaluated as follows. First {\it exp},
an expression of type {\tt exn}, is evaluated to an exception value.
Then the runtime
\index{stack}%
stack is scanned from top to bottom in search of a handler that
can handle the exception. A register points to the top-most exception
handler; the exception handlers are linked together as a linked list
interspersed with the other contents of the runtime stack.  If a
matching handler is found, the runtime stack is popped down to the
handler. This popping includes popping of regions that lie between
that stack top and the handler. Put differently, consider an
expression of the form
\index{let region@\texttt{let region}}%
{\tt let region $\rho$ in $e$ end}; if $e$ evaluates to an exception
packet, then the region bound to $\rho$ is de-allocated and the packet
is also the result of evaluating the \texttt{let region} expression.

We have not attempted to design an analysis that would estimate how
far down the stack a given exception value might propagate. Of course,
it would not be a very good idea to allocate a constructed exception
value in a region that is popped before the exception is handled!
This is why we put all exception names in
\index{region!global}%
global regions.

\section{Handling Exceptions}
The ML expression form
\index{exception!handling}%
$$\boxml{${\it exp}_1$ handle {\it match}}$$
is compiled into a
$\MulExp$ expression of the form
\begin{tabbing}
\ \ \ \ \ \ \=\tt let region $\rho$ in \\
\>\ \ \=\boxml{let $f$ = fn $\at\,\rho$ {\it match} in $e_1$ handle $f$ end}\\
\>\tt end
\end{tabbing}
where $f$ is a fresh variable.  So first a handler (expressed as a
function) is evaluated and stored in some region $\rho$. This region
will always have multiplicity one and therefore be a finite region
which is put on the stack.  Then $e_1$, the result of compiling ${\it
  exp}_1$, is evaluated.  If $e_1$ terminates with a value, the {\tt
  let region} construct will take care of de-allocating the handler.
If $e_1$ terminates with an exception, however, $f$ is applied.

Thus the combined cost of raising an exception and searching for the
appropriate handler takes time proportional to the depth of the
runtime stack in the worst case.

Handling of exceptions is the only operation that takes time that
cannot be determined statically, provided one admits arithmetic
operations as constant-time operations.

\section{Example: Prudent Use of Exceptions}
Here is an example of prudent use of exceptions in the MLKit:
\index{hd@\texttt{hd}}%
\index{tl@\texttt{tl}}%
\bigskip

\vbox{
\hrule
\begin{verbatim}
  exception Hd               (* recommendation 1 *)

  fun hd [] = raise Hd
    | hd (x::_) = x

  exception Tl

  fun tl [] = raise Tl
    | tl (_ ::xs) = xs

  exception Error of string

  local
    val error_f = Error "f"  (* recommendation 2 *)
  in
    fun f(l) =
        hd(tl(tl l)) handle _ => raise error_f
  end

  val r = f[1,2,3,4]
\end{verbatim}
\hrule
}\bigskip

The application \boxml{Error "f"} has been lifted out from the body of
\boxml{f}. No matter how many times {\tt f} is applied, it will not
create additional exception values.\footnote{Program
  \boxml{kitdemo/exceptions.sml}.}

%---------------------------------------------------------
\chapter{Resetting Regions}
\label{storagemodes.sec}
%---------------------------------------------------------
The idea of region resetting was introduced in
Section~\ref{checked.sec}.
\index{region!resetting}%

This chapter gives an informal explanation of the rules that govern
resetting. Knowing these rules is useful, irrespective of whether one
makes the MLKit decide on region resetting, or prefers to control
resetting explicitly in the program.

Resetting only makes sense for infinite regions.  Resetting a region
is a constant-time operation.  Because the same region variable can be
bound sometimes to a finite region and sometimes to an infinite region
at runtime, resetting a region can involve a test at runtime.

The MLKit contains an analysis, called the {\em storage mode analysis},
which has two purposes:
\begin{enumerate}
\item inserting automatic resetting of infinite regions, when possible
\item checking applications of $\resetr$ (and
  \index{forceResetting@$\resetf$}%
  $\resetf$) so as to report on the safety of the resetting requested
  by the programmer
\end{enumerate}

As a matter of design, one might wonder whether it would not be
sufficient to rely on the user to indicate where resetting should be
done. However, checking whether resetting is safe at a particular
point chosen by the user is of course no easier than checking whether
resetting is safe at an arbitrary point in the program, so one might
as well let the compiler insert region resetting whenever it can prove
that it is safe.

In this chapter, we describe the principles that underlie the storage
mode analysis. Even if one is willing to insert $\resetr$ and
$\resetf$ instructions in the program, one still needs to understand
these principles, so as to be able to act upon the messages that are
generated by the system in response to explicit $\resetr$ and
$\resetf$ instructions.

\section{Storage Modes}
As we have seen in previous chapters, region inference decorates every
\index{allocation point}%
\index{at@\texttt{at}}%
allocation point with an annotation of the form $\at\,\rho$,
indicating into what region the value should be stored.

Now the basic idea is that storing a value into a region can be done
in one of two ways, at runtime. One either stores the value at the
\index{top of region}%
{\em top\/} of the region, thereby increasing the size of the region;
or one stores the value into the
\index{bottom of region}%
{\em bottom\/} of the region, by first resetting the region (so that
it contains no values) and then storing the value into the region.
%Pure resetting of a region can be accomplished by storing a value of size zero
%at the bottom of the region.

The storage mode analysis transforms an allocation point $\at\,\rho$
into
\index{attop@\texttt{attop}}%
$\attop\,\rho$ when it estimates that $\rho$ contains live values at
the allocation point, whereas it transforms it into
\index{atbot@\texttt{atbot}}%
$\atbot\,\rho$ if it can prove that the region will contain no live
values at that allocation point. The tokens $\attop$ and $\atbot$ are
called
\index{storage mode}%
{\em storage modes}.

\index{region polymorphism}%
Region polymorphism introduces several interesting problems. Let $f$
be a region-polymorphic function with formal region parameter $\rho$
and consider an allocation point $\at\,\rho$ in the body of $f$.
Whether it is safe for $f$ to store the value at bottom in the region
depends not only on the body of $f$ but also on the context in which
$f$ is called.

For example, consider the compilation unit
\begin{verbatim}
  fun f [] = []
    | f (x::xs) = x+1 :: f xs

  val ll = [1,2,3]
  val l2 = if true then f l1 else l1
  val x::_ = l1
\end{verbatim}
When {\tt f} creates the empty list, it can potentially reset the
\index{region!auxiliary}%
auxiliary region intended for the
\index{pair!auxiliary}%
auxiliary pairs of the list. In the above program, however, the
conditional forces \boxml{f l1} and \boxml{l2} to be in the same
region as {\tt l1}.  Because \boxml{l1} is live after the application
of {\tt f}, this application must not use $\atbot$ as storage mode.
Indeed, even if we removed the last line of the program, the
application could still not use $\atbot$, for \boxml{l1} is exported
from the compilation unit and thus potentially used by subsequent
compilation units.

By contrast, consider\footnote{Program \boxml{kitdemo/sma1.sml}.}
\begin{verbatim}
  fun f [] = []
    | f (x::xs) = x+1 :: f xs

  val n = length(let val l1 = [1,2,3]
                 in if true then f l1 else l1
                 end)
\end{verbatim}
When {\tt f} creates the empty list, it is welcome to reset the region
that holds \boxml{l1}, for by that time, \boxml{l1} is no longer
needed! ({\tt f} traverses {\tt l1}, but when it reaches the end of
the list, {\tt l1} is no longer used.)  Indeed, the MLKit will replace
the list \boxml{[1,2,3]} by \boxml{[2,3,4]}. The ability to replace
data in regions is crucial in many situations (as we illustrated with
the game of Life in Section~\ref{life.sec}).

Because the MLKit allows for separate compilation, it cannot know all
the call sites of a region-polymorphic function, when it is declared.
Therefore, when considering an allocation point $\at\,\rho$ inside the
body of some region-polymorphic function $f$ that has $\rho$ as a
formal region parameter, one cannot know at compile time whether to
use $\attop$ or $\atbot$ as storage mode.  Instead, the storage mode
analysis operates with a third kind of storage mode named $\sat$,
read: ``somewhere at''. Consider an application of $f$ for which
$\rho$ is instantiated to some region variable $\rho'$, say. At
runtime, $\rho'$ is bound to some region name
(Section~\ref{fininf.sec}) $r'$.  Then $r'$ is combined with a
definite storage mode (i.e., $\attop$ or $\atbot$), to yield $r$, say,
which is then bound to $\rho$.  When $r'$ was originally created (by a
{\tt let region} expression), $r'$ was also made to contain an
indication of whether it is an infinite region or a finite
region.\footnote{On machines\label{atbit.lab} that have at least four
  bytes per word, the two least significant bits of a pointer to a
  word will always be 00. These two bits hold extra information in the
  \index{region name}%
  region name.  One bit, called the ``atbot bit'', holds the current
  storage mode of the region. Another bit, called the ``infinity
  bit'', indicates whether the region is finite or infinite.}  At
runtime, an allocation point $\sat\,\rho$ in the body of $f$ will test
$r$ to see whether the region is infinite and whether the value should
be stored at the top or at the bottom.\footnote{When $\rho$ has
  multiplicity infinity, $r'$ must be the name of an infinite region,
  so the runtime check on whether $r$ has its infinity bit set is
  omitted.}

The relevant parts of the result of compiling the last example are
shown in Figure~\ref{sma1.fig}.  To see the storage modes, pass the option
\index{print drop regions expression with storage modes@\texttt{-print\_drop\_regions\_expression\_with\_storage\_modes}}%
$$\boxml{-print\_drop\_regions\_expression\_with\_storage\_modes}$$
to the MLKit compiler.

%The intermediate form obtained by enabling this flag is from before
%the optimisation that drops non-put regions (page
%\pageref{bother-to-distinguish-get-n-put}) and may therefore have more
%region variables than the intermediate form obtained by enabling the
%flag \boxml{print drop regions expression}.

\begin{figure}
\hrule
\medskip
\begin{verbatim}
   let fun f attop r1 [r14:INF] (var1) =
           case var1 of
             nil => nil
           | _ =>
             let val v94 = decon_:: var1;
                 val v95 = #0 v94;
                 val v96 = #1 v94
             in  :: (v95 + 1, f[sat r14] v96)attop r14
             end;
       val n =
         let region r38:INF;
             val a = let region r27:INF;
                         val l1 = [1,2,3] attop r27
  (*1*)              in f[atbot r38] l1
                     end;
             region r40:1;
             fun acc atbot r40 [] (var11, var12) =
                 case var11 of
                    nil => var12
                  | _ => let val v261 = decon_:: var11;
                             val v263 = #1 v261
                         in acc[] <v263, var12 + 1>
                         end
         in  acc[] <a, 0>
         end
   in  {|f: (_,r1), n: _|}
   end
\end{verbatim}
\caption{Storage modes inferred by the storage mode analysis. Notice
  that the MLKit has inlined the call to the function
  \texttt{length}.}
\label{sma1.fig}
\medskip
\hrule
\end{figure}

\section{Storage Mode Analysis}
\label{sma.sec}
For the purpose of the storage mode analysis, actual region parameters
to region-polymorphic functions are considered allocation points.
Passing a region as an actual argument to a region-polymorphic
function involves neither resetting the region nor storing any value
in it, but a storage mode has to be determined at that point
nonetheless, because it has to be passed into the function together
with the region. The storage mode expresses whether, at the call site,
there may be any live values in the region after the call. For
example, in Figure~\ref{sma1.fig}, the call to {\tt f} at {\tt (*1*)}
passes {\tt r16} with storage mode {\tt atbot} because the only value
that exists before the call of {\tt f} and is needed after the call of
{\tt f} is {\tt length}, which is declared in a different compilation
unit and therefore obviously does not reside in {\tt r16}.

Within every lambda abstraction, the MLKit performs a backwards flow
analysis that determines, for every allocation point, a set of
\index{variable!locally live}%
{\em locally live variables}, that is, a set of variables used by the
remainder of the computation in the function up to the syntactic end
of the function. (This includes variables that appear in function
application expressions.) Prior to the computation of locally live
variables, a program transformation, called
\index{K-normalisation}%
\label{K-normal-form}%
{\em K-normalisation}, has made sure that every intermediate result
that arises during computation becomes bound to a variable. (This
happens by introducing extra {\tt let} bindings, when
necessary.)\footnote{K-normalisation is transparent to users: although
  the storage mode analysis and all subsequent phases up to code
  generation operate on K-normal forms, programs are always simplified
  to eliminate the extra {\tt let} bindings before they are presented
  to the user.}

The MLKit also computes a set of locally live variables for those
allocation points that do not occur inside functions.

We now give an informal explanation of the rules that assign storage
modes to allocation points.  Let an allocation point
\begin{equation}
\label{allocpoint}\at\,\rho
\end{equation}
be given.
\bigskip

\noindent{\bf CASE A:} $\rho$ is a global region. Then $\attop$ is used.
There is a deficiency we have to admit here. The MLKit only puts {\tt
  region} bindings around expressions, not around declarations. Thus, if one
writes
\begin{verbatim}
  local
    fun f [] = []
      | f (x::xs) = x+1 :: f xs
    val l1 = [1,2,3]
  in
    val n = length(if true then f l1 else l1)
  end
\end{verbatim}

\noindent
at top level, then \boxml{l1} is put into a global region, although
this is really unnecessary. As a consequence, {\tt f} would be called
with storage mode {\tt attop} and thus {\tt l1} would not be
overwritten.  \bigskip

\noindent{\bf CASE B:}
The region variable $\rho$ is not a global region and the allocation
point (\ref{allocpoint}) occurs inside a lambda abstraction, that is,
inside an expression of the form \boxml{fn {\it pat} => $e$}.  Here we
regard every expression of the form
$$\boxml{let fun f(x) = $e$ in $e'$ end}$$ as an abbreviation for
$$\boxml{let val rec f = fn(x) => $e$ in $e'$ end}$$
Then it makes
sense to talk about {\em the smallest enclosing lambda abstraction (of
  the allocation point)}.

Now there are the following cases:
\begin{description}
\item[B1] {\it $\rho$ is bound outside the smallest enclosing lambda
    abstraction (and this lambda abstraction is not the right-hand
    side of a declaration of a region-polymorphic function that has
    $\rho$ as formal parameter):} use {\tt attop}
    \index{attop@\texttt{attop}}%
    (see Figure~\ref{b1.fig})
  \item[B2] {\it $\rho$ is bound by a {\tt let region} expression
      inside the smallest enclosing function:} use {\tt atbot} if no
    locally live variable at the allocation point has $\rho$ free in
    its region-annotated type scheme with place
    (Section~\ref{regtych.sec}), and use {\tt attop} otherwise
    \index{let region@\texttt{let region}}%
    (see Figure~\ref{b2.fig})
  \item[B3 (first attempt)]{\it $\rho$ is a formal parameter of a
      region-polymorphic function whose right-hand side is the
      smallest enclosing lambda abstraction:} use
    \index{sat@\texttt{sat}}%
    {\tt sat}, if no locally live variable at the allocation point has
    $\rho$ free in its region-annotated type scheme with place, and
    use {\tt attop} otherwise (see Figure~\ref{b3.fig}).
\end{description}
\begin{figure}[htb]
\hrule
\begin{center}
\begin{tabbing}
\\
\hskip3cm\=\tt let region $\rho$\\
       \>\tt in $\ldots$ (fn {\it pat} => $\ldots\at\,\rho\ldots$)\\
       \>\tt end\\
\\
       \>\tt fun f at$\,\rho_1$ [$\rho$] =\\
       \>\tt\ \ \ (fn x => (fn y => $\ldots$ $\at\,\rho$ $\ldots$)at$\,\rho_2$)at$\,\rho_1$\\
\end{tabbing}
\end{center}
\caption{Two typical situations where $\at\,\rho$ is turned into $\attop\,\rho$
  by
  \index{function!Curried}%
  rule~B1.} \medskip \hrule
\label{b1.fig}
\end{figure}

\begin{figure}[htb]
\hrule
\begin{center}
\begin{tabbing}
\\
\hskip3cm\=\tt (fn ${\it pat}$ => $\ldots$\\
       \>\ \ \=\tt let region $\rho$ \\
       \>    \>\tt in  $\ldots\at\,\rho\ldots l \ldots$\\
       \>    \>\tt end $\ldots$\\
       \>\tt )
\end{tabbing}
\end{center}
\caption{The situation considered in B2. If no locally live variable
  $l$ has $\rho$ occurring in its region-annotated type scheme with
  place, replace $\at\,\rho$ by $\atbot\,\rho$, otherwise by
  $\attop\,\rho$.}  \medskip \hrule
\label{b2.fig}
\end{figure}

\begin{figure}[htb]
\hrule
\begin{center}
\begin{tabbing}
\\
\hskip3cm\=\tt fun f $\at\,\rho_0$ [$\rho$, $\ldots$] = \\
         \>\tt \ \ \=\tt (fn ${\it pat}$ => $\ldots\at\rho\ldots l\ldots$)
\end{tabbing}
\end{center}
\caption{The situation considered in B3. If no locally live variable
  $l$ has in its region-annotated type scheme with place a region
  variable that may be aliased with $\rho$, replace $\at\,\rho$ by
  $\sat\,\rho$, otherwise by $\attop\,\rho$.}  \medskip \hrule
\label{b3.fig}
\end{figure}
The motivation for (B1) is that if $\rho$ is declared non-locally,
then we do not attempt to find out whether $\rho$ contains live data
(this would require a more sophisticated analysis.)

The intuition behind (B2) is as follows. Region inference makes sure
that the region-annotated type of a variable always contains free in
it region variables for all the regions that the value bound to the
variable needs when used. The lifetime of the region bound to $\rho$
is given by the {\tt let region} expression, which is in the same
function as the allocation point. Thus, if no locally live variable at
the allocation point has $\rho$ free in its region-annotated type
scheme with place, then $\rho$ really does not contain any live value
at that allocation point.

The intuition behind (B3) is the same as behind (B2), but in this case
there is a complication: $\rho$ is only a formal parameter so it may
be instantiated to different regions; in particular it may be
instantiated to a region variable that does occur free in the
region-annotated type scheme with place of a locally live variable at
the allocation point. If that happens, rule (B3), as stated, is not
sound!

We refer to the phenomenon that two different region variables in the
program may denote the same region at runtime as
\index{region aliasing}%
{\em region aliasing}. To determine whether to use {\tt sat} or {\tt
  attop} in case (B3), the MLKit builds a
\index{region flow graph}%
\label{region flow graph}%
{\em region flow graph\/} for the entire compilation unit. (This
construction happens in a phase prior to the storage mode analysis
proper.)  The nodes of the region flow graph are region variables and
arrow effects that appear in the region-annotated compilation unit.
Whenever $\rho_1$ is a formal region parameter of some function
declared in the unit and $\rho_2$ is a corresponding actual region
parameter in the same unit, a directed edge from $\rho_1$ to $\rho_2$
is created. Similarly for arrow effects: if $\epsilon_1.\rea_1$ is a
bound arrow effect of a region-polymorphic function declared in the
compilation unit and $\epsilon_2.\rea_2$ is a corresponding actual
arrow effect then an edge from $\epsilon_1$ to $\epsilon_2$ is
inserted into the graph.  Also, edges from $\epsilon_2$ to every
region and effect variable occurring in $\rea_2$ are inserted.
Finally, for every region-polymorphic function $f$ declared in the
program and for every formal region parameter $\rho$ of $f$, if $f$ is
exported from the compilation unit, then an edge from $\rho$ to the
global region of the same runtime type as $\rho$ is inserted into the
graph. (This is necessary, so as to cater for applications of $f$ in
subsequent compilation units.)

Let $G$ be the graph thus constructed.  For every node $\rho$ in the
graph, we write $\langle\rho\rangle$ to denote the set of region
variables that can be reached from $\rho$, including $\rho$ itself.
The rule that replaces (B3) is:
\index{region parameter!formal}%
\begin{description}
\item[B3]{\it $\rho$ is a formal parameter of a region-polymorphic
    function whose right-hand side is the smallest enclosing lambda
    abstraction:} use {\tt sat}, if, for every variable $l$ that is
  locally live at the allocation point and for every region variable
  $\rho'$ that occurs free in the region-annotated type scheme with
  place of $l$, it is the case that
  $\langle\rho\rangle\cap\langle\rho'\rangle =\emptyset$; use {\tt
    attop} otherwise.
\end{description}
\medskip

\noindent{\bf CASE C:} $\rho$ is bound by a {\tt let region} expression
and the allocation point (\ref{allocpoint}) does not occur inside any
function abstraction.  As in (B2), use {\tt atbot} if no locally live
variable at the allocation point has $\rho$ free in its
region-annotated type scheme with place, and use {\tt attop}
otherwise.


\section{Example: Computing the Length of Lists}
\label{length.sec}
We shall now illustrate the storage mode rules of
Section~\ref{sma.sec} with some small examples, which also allow us to
discuss benefits and drawbacks associated with region resetting.

Consider the functions declared in
Figure~\ref{length.fig};\footnote{Program \boxml{kitdemo/length.sml}.}
they implement five different ways of finding the length of a list!
The first, {\tt nlength}, is the most straightforward one.  It is not
tail recursive. Textbooks in functional programming often recommend
that functions are written iteratively (i.e., using tail calls)
whenever possible. This we have done with {\tt tlength}.  Next, {\tt
  klength} is a version that contains a local
\index{region endomorphism}%
region endomorphism {\tt loop} to perform the iteration; {\tt llength}
is similar to {\tt klength}, except that the region endomorphism is
declared outside {\tt llength}, using
\index{local@\texttt{local}}%
{\tt local}.
\begin{figure}
\hrule
\medskip
\begin{verbatim}
  fun upto n =
    let fun loop(n,acc) = if n=0 then acc
                          else loop(n-1, n::acc)
    in loop(n,[])
    end

  fun nlength [] = 0
    | nlength (_::xs) = 1 + nlength xs

  fun tlength l =
    let fun tlength'(nil, acc) = acc
          | tlength'(_::xs, acc) = tlength'(xs,acc+1)
    in tlength'(l,0)
    end

  fun klength l =
    let fun loop(p as ([], acc)) = p
          | loop(_::xs, acc) = loop(xs,acc+1)
    in #2(loop(l,0))
    end

  local fun llength'(p as ([], acc)) = p
          | llength'(_::xs, acc) = llength'(xs,acc+1)
  in fun llength l = #2(llength'(l, 0))
  end

  fun global(p as ([], acc)) = p
    | global(_::xs, acc) = global(xs, acc+1)
  fun glength l = #2(global(l, 0))

  val k = 5000000
  val run =
    nlength(upto k) + tlength(upto k) + klength(upto k)
    + llength(upto k) + glength(upto k)
\end{verbatim}
\caption{Five different ways of computing the length of lists.}
\bigskip
\label{length.fig}
\hrule
\end{figure}
A region profile resulting from running the program is shown in
Figure~\ref{length.region.fig}.  The diagram shows how much space is
used in regions (both finite and infinite regions) and on the stack.
The
\index{region descriptor}%
{\tt rDesc} band shows how much space is used on the stack for holding
region descriptors. The
\index{stack band@\texttt{stack} band}%
{\tt stack} band shows how much space is used on the stack, including
neither finite regions nor region descriptors; the {\tt stack} band
mainly consists of registers and return addresses that have been
pushed onto the stack.
%mael
\begin{figure}
\includerp{length_region.pdf}
\caption{Region profiling of five different
  ways of computing the length of a list, namely, from left to right:
  {\tt nlength}, {\tt tlength}, {\tt klength}, {\tt llength}, and {\tt
    glength}.}
\label{length.region.fig}
\end{figure}

In Figure~\ref{length.region.fig}, we clearly see the five phases.  In
each phase, first a list is built---seen as an almost linear growth in
a region; then follows a computation of the length of the list.  The
space behavior of the five ways of computing the length vary. We shall
have more to say about the time behavior in what follows.

As one would expect, {\tt nlength} leads to a peak in stack size; it
does not use regions. The peak in stack size is caused by the stacking
of a return address.

Next, we see that {\tt tlength} is an improvement over {\tt nlength},
the main reason being that the MLKit has figured out that the argument
to {\tt tlength} can be passed unboxed; thus no regions are used to
hold the argument pair. However, if we chose to disable the unboxing
of arguments that the MLKit performs,\footnote{Unboxing of function
  arguments can be disabled by passing the option
  \texttt{-no\_unbox\_function\_arguments} to the MLKit compiler.} the
function would become region-polymorphic and the polymorphic recursion
in regions would allow the pair \boxml{(xs, acc+1)} to be stored in a
region different from the argument pair to {\tt tlength'}. In this
case, what appeared to be a tail call would in fact not be a tail
call, for it would automatically be enclosed in a {\tt let region}
construct, introducing a fresh region for each argument pair
\boxml{(xs, acc+1)}.  This region would be finite, so it would be
allocated on the stack.  Thus, with unboxing of function arguments
disabled, we would see a sharp increase in stack size for {\tt
  tlength'}. Although unboxing of function arguments saves us in this
situation, we cannot always expect it to do so; if we were to collect
boxed data in accumulating parameters to the function and this data is
not to be returned by the function, there is a danger that the
recursive call would not become a tail call due to the introduction of
a {\tt let region} construct being wrapped around the recursive
call.\footnote{The MLKit features an option
  \texttt{--preserve\_tail\_calls}, which ensures that no
  \texttt{region} binding is wrapped around a tail-call. This
  option is enabled by default when garbage collection is enabled.}

The next function, {\tt klength}, deserves careful study, because it
is a prototype of a particular schema that can be used again and again
when programming with regions. Iteration is done by a
\index{region endomorphism}%
region endomorphism, {\tt loop}, which is declared as a local function
to the main function. The use of the same variable {\tt p} on both the
left-hand side and the right-hand side of the declaration of {\tt
  loop} forces {\tt loop} to be a region endomorphism. Because the
result of \boxml{loop(xs,acc+1)} is also the result of {\tt loop}, the
result of \boxml{loop(xs,acc+1)} therefore has to be in the same
region as {\tt p}; but because {\tt loop} is an endomorphism,
\boxml{(xs, acc+1)} is forced to be in the same region as {\tt p}.
Thus, what appears to be a tail call ({\tt loop(xs,acc+1)}) really
will be a tail call; in particular, there will be no fresh region for
the argument and no growth of the stack.

Better still, we have carefully arranged that memory consumption will
be constant throughout the computation of the length of the list.
First, the argument to the initial call of {\tt loop} is a pair
\boxml{(l, 0)} constructed at that point. Because {\tt loop} is a
region endomorphism, the result of \boxml{loop(l, 0)} will be in the
same region as \boxml{(l, 0)}.  Moreover, because we then immediately
take the second projection of that pair, that region is clearly local
to the body of {\tt klength}.  Call the region $\rho$. Because there
can be an unbounded number of stores into this region, $\rho$ is
classified as infinite by multiplicity inference.

The storage mode passed along with $\rho$ in the initial call
\boxml{loop(l,0)} is {\tt atbot}, by rule (B2) of
Section~\ref{sma.sec}. Inside {\tt loop}, the storage mode given to
the allocation of \boxml{(xs, acc+1)} is {\tt sat}, by rule (B3) of
Section~\ref{sma.sec}: the only locally live variable at the point
where the allocation takes place is {\tt loop}, which we must not
destroy before calling! The region that {\tt loop} lies in is clearly
different from $\rho$.

Therefore, every iteration of {\tt loop} resets the infinite region
$\rho$ so that it will contain at most one pair.  This is seen very
clearly in the third hump of Figure~\ref{length.region.fig}.

Next consider {\tt llength}. The difference from {\tt klength} is that
{\tt llength'} is now declared outside {\tt llength}.  Although the
use of {\tt local} makes it clear that {\tt llength'} is not exported
from the compilation unit, {\tt llength'} must in fact reside in a
global region, because {\tt llength}, which is exported, calls {\tt
  llength'}.  Nonetheless, the storage mode analysis still achieves
constant memory usage. As before, we have arranged that iteration is
done by a region endomorphism that is initially applied to a freshly
constructed pair. This pair can reside in a region that is local to
the body of {\tt llength} (once again, the projection
\verb+#2(llength'(l, 0))+ makes sure that the pair does not escape the
body of {\tt llength}).  The crucial bit is now what storage mode {\tt
  llength'} uses when it stores \boxml{(xs, acc+1)}.  The only locally
live variable at that point is {\tt llength'} itself and, as we noted
earlier, {\tt length'} lives in a global region, which is clearly
different from the region inside {\tt llength} that contains all the
pairs.  Thus, storage mode {\tt sat} will be used, as desired.

Finally, consider {\tt glength}, which is similar to {\tt llength},
but with the crucial difference that {\tt global} is exported from the
compilation unit. Because {\tt global} may be called from a different
compilation unit, then, for all we know, {\tt global} may be applied
to a pair that resides in the same (global) region as {\tt global}
itself. Using {\tt sat} when storing {\tt (xs, acc+1)} would then be a
big mistake: it would destroy the very function that we are trying to
call! Therefore, the storage mode analysis assigns {\tt attop} to that
storage operation.\footnote{To be precise, {\tt attop} comes about by
  using rule (B3) of Section~\ref{sma.sec}. This example illustrates
  why we put edges from formal region parameters to global regions for
  exported functions when constructing the region flow graph. Notice
  also that storage mode analysis does not take region runtime types
  into account.}  Consequently, we get a memory leak, as shown in the
final hump of Figure~\ref{length.region.fig}.

To sum up, here is how one writes a loop without using space
proportional to the number of iterations:
\index{length of list}%
\begin{enumerate}
\item The iteration should be done by an auxiliary, uncurried function
  that is declared as local to the function that uses it; we refer
  (informally) to this auxiliary function as the
  \index{iterator}%
  {\em iterator}.
\item The iterator should be a
  \index{region endomorphism}%
  region endomorphism and should be tail recursive.
\item Iteration should start from a suitably fresh initial argument;
  the result of the iteration should be kept clearly separate from the
  region where the iterator function lies.
\end{enumerate}
Mutual recursion poses no additional complications. All functions in a
block of mutually recursive functions are put in the same region.

Finally, the reader may be concerned that the two recommended
solutions, {\tt klength} and {\tt llength}, are much slower than the
other versions. This is partly an artifact of the profiling
software.\footnote{When profiling is turned on, every resetting of a
  region involves resetting of values in the first region page of the
  region.} To get a better picture of the actual cost of the different
versions, we compiled the five programs separately (using lists of
length 10 million instead of 5 million) and then ran the programs on a
Mac Book Pro with 16Gb RAM and a 2,7 GHz Quad-Core Intel Core i7
processor.\footnote{For larger lists, the \texttt{nlength} program may
  cause stack overflow.}  The results are shown in
Figure~\ref{length.timing.fig}. Because {\tt upto} alone takes 0.12
seconds to build the list, the differences in times are clear: the
version of the length function that does not use the stack and that
takes its argument in registers (i.e., \texttt{tlength}) is the
fastest. The recommended versions of the length function (i.e.,
\texttt{klength} and \texttt{llength}) run as well as the versions
that make use of the runtime stack (i.e., \texttt{nlength} and
\texttt{glength}), but are scalable and follow general useful
approaches to writing recursive functions.

\begin{figure}
\hrule
\medskip
\begin{center}
\def\arraystretch{1.4}
\begin{tabular}{l|cccccc}
Program      & {\tt upto} & {\tt nlength} & {\tt tlength} & {\tt klength} & {\tt llength} & {\tt glength} \\ \hline
Time (s) & 0.12 & 0.25 & 0.15 & 0.22 & 0.23 & 0.26
\end{tabular}
\end{center}
\caption{User time in seconds for building a list of 10 million elements and
computing its length, using five different length functions. {\tt upto} builds
the list, but does not compute a length. Times are average
over three runs.}
\label{length.timing.fig}
\medskip
\hrule
\end{figure}

\section{\texttt{resetRegions} and \texttt{forceResetting}}
It is often the case that there are only a few places in the program
where resetting is really essential, for example in some main loop.
Therefore, the MLKit provides two operations that the programmer can use
to encourage (or force) the MLKit to perform resetting at particular
places in the program. The two operations are
\index{resetRegions@\texttt{resetRegions}}
$$\resetr\; {\it vid}$$
and \index{forceResetting@$\resetf$}
$$\resetf\; {\it vid}$$
In both cases, the argument has to be a value
identifier.  To port programs that contain {\tt resetRegions} and {\tt
  forceResetting} to other ML systems, simply declare
\begin{verbatim}
  fun resetRegions _ = ()
  fun forceResetting _ = ()
\end{verbatim}
before compiling the program developed using the MLKit.

Let $\rho$ be a region variable that occurs free in the
region-annotated type scheme with place of {\it vid}.  Let $m$ be the
storage mode determined for $\rho$ at a program point according to the
rules of the previous section.  Whether resetting of {\it vid\/} at that
program point actually takes place at runtime, depends on $m$ and on
whether resetting is forced, see Figure~\ref{smamodes.fig}.

\begin{figure}
\hrule
\medskip
\begin{center}
\def\arraystretch{1.4}
\setlength\tabcolsep{3mm}
\begin{tabular}{p{1.4in}|p{1.8in}|p{1.3in}}
Does resetting take place at runtime? & \resetr     & \resetf \\ \hline
$m=\atbot$ & yes      &  yes \\ \hline
$m=\sat$   & only if runtime storage mode is {\tt atbot}        &  yes$\ast$ \\ \hline
$m=\attop$ & no$\ast$  &  yes$\ast$
\end{tabular}
\smallskip

($\ast$): A compile-time warning is printed in this case.
\end{center}
\caption{The storage modes that will be used when resetting a region
depending on $m$, the storage mode inferred by the storage mode analysis,
and depending on whether the resetting is safe ($\resetr$) or potentially
unsafe ($\resetf$).}
\label{smamodes.fig}
\medskip
\hrule
\end{figure}

\section{Example: Improved Mergesort}
\label{improvedmerge.sec}
We can now improve on the
\index{merge sort}%
\index{msort@\texttt{msort}}%
mergesort algorithm (Section~\ref{polyrec.sec}) by taking storage
modes into account. Splitting a list can be done by an iterative
region endomorphism that is made local to the sorting function.  Also,
when the input list has been split, it is no longer needed, so the
region it resides in can be reset. Similarly, when the two smaller
lists have been sorted (into new regions) the regions of the smaller
lists can be reset. These three simple observations lead to the
variant of {\tt msort} listed in
Figure~\ref{msortreset1.fig}.\footnote{MLB-file:
  \boxml{kitdemo/msortreset1.mlb}, file
  \boxml{kitdemo/msortreset1.sml}.}
\begin{figure}
\hrule
\medskip
\begin{verbatim}
  local
    fun cp [] = []
      | cp (x::xs) = x :: cp xs

    (* exormorphic merge *)
    fun merge(xs, []) : int list = cp xs
      | merge([], ys) = cp ys
      | merge(l1 as x::xs, l2 as y::ys) =
          if x<y then x :: merge(xs, l2)
          else y :: merge(l1, ys)

    (* splitting a list *)
    fun split(x::y::zs, l, r) = split(zs, x::l, y::r)
      | split(x::xs, l, r) = (xs, x::l, r)
      | split(p as ([], l, r)) = p

    (* exomorphic merge sort *)
    fun msort []  = []
      | msort [x] = [x]
      | msort xs = let val (_, l, r) = split(xs, [], [])
                   in resetRegions xs;
                      merge(msort l before resetRegions l,
                            msort r before resetRegions r)
                   end
  in
    val runmsort = msort(upto 200000)
    val result = print "Really done\n"
  end
\end{verbatim}
\caption{Variant of {\tt msort} that uses {\tt resetRegions} to improve
  memory usage. The MLKit fails to infer that the region holding the
  argument list {\tt xs} can be reset after {\tt xs} is split.}
\label{msortreset1.fig}
\medskip \hrule
\end{figure}

Unfortunately, the storage mode analysis complains:
\begin{verbatim}
 *** Warnings ***
resetRegions(xs):
   You have suggested resetting the regions that appear free
   in the type scheme with place of 'xs', i.e., in
   (int, [r104]) list
   (1)
        'r104': there is a conflict with the locally
        live variable
        v187 :(int, [r113]) list
        from which the following region variables can be reached
        in the region flow graph:
             {r113}
        Amongst these, 'r113' can also be reached from 'r104'.
        Thus I have given 'r104' storage mode "attop".
\end{verbatim}
There is one complaint concerning the first $\resetr$, but none
concerning the two remaining ones.  By inspecting the region-annotated
term one sees that \boxml{r104} is a formal parameter of {\tt msort}.
Due to the recursive call {\tt msort l}, the region graph contains an
edge from \boxml{r104} to \boxml{r113}. Thus the analysis decides on
{\tt attop}, using rule (B3). This choice shows a weakness in the
analysis, for using {\tt sat} would really be sound. (The problem is
that, unlike polymorphic recursion, the region flow graph does not
distinguish between different calls of the same function.)  Seeing
that this is the problem, we decide to put $\resetf$ to work, see
Figure~\ref{force.fig}.\footnote{MLB-file:
  \boxml{kitdemo/msortreset2.mlb}, file
  \boxml{kitdemo/msortreset2.sml}.}
\begin{figure}
\hrule\medskip
\begin{verbatim}
  local
    fun cp [] = []
      | cp (x::xs) = x :: cp xs

    (* exormorphic merge *)
    fun merge(xs, []) : int list = cp xs
      | merge([], ys) = cp ys
      | merge(l1 as x::xs, l2 as y::ys) =
          if x<y then x :: merge(xs, l2)
          else y :: merge(l1, ys)

    (* splitting a list *)
    fun split(x::y::zs, l, r) = split(zs, x::l, y::r)
      | split(x::xs, l, r) = (xs, x::l, r)
      | split(p as ([], l, r)) = p

    (* exomorphic merge sort *)
    fun msort []  = []
      | msort [x] = [x]
      | msort xs = let val (_, l, r) = split(xs, [], [])
                   in forceResetting xs;
                      merge(msort l before resetRegions l,
                            msort r before resetRegions r)
                   end
  in
    val runmsort = msort(upto 200000)
    val result = print "Really done\n"
  end
\end{verbatim}
\caption{Using {\tt forceResetting} to reset regions.}
\medskip
\hrule
\label{force.fig}
\end{figure}
The region profile of the improved merge sort appears in
Figure~\ref{msortreset.fig}. As expected, we have now brought space
consumption down from four times to two times the size of the input.
Figure~\ref{msortreset.fig} may be compared to
Figure~\ref{msortregion.fig} on page~\pageref{msortregion.fig}.

\begin{figure}
\includerp{msortreset2.pdf}
\index{region.ps@\texttt{region.ps}}%
\index{sampleMax@\texttt{-sampleMax} option}%
\index{eps file@\texttt{-eps} option}%
\index{rp2ps@\texttt{rp2ps}}%
\caption{Region profiling of the improved mergesort.
  The upper triangle contains unsorted elements, while the lower
  triangle contains sorted elements.  The program was compiled with
  profiling enabled and then run with the command \boxml{run -microsec 1000}.
  The PostScript picture \boxml{region.ps} was generated
  with the command \boxml{rp2ps -region -sampleMax 200}
  and then converted into \boxml{region.pdf} with \texttt{ps2pdf}.}
\label{msortreset.fig}
\end{figure}

\section{Example: Scanning Text Files}
\label{scan.sec}
In this section we present a program that can
\index{scan@\texttt{scan}}%
scan a sequence of Standard ML source files and compute what
percentage of the source files is made up by comments. Recall that an
ML comment begins with the two characters {\tt (*}, ends with {\tt
  *)}, and that comments may be nested but must be balanced (within
each file, we require).

The obvious solution to this problem is to implement an automaton with
counters to keep track of the level of nesting of parentheses, number
of characters read, and number of characters within comments. This solution
provides an interesting test for region inference: although designed
with the lambda calculus in mind, does the scheme cope with good
old-fashioned state computations?

Let us be ambitious and write a program that only ever holds on to one
character at a time when it scans a file. In other words, the aim is
to use constant space (i.e., space consumption should be independent
of the length of the input file).

To this end, let us arrange to use a region with infinite multiplicity to
hold the current input character and then reset that region before we proceed
to the next character. The iteration is done by tail recursion, using region
endomorphisms to ensure constant space usage.

The bulk of the program appears below.\footnote{MLB-file:
  \boxml{kitdemo/scan.mlb}, file: \boxml{kitdemo/scan.sml}.} The
scanning of a single file is done by {\tt scan}, which contains three
mutually recursive region endomorphisms ({\tt count}, {\tt
  after\_lpar}, and {\tt after\_star}) written in accordance with
the guidelines in Section~\ref{length.sec}.

It turns out that the constraints we have put on ourselves with running
in constant space does work well with the combination of how
\texttt{TextIO} input streams buffers input data. Instead, we shall
make use of the lower-level \texttt{Posix} operations for opening and
reading files.

The built-in function {\tt Posix.IO.readVec}, which reads a vector of
bytes from an open file descriptor, understands storage modes; if
called with storage mode {\tt atbot}, it will reset the region where
the byte vector should be put before reading the bytes from the file
descriptor.  Consequently, at every call of {\tt next}, the ``input
buffer region'' will be reset.

The other important loop in the program is {\tt driver}, a function
that repeatedly reads a file name from a given file descriptor, opens the
file with that name, and calls {\tt scan} to process the file. Once
again, we want to keep at most one file name in memory at a time, so
we would like the region containing the file name to be reset upon
each iteration.  As it turns out, {\tt readWord} will always try to
store the string it creates at the bottom of the region in question.

In general however, when splitting a program unit into two, one may
have to insert explicit $\resetr$ into the second unit, when
operations from the first unit are called. This extra resetting may be
necessary because formal region parameters of exported functions are
connected to global regions in the region flow graph (cf., rule B3).

\bigskip
\hrule
\begin{verbatim}
local
  structure F = Posix.FileSys

  exception NotBalanced
  fun scan fd : int * int =
    let
      fun next () = Byte.bytesToString(Posix.IO.readVec(fd,1))
      fun up (lev,ins) = if lev > 0 then ins + 1
                         else ins

      (* n   : characters read from 'fd'
         ins : characters inside comments
         lev : current (level) number of unmatched (*
         s   : next input character or empty *) *)

      fun count (p as (n,ins,lev,s)) =
        case s of
          "" => (* end of stream: *) p
        | "(" => after_lpar(n+1,ins,lev,next())
        | "*" => after_star(n+1,up(lev,ins),lev,next())
        | _  => count(n+1,up(lev,ins), lev,next())
      and after_lpar (p as (n,ins,lev,s)) =
        case s of
          "" => p
        | "*" => count(n+1,ins+2, lev+1,next())
        | "(" => after_lpar(n+1,up(lev,ins),lev,next())
        | _ => count(n+1,up(lev,up(lev,ins)),lev,next())
      and after_star (p as (n,ins,lev,s)) =
        case s of
          "" => p
        | ")" => if lev > 0 then
                    count(n+1,ins+1,lev-1,next())
                 else raise NotBalanced
        | "*" => after_star(n+1,up(lev,ins),lev,next())
        | "(" => after_lpar(n+1,ins,lev,next())
        | _  => count(n+1,up(lev,ins),lev,next())

      val (n,ins,lev,_) = count(0,0,0,next())

    in if lev=0 then (n,ins) else raise NotBalanced
    end

  fun report_file (filename, n, ins) =
      writeln (filename ^ ": size = " ^ Int.toString n
	       ^ " comments: " ^ Int.toString ins ^ " ("
	       ^ (Int.toString(percent(ins, n))
		  handle _ => "") ^ "%)");

  (* scan_file(filename) scans through the file named filename
     returning either SOME(size_in_bytes, size_of_comments)
     or, in case of an error, NONE. In either case a line of
     information is printed. *)

  fun scan_file filename : (int*int) option =
      let val fd = F.openf (filename, F.O_RDONLY, F.O.flags[])
      in let val (n, ins) = scan fd
         in Posix.IO.close fd;
            report_file (filename, n, ins);
            SOME (n, ins)
         end handle NotBalanced =>
                    (writeln (filename ^ ": not balanced");
                     Posix.IO.close fd;
                     NONE)
      end handle IO.Io {name,...} =>
                 (writeln (name ^ " failed."); NONE)

  fun report_totals (n, ins) =
      writeln ("\nTotal sizes: " ^ Int.toString n
	       ^ " comments: " ^ Int.toString ins
	       ^ " (" ^ (Int.toString (percent (ins, n))
			 handle _ => "") ^ "%)")

  (* main(fd) reads a sequence of filenames from fd, one file
     name pr line (leading spaces are skipped; no spaces
     allowed in file names). Each file is scanned using
     scan_file after which a summary report is printed *)

  fun main fd : unit =
      let fun driver (p as (NONE, n, ins)) =
              (report_totals(n, ins); p)
            | driver (p as (SOME filename, n, ins)) =
              driver (case scan_file filename of
                          SOME(n', ins') =>
                          ( resetRegions p
                          ; (readWord fd, n+n', ins+ins')
                          )
                        | NONE => ( resetRegions p
                                  ; (readWord fd, n, ins)
                                  )
                     )
      in driver (readWord fd, 0, 0); ()
      end
in
  val result = main F.stdin
end
\end{verbatim}
\hrule
\bigskip

The program was compiled both with and without profiling turned on.
The output from running the program on 14 of the source files for the
MLKit is shown here:
\begin{verbatim}
Parsing/Infixing.sml: size = 32156 comments: 5294 (16%)
Parsing/Parse.sml: size = 4537 comments: 726 (16%)
Parsing/Topdec.grm.sml: size = 195869 comments: 4698 (2%)
Parsing/GRAMMAR_UTILS.sml: size = 4818 comments: 701 (14%)
Parsing/INFIX_STACK.sml: size = 487 comments: 321 (65%)
Parsing/Topdec.lex.sml: size = 49968 comments: 1023 (2%)
Parsing/LEX_BASICS.sml: size = 2046 comments: 1289 (63%)
Parsing/LEX_UTILS.sml: size = 1575 comments: 383 (24%)
Parsing/GrammarUtils.sml: size = 17002 comments: 1820 (10%)
Parsing/LexBasics.sml: size = 12649 comments: 3987 (31%)
Parsing/MyBase.sml: size = 33803 comments: 11124 (32%)
Parsing/HOOKS.sml: size = 312 comments: 170 (54%)
Parsing/InfixStack.sml: size = 7404 comments: 2972 (40%)
Parsing/LexUtils.sml: size = 8305 comments: 487 (5%)

Total sizes: 370931 comments: 34995 (9%)
\end{verbatim}
A region profile for that run is shown in Figure~\ref{scan.fig}.  The
almost-constant space usage is evident. The occasional disturbances
are due to the non-iterative functions that read a file name from
input by first reading one line and then extracting the name.
\begin{figure}
\includerp{scan.pdf}
\caption{Region profile of the comment scanner. The occasional
  increases in memory use is due to the functions that read a file
  name from a file descriptor.  The program was compiled with
  profiling enabled, then run with the command \texttt{run -notimer
    1000 < ../kitdemo/scanfiles}. A PostScript file \texttt{region.ps}
  can be generated with the command \texttt{rp2ps -region -sampleMax
    200} and converted to \texttt{region.pdf} using \texttt{ps2pdf
    region.ps region.pdf}. }
\label{scan.fig}
\end{figure}


%---------------------------------------------------------
\chapter{Higher-Order Functions}
\label{hof.sec}
%---------------------------------------------------------

\section{Lambda Abstractions (\texttt{fn})}
A {\em lambda abstraction\/}
\index{lambda abstraction}%
\index{function!higher-order}%
in Standard ML is an expression of the form
$$\boxml{fn {\it pat} => {\it exp}}$$
where {\it pat\/} is a pattern
and {\it exp\/} an expression.  Lambda abstractions denote functions.
We refer to the {\it exp\/} as the {\em body\/} of the function;
variable occurrences in {\it pat\/} are binding occurrences;
informally, the variables that occur in {\it pat\/} are said to be
\index{variable!lambda-bound}%
{\em lambda-bound\/} with scope {\it exp}.

Lambda abstractions are represented by closures, both in the language
definition and in the MLKit. In the MLKit, a closure for a lambda
abstraction consists of a code pointer plus one word for each free
variable of the lambda abstraction. Closures are not tagged except
when garbage collection is enabled, in which case a closure contains
one or more words to hold the tag.

At this stage, it will hardly come as a surprise to the reader that
closures are stored in regions.  Sometimes they reside in finite
regions on the stack, other times they live in infinite regions, just
like all other boxed values.

Every occurrence of {\tt fn}
\index{fn@\texttt{fn}}%
in the program is considered an allocation point; the region-annotated
version of the lambda abstraction is
$$\boxml{fn $\at\,\rho$ {\it pat} => {\it exp}}$$
Standard ML allows
functions to be declared using {\tt val} rather than {\tt fun}, for
example,
\begin{verbatim}
  val h = g o f
\end{verbatim}
declares the value identifier {\tt h} to be the composition of {\tt g}
and {\tt f}.  Whereas functions declared with
\index{fun@\texttt{fun}}%
{\tt fun} automatically become region-polymorphic, functions
declared with
\index{val@\texttt{val}}%
{\tt val} do not in general become
\index{region polymorphism}%
region-polymorphic.\footnote{The reason for this is that the
  expression on the right-hand side of the value declaration might
  have an effect (e.g, print something) before returning the function.
  It would not be correct to suspend this effect by introducing formal
  region parameters.} However, in the special case where the
right-hand side of the value declaration is a
\index{lambda abstraction}%
lambda abstraction, the MLKit automatically converts the declaration
into a {\tt fun} declaration, thereby making the function
region-polymorphic after all.

ML allows declarations of the form
\index{fun@\texttt{fun}}%
$$\boxml{fun $f$ $\atpat_1\,\atpat_2 \cdots \atpat_n$ = $\exp$}$$
as a shorthand for
$$\boxml{fun $f$ $\atpat_1$ = fn $\atpat_2$ => $\cdots$ fn $\atpat_n$
  => $\exp$}$$
where $\atpat$ ranges over atomic patterns.  Functions
declared using this abbreviation are said to be
\index{function!Curried}%
{\em Curried}.

\section{Region-Annotated Function Types}
\label{functiontypes.sec}
The general form of a region-annotated
\index{function type!region-annotated}%
\index{type!region-annotated}%
function type is
$$([\mu_1,\cdots,\mu_n] \ar{\epsilon.\rea} \mu', \rho)$$
where
$\mu_1,\cdots\mu_n$ are the type with places of the arguments, $\mu'$
is the type with place of the result, and $\rho$ is the region
containing the closure for the function. When a function type has only
one argument type, we shall often write it on the form $(\mu
\ar{\epsilon.\rea} \mu', \rho)$, and so shall the MLKit.

As mentioned in Section~\ref{listtypes.sec}, the unusual looking
object $\epsilon.\rea$ is called an
\index{arrow effect}%
{\em arrow effect}. Its first component
is an
\index{effect variable}%
effect variable, whose purpose will be explained shortly.  The second
component is called the
\index{effect!latent}%
{\em latent effect}, and describes the effect of evaluating the body
of the function.

The following example illustrates why latent effects are crucial for
knowing the lifetimes of closures.\footnote{Program
  \boxml{kitdemo/lambda.sml}.} Consider
\begin{verbatim}
  val n = let val f = let val xs = [1,2]
                      in fn ys => length xs + length ys
                      end
          in f [7]
          end
\end{verbatim}
Notice that {\tt xs} has to be kept alive for as long as the function
\boxml{(fn ys => $\cdots$)} may be called, for this function will
access {\tt xs}, when called.  The region-annotated version of the
example appears in Figure~\ref{lambda1.fig}.\footnote{To see the
  output programs discussed in this section, enable the flag
  \texttt{-print\_drop\_regions\_expression}.}
\begin{figure}
\hrule \medskip
\begin{verbatim}
   let val n =
         let region r134:INF, r141:INF, r150:1;
             val f =
               let val xs = [1,2] attop r134
               in  fn atbot r150 ys =>
                     length[] xs + length[] ys
               end
         in  f [7] attop r141
         end
   in  {|n: _|}
   end
\end{verbatim}
\caption{Region-annotated program illustrating that the lifetime of
  a closure is at least as long as the lifetime of the values that
  evaluation of the function body will require.}  \medskip \hrule
\label{lambda1.fig}
\end{figure}
We see that {\tt xs} is put in {\tt r134}, that the function closure
for \boxml{(fn ys => $\cdots$)} is put in {\tt r150} and indeed, {\tt
  r134} and {\tt r150} have the same lifetime. To understand how the
region inference system figured that out, let us consider the effect
and the region-annotated types of particular sub-expressions. Looking
at the lambda abstraction, it must have a functional type of the form
$(\tau\ar{\epsilon.\rea}\tau', {\tt r150})$ where $\rea$ is the effect
$$\{\Get(\boxml{r1}), \Get(\boxml{r134}), \Get(\boxml{r141})\}$$
Notice
that \boxml{r134} occurs free in the type of the lambda abstraction.
But, as pointed out in Section~\ref{effects.sec}, the criterion
\index{region!de-allocation}%
for putting a {\tt region} binding of $\rho$ around an expression
$e$ is that $\rho$ occurs free neither in the type with place of $e$
nor in the type scheme with place of any variable in the domain of the
type environment. The smallest sub-expression of the program for which
{\tt r134} does not occur free in the type with place of the expression
is the right-hand side of the {\tt val} binding of {\tt n}, for that
expression simply has type with place $\boxml{int}$.  And at that
point, the only region variables that occur free in the type
environment are global region variables.  Hence the placement of the
{\tt region} binding of {\tt r134}.

\section{Arrow Effects}
In a first-order language, effect variables might not be particularly
important.  But in a higher-order language like ML, effect variables
are useful for tracking dependencies between functions. The following
example illustrates the point:\footnote{Program
  \boxml{kitdemo/apply.sml}.}
\begin{verbatim}
  fun apply f x = f x
  val y = apply (fn n => n + 1.0) 5.0
  val z = apply (fn m => m) 6
\end{verbatim}
Here is the region-annotated type scheme of {\tt apply}:
\begin{tabbing}
\qquad$\forall\alpha_0\alpha_2\rho_7\rho_8\epsilon_{11}\epsilon_{12}\epsilon_{13}.$\=$(\alpha_0
        \ar{\epsilon_{11}.\emptyset}\alpha_2,\rho_8)\ar{\epsilon_{12}.\{\Put(\rho_7)\}}$\\
            \>$(\alpha_0\ar{\epsilon_{13}.\{\Get(\rho_8), \epsilon_{11}\}}\alpha_2,\rho_7)$
\end{tabbing}
The latent effect associated with $\epsilon_{12}$ shows that when {\tt
  apply} is applied to a function, it may create (in fact: will
create) a function closure in $\rho_7$.  The latent effect associated
with $\epsilon_{11}$ is empty, because the declaration of {\tt apply}
does not tell us anything about what effect its formal parameter {\tt
  f} must have. Crucially, however, $\epsilon_{11}$ is included as an
atomic effect in the latent effect associated with $\epsilon_{13}$;
whenever the body of {\tt apply f} is evaluated, the body of {\tt f}
may be (in fact: will be) evaluated.

The polymorphism in effects makes it possible to distinguish between
the latent effects of different actual arguments to {\tt apply}. For
example, the functions {\tt (fn n => n + 1.0)} and {\tt (fn m => m)}
have different latent effects. Let us take the function {\tt (fn n =>
  n + 1.0)} as an example. It has region-annotated type with place
\begin{equation}
\label{suc.lab}
((\boxml{real},\rho_{18})\ar{\epsilon_{14}.\{\Get(\rho_{18}),\Put(\rho_5)\}}(\boxml{real}, \rho_5), \rho_{17})
\end{equation}
Here, the effect variable $\epsilon_{14}$ and the region variables
$\rho_{18}$ and $\rho_5$ were chosen arbitrarily. (Actually, the
region variable $\rho_5$ denotes the global region for reals.) The
region inference algorithm discovers that (\ref{suc.lab}) can be
derived from the argument type
$$(\alpha_0\ar{\epsilon_{11}.\emptyset}\alpha_2,\rho_8)$$
of the type scheme for {\tt apply} by the instantiating substitution
$$S =(\!\!\begin{array}[t]{l}\{\alpha_0\mapsto(\boxml{real},\rho_{18}),\alpha_2\mapsto(\boxml{real}, \rho_5)\},\{
       \rho_8\mapsto\rho_{17}\},\\
     \{\epsilon_{11}\mapsto\epsilon_{14}.\{\Get(\rho_{18}),\Put(\rho_5)\})
   \end{array}$$
Formally, a
\index{substitution}%
{\em substitution\/} is a triple $(\St,\Sr,\Se)$, where $\St$ is a
finite map from type variables to region-annotated types, $\Sr$ is a
finite map from region variables to region variables, and $\Se$ is a
finite map from effect variables to arrow effects.  Let us explain why
substitutions map effect variables to arrow effects.  One alternative,
one might consider, is to let substitutions map effect variables to
effect variables. But then substitutions would not be able to account
for the idea that effects can grow, when instantiated. In the {\tt
  apply} example, for instance, the empty effect associated with
$\epsilon_{11}$ has to grow to $\{\Get(\rho_{18}),\Put(\rho_5)\}$ at
the concrete application of {\tt apply}. Otherwise, as it is easy to
demonstrate, the region inference system would become unsound.

Another alternative would be to let substitutions map effect variables
to effects. But nor that would work well together with the idea of
using substitutions to express growth of effects. For example,
when applying the map $\{\epsilon\mapsto\{\Get(\rho_0),\Put(\rho_2)\}\}$ to
the effect $\{\Get(\rho_9),\epsilon\}$, say, we would presumably yield
the effect $\{\Get(\rho_9),\Get(\rho_0),\Put(\rho_2)\}$ in which the
fact that the original effect had to be at least as large as whatever
$\epsilon$ stands for, is lost.  Instead, we define substitution so
that applying the effect substitution
$\{\epsilon\mapsto\epsilon.\{\Get(\rho_2),\Put(\rho)\}\}$ to
$\{\Get(\rho_9),\epsilon\}$ yields
$\{\Get(\rho_9),\epsilon,\Get(\rho_2),\Put(\rho)\}$.

We can now give a complete definition of atomic effects.  An
\index{effect!atomic, definition}%
{\em atomic effect\/} is either an effect variable or a term of the
form $\Get(\rho)$ or $\Put(\rho)$, where $\rho$ as usual ranges over
region variables. An
\index{effect!definition}%
{\em effect\/} is a finite set of atomic effects.

One can get the MLKit to print region-annotated
\index{type!region-annotated}%
\index{region-annotated type scheme!printing of}%
type schemes with places of all binding occurrences of value
variables.  Also, one can choose to have arrow effects included in the
printout by passing the options \texttt{print\_types} and
\texttt{print\_effects} to the MLKit compiler. Although passing these
options gives very verbose output, it is instructive to look at such a
term at least once, to see how arrow effects are instantiated. We show
the full output for the {\tt apply} example in Figure~\ref{apply.fig}.

\begin{figure}
\hrule \medskip
\begin{verbatim}
  fun apply
      :all
          r18,r16,e15,e19,e17,'a0,'a2.
          ('a0-e15->'a2,r16)
          -e19(put(r18))->
          ('a0-e17(U(U,get(r16),e15))->'a2,r18)
      attop r1
      [r18:1]
      [r16:0]
      (f) =
      fn attop r18 x:'a0 => f x;
  val y:(real,r1) =
    let region r21:1, r23:1, r24:1
    in   apply
          [atbot r24]
          [(real,r21),(real,r1)]
          [r24,r23]
          [e27(get(r21),put(r1)),
           e26(put(r24)),
           e25(e27(get(r21),put(r1)),get(r23))]
         (fn atbot r23 n:(real,r21) =>
           f64_to_real(attop r1, real_to_f64(n) + 1.0f64))
         5.0attop r21
    end;
  val z:int =
    let region r42:1, r43:1
    in   apply
          [atbot r43]
          [int,int]
          [r43,r42]
          [e46,e45(put(r43)),e44(e46,get(r42))]
         (fn atbot r42 m:int => m)
         6
    end
\end{verbatim}
\caption{The instantiation of arrow effects keeps different applications of
  the same function (here {\tt apply}) apart. The output was obtained
  by compiling the program \boxml{kitdemo/apply.sml} with options
  \texttt{-print\_types}, \texttt{-print\_effects}, \texttt{-no\_uncurry} and
  \texttt{-maximum\_inline\_size 0}.}  \medskip \hrule
\label{apply.fig}
\end{figure}

In reading the output, it is useful to know that the MLKit represents
effects and arrow effects as graphs, the nodes of which are region
variables, effect variables, $\Put$, $\Get$, or \boxml{U} (for
``union''; \boxml{U} by itself means the empty set).  Region variables
are leaf nodes. A $\Put$ or $\Get$ node has emanating from it
precisely one edge; it leads to the region variable in question.  An
effect variable node (written {\tt e} followed by a sequence number)
is always the handle of an arrow effect; there are edges from the
effect variable to the atomic effects of that arrow effect, either
directly, or via union nodes or other effect variable nodes.  For
instance, \boxml{e13(U(U,get(r8),e11))} in the figure denotes an
effect variable with an edge to a union node that has edges to an
empty union node, a $\Get$ node, and an effect variable node.

When a term containing arrow effects is printed, shared nodes that
have already been printed are marked with a \boxml{@}; their children
are not printed again.
%For instance, in the figure, the second
%occurence of \texttt{r2} is printed as \boxml{@r2}.
In the figure, the binding occurrence of {\tt apply} has been printed
with its region-annotated type scheme. Each non-binding occurrence of {\tt
  apply} has been printed with four square-bracketed lists. The first
list is the actual region arguments; the following three are
instantiation lists that show the range of the substitution by
which the bound variables of the type scheme was instantiated, in the
same order as the bound variables occurred.  For example, in the
second use of {\tt apply}, \boxml{r8} was instantiated to {\tt r25}.

\section{On the Lack of Region Polymorphism}
Unlike identifiers bound by {\tt fun}, lambda-bound function
identifiers are never region-polymorphic. So in an expression of the
form
$$\boxml{fn f => $\cdots$ f $\cdots$ f $\cdots$}$$
all the uses of
$\boxml{f}$ use the same regions. Indeed, because \boxml{f} occurs
free in the type environment while region inference analyses the body
of the lambda abstraction, none of the regions that appear in the type
of \boxml{f} will be de-allocated inside the body of the lambda
abstraction. Also, such a region must be bound outside the lambda
abstraction, so any attempt to reset such a region inside the body of
the abstraction will cause the storage mode analysis to complain (by
Rule (B1) of Section~\ref{sma.sec}).

Therefore, when a function $f$ is passed as argument to another
function $g$, as in the expression \boxml{$g$($f$)}, first regions are
allocated for the use of $f$, then $g$ is called, and finally, the
regions are de-allocated (provided they are not global regions).
Whether the {\tt let region} construct thus introduced encloses the
call site immediately, as in
$$\boxml{let region $\rho_1,\ldots,\rho_n$ in $g$($f$) end}$$
or further out, as in
$$\boxml{let region $\rho_1,\ldots,\rho_n$ in $\ldots$ $g$($f$)
  $\ldots$ end}$$
depends on the type and effect of the expression
\boxml{$g$($f$)} in the usual way: regions can be de-allocated when
they occur free neither in the type with place of the expression
nor in the type environment.

\section{Examples: \texttt{map} and \texttt{foldl}}
Consider the program\footnote{Program \boxml{kitdemo/map.sml}.}
\begin{verbatim}
  fun map f [] = []
    | map f (x::xs) = f(x) :: map f xs

  val x = map (fn x => x+1) [7,11]
\end{verbatim}
This formulation of {\tt map} is not the most efficient one in the
MLKit, because it will create one closure for each element in the
list, due to currying.\footnote{When {\tt map} and the application of
  {\tt map} appear in the same compilation unit, the MLKit will
  automatically specialise {\tt map} to a recursive function that does
  not have this defect. This specialisation is the result of a general
  optimisation of curried functions that are invariant in their first
  argument. The output we present in this section was obtained by
  passing to the MLKit compiler the options
  \texttt{-maximum\_specialise\_size 0} and \texttt{-no\_uncurry}.} However it serves to
illustrate the point made in the previous section about allocating
regions in connection with higher-order functions. The
region-annotated version is listed in Figure~\ref{map.fig}.
\begin{figure}
\hrule \medskip
\begin{verbatim}
   let fun map attop r1 [r34:1, r20:0] (var1) =
            fn attop r34 var2 =>
            (case var2 of
               nil => nil
             | _ =>
               let val v102 = decon_:: var2;
                   val v103 = #0 v102;
                   val v104 = #1 v102
               in  :: (var1 v103, let region r28:1
                                  in map[atbot r28,attop r20]
                                       var1 v104
                                  end)attop r20
               end
            );
       val x =
         let region r37:1, r38:INF, r40:1
         in  map[atbot r40,attop r4]
              (fn atbot r37 x => x + 1) [7,11] attop r38
         end
   in  {|map: (_,r1), x: _|}
   end
\end{verbatim}
\caption{Although this version of {\tt map} creates a closure for
  each list element, the region-polymorphic recursion (of {\tt map})
  ensures that that closure is put in a region local to {\tt map}.
  Thus, these closures do not pile up in {\tt r37}, the region of the
  initial argument.}
\medskip \hrule
\label{map.fig}
\end{figure}
We see that the region that appears free in the type with place of the
successor function (i.e., \boxml{r37}) is allocated prior to the call
of {\tt map} and that it stays alive throughout the evaluation of the
body of {\tt map}. Notice, however, that the closures that are created
when {\tt map} is applied do not pile up in {\tt r37}, the region of
the successor function. Instead, they are put in local regions bound
to {\tt r28}, one closure in each region.  Also, if we had given some
more complicated argument to {\tt map}, the body of that function
could include local {\tt region} declarations. For each list element,
regions would then be allocated, used, and then de-allocated before
proceeding to the next list element.

So it might appear that higher-order functions are nothing to worry
about when programming with regions. That is not so, however. The
limitation that lambda-bound functions are never region-polymorphic
can lead to space leaks. Here is an example:
\begin{verbatim}
  fun foldl f acc [] = acc
    | foldl f acc (x::xs)  = foldl f (f(x,acc)) xs

  val x = foldl (fn (x,acc) => 10*acc+x) 0 [7,2]
\end{verbatim}
Because {\tt f} is lambda-bound, all the pairs created by the
expression \boxml{(x,acc)} will pile up in the same region. The
storage mode analysis will infer storage mode {\tt attop} for the
allocation of the pair, by rule (B1) of Section~\ref{sma.sec}; because
{\tt foldl} is curried, there are several lambdas between the formal
region parameter of {\tt foldl} that indicates where the pair should
be put and the allocation point of the pair.

It does not help to uncurry {\tt foldl} and turn {\tt foldl} into a
region endomorphism:
\begin{verbatim}
  fun foldl(p as (f,[],_)) = p
    | foldl(f,x::xs,acc) = foldl(f,xs,f(x,acc))

  val x = #3(foldl(fn(x,acc) => 10*acc+x,[7,2],0))
\end{verbatim}
The storage mode analysis will still give {\tt attop} for the
allocation of the pair \boxml{(x,acc)}, because the region of the pair
is free in the region-annotated type of \boxml{f}, which is locally
live at that point.

What if we require that {\tt f} be curried, so as to avoid the
creation of the pair altogether?\footnote{Program
  \boxml{kitdemo/fold2.sml}.}
\begin{verbatim}
  fun foldl f b xs =
    let fun loop(p as ([], b)) = p
          | loop(x::xs, b) = loop(xs,f x b)
    in #2(loop(xs,b))
    end
\end{verbatim}
The region-annotated version of this program appears in
Figure~\ref{fold2.fig} on page~\pageref{fold2.fig}. This saves the
allocation of a pair inside loop, although the saving is lost if the
evaluation of {\tt f x} creates a closure.

In short, folding a function over a list may leak two words of memory
for each list element.

%---------------------------------------------------------
\chapter{The Function Call}
%---------------------------------------------------------
Standard ML allows function applications of the form
$$\exp_1 \exp_2$$
where $\exp_1$ is the operator and $\exp_2$ is the
operand.  The syntax for function application is overloaded, in that
it is used for three different purposes in ML:
\begin{enumerate}
\item applications of built-in operations such as \boxml{+},
  \boxml{=}, and \boxml{:=}
\item applications of unary value constructors (including {\tt ref})
  and unary exception constructors
\item applications of user-defined functions, that is, functions
  introduced by {\tt fn} or {\tt fun}
\end{enumerate}
This chapter is about the last kind of function applications; in the
following, we use the term function application to stand for
applications of user-defined functions only.

Function applications are ubiquitous in Standard ML programs; in
particular, iteration is often achieved by function calls. Not
surprisingly, careful compilation of function calls is essential for
obtaining good performance.

The MLKit partitions function calls into four kinds, which are
implemented in different ways.  At best, a function call is simply
realised by a jump in the target code.  The resource conscious
programmer will want to know the special cases; for example, when
doing an iterative computation, it is important to know whether the
space usage is going to be independent of the number of iterations.

The MLKit performs a backwards flow analysis, called
\index{call conversion}%
{\em call conversion}, to determine what function calls are tail calls
and, more generally, what function calls fall into the four special
cases. We say that expressions produced by this analysis are
\index{function call!call-explicit}%
\label{call-explicit}%
{\em call-explicit}. One can inspect call-explicit programs by
passing the option
\index{print call-explicit expression@\texttt{-print\_call\_explicit\_expression}}%
$$\boxml{-print\_call\_explicit\_expression}$$
to the MLKit compiler,
and thus check whether specific function calls in the code turn out as
intended.  Call-explicit expressions are produced after regions have
been dropped (page~\pageref{bother-to-distinguish-get-n-put}) but
before native code generation.

We shall first give a brief description of the parameter passing
mechanism in general and then discuss the different kinds of function
calls provided, working our way from the most specialised (and most
efficient) cases towards the default cases.

\section{Parameter Passing}
Parameters to functions are passed either on the runtime
\index{stack}%
stack or, if possible, in
\index{register}%
registers. Also region parameters to region-polymorphic functions are
passed on the runtime stack or in registers.

\section{Tail Calls and Non-Tail Calls}
\label{tailcall.sec}
A call that is the last action of a function is referred to as a {\em
  tail call}. After region inference, the MLKit performs a tail call
analysis (in one backwards scan through the program). It is
significant that the tail call analysis happens after region
inference; as we saw in Section~\ref{length.sec}, a function call that
looks like a tail call in the source program may end up as a non-tail
call in the region-annotated program, because the function has to
return to free memory. The tail call analysis divides function calls
into four different kinds of calls:
\begin{quote}
\begin{description}
\item[{\tt jmp}:] tail calls to known functions
\item[{\tt funcall}:] non-tail calls to known functions
\item[{\tt fnjmp}:] tail calls to unknown functions
\item[{\tt fncall}:] non-tail calls to unknown functions
\end{description}
\end{quote}
In the sections to follow, we describe each of these kinds of calls in
detail.

\section{Tail Call to Known Function (\texttt{jmp})}
\label{simplejump.sec}
A call to a
\index{region polymorphism}%
region-polymorphic function (i.e., a known function) takes the form
$$\boxml{$f$ [$\rho_1$, $\ldots$, $\rho_n$] <$e_1,\ldots,e_m$>}$$
where $\rho_1$, $\ldots$, $\rho_n$ are actual region parameters to the
function, $f$ is the name of a region-polymorphic function, and
$e_1 \cdots e_m$, $m \geq 1$ are value arguments to the function (we
often omit the brackets $\verb+<+ \cdots \verb+>+$ when $m = 1$.) The MLKit
turns such a function call into the form
$$\boxml{jmp $f$ [$\rho_1$, $\ldots$, $\rho_n$] <$e_1,\ldots,e_m$>}$$
if the call
appears in a tail-call position, that is, if the call is the last
thing the current function needs to do.  Because the start address of
$f$ is known during compilation (because $f$ is region-polymorphic),
such a call is as efficient as an assembly language jump to a constant
label (not taking into account the shuffling of arguments needed to
match the calling convention for $f$.

The way to avoid that a {\tt region} binding is wrapped around
the function call (and thus causes the call not to be recognized as a
tail call) is to turn the calling function into a region endomorphism,
when possible.

The following is an example of how one obtains a tail call to a known
function:\footnote{Program \boxml{kitdemo/tail.sml}.}
\begin{verbatim}
  local
    fun f'(p as (0,b)) = p
      | f'(n,b) = f'(n-1,n*b)
  in
    fun f(a,b) = #2(f'(a,b))
  end
\end{verbatim}
The call-explicit version of {\tt f'} appears in
Figure~\ref{tail.fig}.
\begin{figure}
\hrule \medskip
\begin{verbatim}
  fun f' attop r1 [r13:inf] (var2) =
    let val v96 = #0 var2
    in  case v96 of
           0 => var2
         | _ => let val v98 = #1 var2
                in jmp f'[sat r13] (v96 - 1, v96 * v98)sat r13
                end
    end
\end{verbatim}
\caption{An example where a function call turns into a tail call to a known function.}
\medskip \hrule
\label{tail.fig}
\end{figure}

There is a more efficient version of the function {\tt f} that
exploits the MLKit's unboxing of function arguments, but in general, one
can rely on unboxing to ensure tail-calls only when the elements of
the argument tuple themselves are unboxed; otherwise there is a risk
that, for each invocation, fresh regions are introduced to hold the
arguments to the call, and the call would need to return to
de-allocate these regions.

The MLKit can transform a call into a \boxml{jmp} tail call even in the
case that the call appears in the body of a \boxml{fn} expression.
Consider the following two mutually recursive functions {\tt g} and
{\tt h}:\footnote{Program {\tt kitdemo/tail2.sml}.}
\begin{verbatim}
  fun g (n,b) = h (n-1) b
  and h 0 b = b
    | h n b = g(n,n*b)
\end{verbatim}
Here {\tt h} calls {\tt g} in a tail position. The call explicit
version of the program is listed in Figure~\ref{tail2.fig}, and
indeed, the call to {\tt g} is recognized as a tail call.
\begin{figure}
\hrule \medskip
\begin{verbatim}
   let fun h attop r1 [r18:3] (var1) =
         fn attop r18 var2 =>
           (case var1 of
               0 => var2
             | _ => jmp g[] <var1, var1 * var2>)
       and g attop r1 [] (v90, v91) =
         let region r21:3
         in fncall funcall h[atbot r21] (v90 - 1) v91
         end
   in  {|h: (_,r1), g: (_,r1)|}
   end
\end{verbatim}
\caption{A function call can turn into a tail call even
  in the case that the call appears in the body of a {\tt fn} expression.}
\medskip \hrule
\label{tail2.fig}
\end{figure}
Also notice that the MLKit does not try to in-line {\tt g} in {\tt h}
(or vice-versa), although such an optimisation would certainly improve
on the efficiency of the generated code. Another example of a {\tt
  jmp} tail call is shown in Section~\ref{foldl.sec}.

\section{Non-Tail Call to Known Function \index{funcall@\texttt{funcall}}(\texttt{funcall})}
In the case that a call to a known function cannot be turned into a
tail call, because the call needs to return to do more work, the call
is transformed into
$$\boxml{funcall $f$ [$\rho_1, \ldots, \rho_n$] $\exp$}$$
where {\tt
  funcall} is the mnemonic used for non-tail calls to
region-polymorphic functions. One example is the call to {\tt h} in
Figure~\ref{tail2.fig}. Here the call to {\tt h} takes a region
argument {\tt r21} and an ordinary argument {\tt (v90-1)}; the call to
{\tt h} returns a closure, which needs to be applied to {\tt v91}
before the function {\tt g} can de-allocate the region {\tt r21} and
return.

This case completes all possible cases of applications of
region-polymorphic functions. We now turn to function applications
where the operator is not the name of a region-polymorphic function.

\section{Tail Call to Unknown Function (\texttt{fnjmp})}
Consider the case\index{fnjmp@\texttt{fnjmp}}
$$\exp_1\,\exp_2$$
where (a) the call is a tail call and (b) $\exp_1$
is not the name of a region-polymorphic function.

Here $\exp_1$ is evaluated to a closure in memory, pointed to by a
\index{standard closure register}%
\index{register!standard closure}%
{\em standard closure register}. Then $\exp_2$ is evaluated and the result
put in a
\index{standard argument register}%
\index{register!standard argument}%
{\em standard argument register}. The first word in the closure
contains the address of the code of the function. This address is
fetched into a third register and a jump to the address is made.
Because the call is a tail call, it induces no allocation, neither on
the stack nor in regions.  It is thus as efficient as an indirect jump
in assembly language.

%To avoid that $\exp_2$ puts values
%in fresh regions (which would make the call a non-tail call) one
%can ``disable'' region polymorphism of $f$ as explained in Section~\ref{tailcall.sec}.

The mnemonic used in call-explicit expressions for this special case is
$$\boxml{fnjmp $\exp_1$ $\exp_2$}$$

\section{Non-Tail Call to Unknown Function (\texttt{fncall})}
Consider the case
$$\exp_1\,\exp_2$$
where (a) the call is not a tail call and (b)
$\exp_1$ is not the name of a region-polymorphic function.

Applications of this form are implemented as follows. First $\exp_1$
is evaluated and the result, a pointer to a closure, is stored in the
\index{standard closure register}%
\index{register!standard closure}%
standard closure register. Then $\exp_2$ is evaluated and stored in
the
\index{standard argument register}%
\index{register!standard argument}%
standard argument register.  Then live registers and a return
address are pushed onto the stack and a jump is made to the code
address that is stored in the first word of the closure pointed to by
the standard closure register. Upon return, registers are restored
from the stack.

The mnemonic used in call-explicit expressions for this special case is
$$\boxml{fncall $\exp_1$ $\exp_2$}$$

\section{Example: Function Composition}
The Standard ML Basis Library declares function composition as
follows\footnote{Program \boxml{kitdemo/compose.sml}.}
\begin{verbatim}
  fun (f o g) x = f(g x)
\end{verbatim}
The resulting call-explicit expression produced by the MLKit is
\begin{verbatim}
  fun o attop r1 [r22:3] (v92, v93) =
      fn attop r22 x => fnjmp v92 (fncall v93 x)
\end{verbatim}
Notice that
\index{o@\texttt{o}}%
\boxml{f o g} first creates a closure in \boxml{r22} and then returns.
The closure is of size three words and contains a pointer to the code
for the function and pointers to the closures for \boxml{f} and
\boxml{g}. When called, the created function first performs a non-tail
call of \boxml{g} and then a tail call to \boxml{f}.

\section{Example: \texttt{foldl} Revisited}
\label{foldl.sec}
Consider the following declaration of folding over
lists:\footnote{Program \boxml{kitdemo/fold1.sml}.}
\begin{verbatim}
  fun foldl f b xs =
    case xs of
      [] => b
    | x::xs' => foldl f (f x b) xs'
\end{verbatim}
The recursive call of
\index{foldl@\texttt{foldl}}%
{\tt foldl} is a call of a known function, but not a tail call; {\tt
  foldl} returns a closure, which is subsequently applied to the value
of {\tt (f x b)}. This too returns a closure, which in turn is applied
to {\tt xs'}.  The resulting call-explicit expression is shown in
Figure~\ref{fold1.fig}.
\begin{figure}
\hrule \medskip
\begin{verbatim}
  fun foldl attop r1 [r40:4, r38:4] (f) =
    fn attop r40 b =>
      fn attop r38 xs =>
        (case xs of
            nil => b
          | _ =>
              let val v100 = decon_:: xs;
                  val v101 = #0 v100;
                  val v102 = #1 v100;
                  region r30:4
              in  fncall
                   let region r31:4
                   in fncall
                        funcall foldl[atbot r31,atbot r30] f
                        (fncall fncall f v101 b)
                   end
                   v102
              end)
\end{verbatim}
\caption{The straightforward implementation of {\tt foldl} uses space
  linear in the length of the list. (Program {\tt
    kitdemo/fold1.sml}.)}
\medskip \hrule \label{fold1.fig}
\end{figure}
Notice that upon each iteration, fresh regions for holding two
closures are being allocated for the duration of the recursive call.
Thus, space usage is linear in the length of the list (4 words for
each list cell, to be precise).

An alternative version of {\tt foldl} assumes that \boxml{f}
is curried:\footnote{Program \boxml{kitdemo/fold2.sml}.}
\begin{verbatim}
  fun foldl f b xs =
    let fun loop(p as ([], b)) = p
          | loop(x::xs, b) = loop(xs,f x b)
    in
        #2(loop(xs,b))
    end
\end{verbatim}
It is compiled into the call-explicit expression in
Figure~\ref{fold2.fig}.
\begin{figure}
\hrule \medskip
\begin{verbatim}
  fun foldl attop r1 [r50:3, r48:3] (f) =
    fn attop r50 b =>
      fn attop r48 xs =>
        let region r25:1;
            fun loop atbot r25 [r32:inf] (var2) =
              let val v107 = #0 var2
              in  case v107 of
                      nil => var2
                    | _ =>
                        let val v109 = decon_:: v107;
                            val v110 = #0 v109;
                            val v111 = #1 v109;
                            val v112 = #1 var2
                        in  jmp loop[sat r32]
                              (v111,
                               fncall fncall f v110 v112
                              )sat r32
                        end
              end;
            region r44:inf
        in  #1 funcall loop[atbot r44] (xs, b)atbot r44
        end
\end{verbatim}
\caption{The result of compiling the efficient version of {\tt foldl}
  ({\tt kitdemo/fold2.sml}) is an iterative function that avoids
  argument pairs piling up in one region.}  \medskip \hrule
\label{fold2.fig}
\end{figure}
Here the loop is implemented as a jump and there is no new allocation
in each iteration, except, of course, for the allocation that {\tt f}
might make.\footnote{All the allocations made by the calls to {\tt f}
  (one call for each element of the list) are put in the same regions.
  If the list is very long or the values produced large, it may be a
  good idea to copy the final result to separate regions.}

As an exercise, consider the following variant of {\tt foldl}, which
assumes that {\tt f} takes a pair as an argument:\footnote{Program
  \boxml{kitdemo/fold3.sml}.}
\begin{verbatim}
  fun foldl' f b xs =
    let fun loop(p as ([], b)) = p
          | loop(x::xs, b) = loop(xs,f(x,b)))
    in
        #2(loop(xs,b))
    end
\end{verbatim}
Interestingly, this program contains a potential space leak. Can you
detect it? If not, the MLKit will tell you when you compile the
program if you pass the compiler the option
\texttt{-warn\_on\_escaping\_puts}.

%---------------------------------------------
\chapter{ML Basis Files and Modules}
\label{mlb_and_modules.chap}
%---------------------------------------------
In Section \ref{tryit.sec} we described how to compile and run
single-file programs. In this chapter, we describe how to program in
the large with the MLKit, using
\index{Standard ML!Modules}%
Standard ML Modules and the possibility of organising source files
in ML Basis Files. The MLKit fully supports Standard ML Modules and it
has a sophisticated system for avoiding unnecessary recompilation. In
the following section, we describe the notion of ML Basis Files. We then
turn to show how to program with structures, signatures, and functors.
To enable the programmer to write efficient programs using the Modules
language, we shall also explain how the MLKit compiles Modules language
constructs.

\section{ML Basis Files}
An ML Basis File, in short MLB-file,
\index{ML Basis File}%
\index{{MLB}-file}%
is a file that lists the SML source files
that make up a project or a library. An MLB-file can also
\index{referencing an MLB-file}%
\emph{reference} other MLB-files, so one can organise projects in a
hierarchical manner. MLB-files are enforced not to be cyclic.

MLB-files have file extension \index{.mlb@\texttt{.mlb}}{\tt .mlb}.
The content of an MLB-file is a \emph{basis declaration}, for which
the
\index{MLB-file!grammar}%
grammar is given in Figure~\ref{mlb_grammar.fig}. We assume a
denumerable infinite set of \emph{basis identifiers} Bid, ranged over
by \emph{bid}. We use \emph{longbid} to range over \emph{long basis
  identifiers}, that is, non-empty lists of basis identifiers
separated by a punctuation letter (\texttt{.}). Basis identifiers can
be used for giving a name to a group of compilation units and allow
for expressing source dependencies, exactly, as a directed acyclic
graph, within one MLB-file.

\begin{figure}
\hrule\medskip
\[
\begin{array}{rcll}
  \emph{bdec} & ::= & \emph{bdec}~ \emph{bdec} & \mbox{sequential~basis~declaration} \\
            & |   & \varepsilon & \mbox{empty~basis~declaration} \\
            & |   & \texttt{local}~ \emph{bdec}~\texttt{in}~\emph{bdec}~\texttt{end} & \mbox{local~declaration} \\
            & |   & \texttt{basis} ~\emph{bid}~\texttt{=}~\emph{bexp} & \mbox{basis~identifier~binding} \\
            & |   & \texttt{open} ~\emph{longbid}* & \mbox{opening~of~a~basis}\\
            & |   & \emph{atbdec} \\
            & |   & \emph{path}.\texttt{mlb} & \mbox{include} \\ \\
  \emph{atbdec} & ::= & \emph{path}.\texttt{sml} & \mbox{source~file} \\
              & |   & \emph{path}.\texttt{sig} & \mbox{source~file} \\ \\
  \emph{bexp} & ::= & \texttt{bas}~ \emph{bdec}~ \texttt{end} & \mbox{basis~declaration~grouping} \\
            & |   & \texttt{let}~\emph{bdec}~\texttt{in}~\emph{bexp}~\texttt{end} & \mbox{let~expression} \\
            & |   & \emph{longbid}
\end{array}
\]
\caption{Grammar for MLB-files, i.e., files with extension {\tt .mlb}.
  For some file extension {\tt .}\emph{ext}, {\it path}{\tt
    .}\emph{ext} denotes either an absolute path or a relative path
  (relative to the directory in which the MLB-file is located) to a
  file on the underlying file system.}
\label{mlb_grammar.fig}
\medskip \hrule
\end{figure}
In an MLB-file, one can reference source files and other MLB-files
using absolute or relative
\index{path!absolute}%
\index{path!relative}%
paths.  Relative paths are relative to the location of the MLB-file.
Paths can reference environment variables using the
\texttt{\$(ENVVAR)} notation, where \texttt{ENVVAR} is an environment
variable.

Until now, we have seen a few examples of MLB-files that reference the
Basis Library, using the \texttt{\$(SML\_LIB)} environment variable
(see Section~\ref{polyrec.sec} for such an example). In
Section~\ref{functors.sec}, we present an example of an MLB-file that
reference other MLB-files. In Section~\ref{comp_and_link_with_C.sec},
we shall see an example of how an MLB-file can be compiled and linked
with external object files, produced with a C compiler, for instance.
MLB-files may contain Standard ML style
\index{MLB-file!comments in}%
\index{comments!in MLB-file}%
comments. The declared identifiers of an MLB-file is the union of the
identifiers being declared by source files in the MLB-file, excluding
source files that are included using {\tt local}. As an example of the
use of basis identifiers and {\tt local} to limit what identifiers are
declared by an MLB-file, consult the MLB-file {\tt basis/basis.mlb}.

Every source file must contain a Standard ML top-level declaration;
the scope of the declaration is all the subsequent source files
mentioned in the MLB-file and all other MLB-files that reference this
MLB-file. Thus, a source file may depend on source files mentioned
earlier in the MLB-file and on other referenced MLB-files.  The
meaning of an entire MLB-file is the meaning of the top-level
declaration that would arise by expanding all referenced MLB-files and
then concatenating all the source files listed in the MLB-file (with
appropriate renaming of declared identifiers of source files that are
included using {\tt local}), in the order they are listed, except that
each MLB-file is executed only the first time it is imported.

The MLKit has a system for managing compilation and recompilation of
\index{MLB-files}%
MLB-files.  The system guarantees that the result of first modifying
one or more source files and then using the separate
compilation system to rebuild the executable is the same as if all
\index{source file}%
source files were
\index{recompilation}%
recompiled.

Thus, the separate compilation system is a way of avoiding recompiling
parts of a (possibly) long sequence of declarations, while ensuring
that the result is always the same as if one had compiled the entire
program from scratch.  As an example, consider the MLB-file
(\boxml{kitdemo/scan.mlb}) for the text scanning example of
Section~\ref{scan.sec}. It contains the following three lines:
\begin{verbatim}
  $(SML_LIB)/basis/basis.mlb
  lib.sml
  scan.sml
\end{verbatim}

\noindent
The source files for the project are {\tt lib\_posix.sml} and {\tt scan.sml},
which are both located in the directory where {\tt scan.mlb} is
located. Whereas each of the source files {\tt lib.sml} and {\tt
  scan.sml} depends on the Basis Library, the source file {\tt
  scan.sml} also depends on {\tt lib.sml}.

Compiling an MLB-file is easy; simply give it as an argument to the
MLKit executable. When the MLB-file is first compiled, the MLKit
detects automatically when a source file has been modified (by
checking file modification dates). After a project has been
successfully compiled and linked, it can be executed by running the
command
\index{run@\texttt{run}}%
\begin{verbatim}
  ./run
\end{verbatim}
in the working directory.

The MLKit compiles each source file of an MLB-file one at a time, in
the order mentioned. A source file is compiled under a given set of
assumptions, which provides, for instance, region-annotated type
schemes with places for free variables of the source file. Also,
compilation of a source file gives rise to exported information about
declared identifiers. Exported information may occur in assumptions
for source files mentioned later in the MLB-file.

There are two rules that govern when a source file is recompiled.  A
source file is recompiled if either (1) the user has modified the
source file or (2) the assumptions under which the source file was
previously compiled have changed. To avoid unnecessary recompilation,
assumptions for a source file depend on only its free identifiers.
Moreover, if a source file has been compiled earlier, the MLKit seeks to
\index{matching}%
{\em match\/} the new exported information to the old exported
information by renaming generated names to names generated when the
source file was first compiled. Matching allows the compiler to use
fresh names (stamps) for implementing generative data types, for
instance, and still achieve that a source file is not necessarily
\index{recompilation!cut-off}%
recompiled even though source files, on which it depends, are
modified.

Let us assume that we modify the source file {\tt lib.sml} of the text
scanning example, after having compiled the MLB-file
\texttt{kitdemo/scan.mlb} once. When compiling the MLB-file again, the
MLKit checks whether the assumptions under which the source file {\tt
  scan.sml} was compiled have changed, and if so, recompiles {\tt
  scan.sml}.  Modifying only comments or string constants inside {\tt
  lib.sml} or extending its set of declared identifiers does not
trigger recompilation of {\tt scan.sml}.

Some of the information a source file depends on is the ML type
schemes of its free variables. It also depends on, for example, the
region-annotated type schemes with places of its free variables.  Thus
it can happen that a source file is recompiled even though the ML type
assumptions for free variables are unchanged. For instance, the
region-annotated type scheme with place for a free variable may have
changed, even though the underlying ML type scheme has not.

As an example, consider what happens if we modify the function {\tt
  readWord} in the source file {\tt lib.sml} so that it puts its
result in a global region. This modification will trigger
recompilation of the source file {\tt scan.sml}, because the
assumptions under which it was previously compiled have changed.
Besides changes in region-annotated type schemes with places, changes
in multiplicities and in physical sizes of formal region variables of
functions may also trigger recompilation.


\section{Structures}
The support for Modules together with the possibility of dividing
top-level declarations into different source files provide a mechanism
for programming in the large. In the MLKit, structures exist only at
compile time.  Thus one need not worry where
\index{structure declaration}%
structures live at runtime.

We illustrate the compile-time nature of structures with the following
example. Consider the MLB-file {\tt PolySet.mlb},\footnote{MLB-file:
  \boxml{kitdemo/PolySet.mlb}.} which mentions the source files {\tt
  PolySet.sml}, {\tt INT\_SET.sml}, and {\tt IntSet.sml}. The source
file {\tt PolySet.sml} contains the following top-level declaration:
\begin{verbatim}
  structure PolySet =
    struct
      type 'a set = 'a list
      val empty = []
      fun singleton x = [x]
      fun mem(x,[]) = false
        | mem(x,y::ys) = x=y orelse mem(x,ys)
      fun union(s1,[]) = s1
        | union(s1,x::s2) = if mem(x,s1) then union(s1,s2)
                            else x::union(s1,s2)
    end
\end{verbatim}
The code generated by the MLKit for the {\tt PolySet} structure is
exactly as if the declarations were written outside of a structure.
As a consequence, when you refer to a component of a structure using
qualified identifiers (e.g., {\tt PolySet.mem}), no code is generated
for fetching the component from the structure. Moreover, when opening
a structure, using the
\index{open declaration}%
{\tt open} declaration, no code is generated for rebinding the
identifiers that become visible.

\section{Signatures}
\index{signature declaration}%
In the MLKit, signature declarations exist only at compile time. That
is, a signature declaration does not result in any code being
generated. The source file {\tt INT\_SET.sml} in the MLB-file {\tt
  PolySet.mlb}, mentioned earlier, contains the signature declaration
\begin{verbatim}
  signature INT_SET =
    sig
      type 'a set
      val empty : int set
      val singleton : int -> int set
      val mem : int * int set -> bool
      val union : int set * int set -> int set
    end
\end{verbatim}

Signatures are used in two contexts; for specifying arguments to
functors and for providing restricted views of structures using
\index{signature constraint!transparent}%
transparent and
\index{signature constraint!opaque}%
opaque signature constraints. We defer the discussion of the use of
signatures for specifying arguments to functors to
Section~\ref{functors.sec}.

Transparent signature constraints may both restrict components from a
structure and make polymorphic components less polymorphic. Moreover,
opaque signature constraints may also make type components of
structures abstract. Consider the structure declarations
\begin{verbatim}
  structure IntSet1 : INT_SET = PolySet
  structure IntSet2 :> INT_SET = PolySet
\end{verbatim}

\noindent
located in the source file {\tt kitdemo/IntSet.sml}. No code is
generated for the structure declarations. Instead, the compiler
memorises that if you refer to the long identifier {\tt IntSet1.mem},
for instance, then it is actually {\tt PolySet.mem} that is applied
with type instance {\tt int}.

As for the second declaration, opaque signature constraints are
eliminated at compile time (after elaboration) and transformed into
transparent signature constraints.

\section{Functors \label{functors.sec}}
\index{functor}%
\index{specialisation!functor}%
Functors map structures to structures. The MLKit specialises a functor
every time it is applied.  Thus, types that are abstract for the
programmer (inside a functor body) become visible to the compiler.
Region-annotated type schemes and other information about identifiers
in the actual functor argument are available when the MLKit compiles the
functor body.

For practical reasons, it is important that not all functor
applications are expanded at once, since this could cause intermediate
representations of programs to become as large as (or even much larger
than) the entire program. Further, non-restricted in-lining could lead
to unnecessary recompilation upon modification of source files.
Instead, the largest structure declarations not containing functor
applications are compiled into separate chunks of machine object code.
Assumptions for compiling these structure declarations are memorised,
so that the generated code can be reused upon modification of source
files if the assumptions do not change.

Consider the following MLB-file:\footnote{MLB-file:
  \boxml{kitdemo/Set.mlb}.}
\begin{verbatim}
  $(SML_LIB)/basis/basis.mlb
  local utils/utils.mlb
  in SET.sml Set.sml SetApp.sml
  end
\end{verbatim}
The MLB-file reference the MLB-file {\tt utils.mlb} from the {\tt utils}
directory.\footnote{MLB-file: \boxml{kitdemo/utils/utils.mlb}.} This
MLB-file provides a structure {\tt ListUtils} that contains the
function {\tt pr\_list} with type scheme {\tt ('a -> string) -> 'a
  list -> string}. The content of the file {\tt Set.sml} is listed in
Figure~\ref{Set.fig}. It declares the functor {\tt Set}, which takes
as arguments the element type for the set, an ordering function on
elements, and a function for providing a string representation of
elements.
\begin{figure}[ht]
\hrule \medskip
\begin{verbatim}
  functor Set (eqtype elem (*total order*)
               val lt : elem * elem -> bool
               val pr : elem -> string)
       : SET where type elem = elem =
    struct
      type elem = elem
      type set = elem list
      val empty : set = []
      fun singleton e = [e]
      fun mem x l =
        let fun mem' [] = false
              | mem' (y::ys) = if lt(y,x) then mem' ys
                               else not(lt(x,y))
        in mem' l
        end
      fun union(s1,s2) =
        let fun U (t as ([], [], acc)) = t
              | U ([], y::ys, acc) = U([], ys, y::acc)
              | U (x::xs, [], acc) = U(xs, [], x::acc)
              | U (s1 as x::xs, s2 as y::ys, acc) =
                  U(if lt(x,y) then (xs, s2, x::acc)
                    else if lt(y,x) then (s1, ys, y::acc)
                    else (xs, ys, y::acc))
        in rev(#3(U(s1, s2, [])))
        end
      val pr = fn s => ListUtils.pr_list pr s
    end
\end{verbatim}
\caption{The source file \boxml{kitdemo/Set.sml}.}
\medskip \hrule \label{Set.fig}
\end{figure}

The source file {\tt SetApp.sml} is listed in
Figure~\ref{SetApp.fig}. It constructs a structure {\tt IntSet} by
applying the functor {\tt Set} to appropriate arguments including an
ordering operation on integers and an operation for giving the string
representation of an integer. The {\tt IntSet} structure is used for
constructing a set \verb+{2,5}+, which the program prints using the
built-in {\tt print} function.
\begin{figure}[ht]
\hrule \medskip
\begin{verbatim}
  structure IntSet = Set(type elem = int
                         val lt = op <
                         fun pr a = Int.toString a)
  open IntSet
  val _ = print (pr (union(singleton 2, singleton 5)))
\end{verbatim}
\caption{The source file \boxml{kitdemo/SetApp.sml}.}
\medskip \hrule \label{SetApp.fig}
\end{figure}

The body of the {\tt Set} functor is instantiated to form the code for
the {\tt IntSet} structure. The result of instantiating the {\tt Set}
functor is first translated into a $\Lam$ program and then translated
into a $\MulExp$ program. The $\MulExp$ call-explicit code for the
{\tt mem} function is shown in Figure~\ref{set_inst_mulexp.fig}.
\begin{figure}[ht]
\hrule \medskip
\begin{verbatim}
  fun mem attop r1 [] (x, l) =
    let region r53:1;
        fun mem' atbot r53 [] (var2) =
          case var2 of
             nil => false
           | _ =>
              let val v193 = decon_:: var2;
                  val v194 = #0 v193;
                  val v195 = #1 v193
              in  case v194 < x of
                     true => jmp mem'[] v195
                   | _ => (case x < v194 of
                              true => false
                            | _ => true)
              end
    in  funcall mem'[] l
    end
\end{verbatim}
\caption{The $\MulExp$ call-explicit code for the {\tt mem}
  function resulting from instantiating the {\tt Set} functor.}
\medskip \hrule
\label{set_inst_mulexp.fig}
\end{figure}

Notice that the code for the {\tt mem}~function holds inlined code for
the {\tt lt}~function; because the function is sufficiently small, the MLKit propagates its intermediate representation
 across module boundaries.

%---------------------------------------------------------
\chapter{Garbage Collection}
\label{gc.chap}
%---------------------------------------------------------
The MLKit supports reference tracing garbage collection in
combination with the region memory model \cite{hallenberg99,het02}.
Garbage collection is also possible with region profiling enabled.

The reference-tracing garbage collector is enabled by default and, as
we have seen earlier, garbage collection can be disabled by passing
the \texttt{-no\_gc} option to the MLKit compiler at compile time. As
we shall see, it is also possible to disable garbage collection at
runtime for a program that has been compiled with garbage collection
enabled.

The MLKit also features generational reference-tracing garbage
collection (option \texttt{-gengc}), which in some cases is superior
to ordinary reference-tracing garbage collection, but which may also
cause additional fragmentation \cite{elshaljfp21}.

\section{Dangling Pointers}
The region type system supports deallocation of memory that is not
accessed in the remainder of the execution of the program. Because of
this principle, the execution model may lead to {\em dangling
  pointers}, that is, pointers that point into memory that has been
discharged. When garbage collection is enabled, the region type system
is modified slightly so as to guarantee that no dangling pointers
occur during execution \cite{elsman:tldi03}. The following example
illustrates how the enabling of garbage collection changes the way
programs are compiled:
\begin{verbatim}
  val f = let val x = ref (2, [1])
          in fn y => (#1 (!x), y)
          end
  val r = f 5
\end{verbatim}
When garbage collection is disabled, the program is compiled into the
following MulExp program:\footnote{Compiled with {\tt mlkit -no\_gc
    -maximum\_inline\_size 0 -Ppse -w 40 dangling.sml} from within the
  {\tt kitdemo} directory.}
\begin{verbatim}
  val f =
    let region r9:inf;
        val x = ref attop r6 (2, [1] attop r9)attop r4
    in  fn attop r1 y => (#0 (!x), y)attop r4
    end
  val r = fncall f 5
\end{verbatim}
Notice here that region {\tt r9}, which contains the list {\tt [1]},
is de-allocated before the function {\tt f} is applied to the value
{\tt 5}. If we chose to run this program together with a reference
tracing garbage collector, a fatal error could occur: The memory that
contains the list {\tt [1]} could be reused for other purposes at the
time the garbage collector tries to trace the dangling pointer.

Figure~\ref{dangling_gc.fig} shows the MulExp program produced when
garbage collection is enabled.\footnote{Compiled with {\tt mlkit -gc
    -maximum\_inline\_size 0 -Ppse -w 50 dangling.sml} from within the
  {\tt kitdemo} directory.}
\begin{figure}[ht]
\hrule \medskip
\begin{verbatim}
  val f =
    let val x = ref attop r6 (2, [1] attop r4)attop r4
    in  fn attop r1 y => (#0 (!x), y)attop r4
    end
  val r = fncall f 5
\end{verbatim}
\caption{The $\MulExp$ program produced when compiling the program
  {\tt kitdemo/dangling.sml} with garbage collection enabled. To avoid
  dangling pointers when garbage collection is enabled, all values in
  the closure for {\tt f} are kept alive as long as the closure
  itself.}  \medskip \hrule
\label{dangling_gc.fig}
\end{figure}
When garbage collection is enabled, the MLKit makes sure that whenever
a closure is live all values stored in the closure are kept live as
long as the closure is live.  Assume that the type with place $\mu$ of
the function associated with the closure is on the form $(\mu_1
\ar{\epsilon.\varphi} \mu_2, \rho_0)$.  The MLKit enforces the
restriction by requiring that for each region variable $\rho$ that
occur free in the type of free variables of the function (those
variables for which values are stored in the closure at runtime),
$\rho$ occur free in $\mu$. In the implementation, the requirement may
lead to extra $\Get$ effects being added to $\epsilon.\varphi$ when
garbage collection is enabled. In the example, an imposed $\Get$
effect on the arrow effect in the type for {\tt f} makes it impossible
to wrap a {\tt region} binding around the binding for {\tt f}. (See
\cite[page 50]{total93} and \cite{elsman:tldi03} for more information
about this requirement.)

\section{Scanning Text Files with Stream IO and Garbage Collection}

In Section~\ref{scan.sec}, we saw how we could use basic non-buffered
\texttt{Posix} IO operations for scanning text files in constant
space. The Standard ML Basis library, however, also features a
stream-based \texttt{TextIO} structure that supports arbitrary
look-ahead, buffering, stream-redirection, and many other features
\cite{basislib2004}. Unfortunately, as mentioned in
Section~\ref{scan.sec}, this functionality does not work well together
with MLKit's region based memory management, unless combined with a
mechanism for dynamically garbage collecting regions. We now consider
a modified version of the the text scanning program listed in
Section~\ref{scan.sec} that uses the \texttt{TextIO.inputN} function
for file reading, instead of using \texttt{Posix} buffered IO.

Figure~\ref{scan-stream.fig} shows two region profiles for the
modified text scanning program.\footnote{MLB-file:
  \texttt{scan\_stream.mlb}.} We see that the reference-tracing
garbage collector periodically cleans up the global regions r1 and r4,
which tends to grow steadily without garbage collection.

\begin{figure}
\includerp{scan_stream_nogc.pdf}

\includerp{scan_stream.pdf}

\caption{Two region profiles of text scanning using buffered
  stream-based IO operations. The top region profile is with
  reference-tracing garbage collection disabled and the bottom
  region profile is with reference-tracing garbage collection
  enabled.}
\label{scan-stream.fig}
\end{figure}


\section{Instrumenting the Executable}
Executables produced by the MLKit with garbage collection enabled can be
instrumented by use of command-line options. For instance, if the MLKit
has produced a file {\tt run}, one can pass the option {\tt
  -verbose\_gc} to {\tt run} to enable the printing of garbage
collection information at runtime. An overview of available
command-line options is shown by passing the option {\tt -help} to the
generated executable: {\small
\begin{verbatim}
  Usage: ./run
        [-help, -h]
        [-disable_gc | -verbose_gc] [-heap_to_live_ratio d]
    where
        -help, -h                Print this help screen and exit.

        -disable_gc              Disable garbage collector.
        -verbose_gc              Show info after each collection.
        -heap_to_live_ratio d    Use heap to live ratio d, ex. 3.0.
\end{verbatim}
}

\part{System Reference}

%---------------------------------------------------------
\chapter{Region Profiling}
\label{useOfProf.sec}
%---------------------------------------------------------
We have already seen several examples of the use of the profiler. We
shall now explain in more detail how to profile programs. For example, we shall see
how one can find out precisely what allocation points in the program
contribute to allocation in a particular region.

The profiler consists of several tools that can be used to analyse the
dynamic memory behavior of a program. First of all, the profiler lets
you create graphs of the dynamic memory usage of the program. Three
different kinds of graphs may be created:
\begin{itemize}
\item A
  \index{region profile}%
  \index{profile!region}%
  {\em region profile\/} is a graph that gives a global view of the
  memory usage by showing the total number of bytes allocated in
  regions and on the stack as a function of time. In the graph,
  regions that arise from the same
  \begin{center}
    \texttt{region} $\rho$
  \end{center}
  construct are collected into one colored band, labelled $\rho$. The
  region variables that label bands are always global or {\tt region}-bound,
  never formal region parameters.
\item An
  \index{object profile}%
  \index{profile!object}%
  {\em object profile\/} is a graph that, for a particular region,
  shows the objects allocated in the region, with one coloured band
  for each allocation point in the region-annotated
  program\footnote{Every occurrence of an $\at$ in the
    region-annotated program is an allocation point.}. Each allocation
  point is annotated with a
  \index{program point}%
  {\em program point}, which is a unique number that identifies the
  allocation.\footnote{Program points are unique. In particular, for a
    project with two program units, the program points in the
    region-annotated programs for the two units will be distinct.}  To
  inspect region-annotated programs with program points, pass the
  MLKit compiler the option \texttt{-print\_program\_points} in
  addition to the option \texttt{-print\_call\_explicit\_expression},
  say.\footnote{Program points are annotated during physical size
    inference.}

  If you have an object profile showing that program point
  \texttt{pp42}, say, contributes with allocation, you can search for
  \texttt{pp42} in the region-annotated program and thus find the
  construct that caused the allocation.
\item A
  \index{stack profile}%
  \index{profile!stack}%
  {\em stack profile\/} is a graph that shows the stack memory usage,
  as a function of time.
\end{itemize}

In addition to the possibility of generating programs with program
points, it is also possible, during compilation, to generate a
\index{region flow graph}%
{\em region flow graph}, which shows how regions may be passed around
at runtime when region-polymorphic functions are applied. The region
flow graph comes in handy when profiling large programs and when one wants
to find out why a formal region variable is instantiated to a
certain {\tt region}-bound region variable.

The following example clarifies the use of a region flow graph.
Suppose the region profile shows that \texttt{r5} is responsible for
most of the memory usage.  Further, suppose an object profile of
\texttt{r5} shows that program point \texttt{pp345} is responsible for
most of the allocation.  Searching for \texttt{pp345} in the
region-annotated program, you may find that the allocation at
\texttt{pp345} is into some other region variable, \texttt{r34}, say.
Here \texttt{r34} will be a formal region parameter of a
region-polymorphic function that at runtime has been instantiated to
\texttt{r5} by one or more calls of region-polymorphic functions.
You can now use the region flow graph to find the cascade of region
polymorphic applications that ends up instantiating \texttt{r34} to
\texttt{r5}.

The profiling process is sketched in Figure~\ref{profStrategy.fig}.
\setlength{\unitlength}{6mm}
\newcommand{\picbox}[1]{\framebox(7,4){\parbox{38mm}{\begin{center}
        #1 \end{center}}}}
\begin{figure}
\hrule \medskip
\begin{center}
\begin{picture}(18,17)
\put(2,0){\picbox{Generate profile \\ with {\tt rp2ps}}}
\put(2,6){\picbox{Choose runtime \\ profiling strategy \\ and execute}}
\put(2,12){\picbox{Choose compile-time \\ profiling strategy \\ and compile}}
\put(11,0){\dashbox{.5}(7,4){\parbox{38mm}{\begin{center}
        Region profile, object profile, or stack profile \end{center}}}}
\put(11,6){\dashbox{.5}(5,3){\parbox{20mm}{\begin{center} data file {\tt profile.rp} \end{center}}}}
\put(11,11){\dashbox{.5}(7,2){\parbox{38mm}{\begin{center}
        Region flow graph \end{center}}}}
\put(11,15){\dashbox{.5}(7,2){\parbox{38mm}{\begin{center}
        Program annotated with program points \end{center}}}}
\put(9,15){\vector(2,1){2}}
\put(9,13){\vector(2,-1){2}}
\put(9,8){\vector(2,0){2}}
\put(9,2){\vector(2,0){2}}
\put(9,8){\vector(2,0){2}}
\put(5.4,12){\vector(0,-1){2}}
\put(5.6,12){\vector(0,-1){2}}
\put(3.9,4){\vector(0,1){2}}
\put(4.1,4){\vector(0,1){2}}
\put(6.9,6){\vector(0,-1){2}}
\put(7.1,6){\vector(0,-1){2}}
\put(11,7){\vector(-2,-3){2}}
\put(0.9,1.9){\line(0,1){12.2}}
\put(1.1,2.1){\line(0,1){11.8}}
\put(1.1,2.1){\line(1,0){0.9}}
\put(0.9,1.9){\line(1,0){1.1}}
\put(0.9,14.1){\vector(1,0){1.1}}
\put(1.1,13.9){\vector(1,0){0.9}}
\end{picture}
\caption{Overview of the profile process. The process sometimes requires the programmer
  to refine the runtime profiling strategy, or even the compile-time
  profiling strategy. Dotted boxes represent output from the compiler,
  from executing the program, and from using the tool {\tt rp2ps},
  which generates PostScript graphs from the exported data file.}
\label{profStrategy.fig}
\end{center}
\medskip
\hrule
\end{figure}

%\renewcommand{\picbox}[1]{\framebox(5,3){\scriptsize{\parbox{22mm}{\begin{center}
%        #1 \end{center}}}}}
%\newcommand{\vectorr}[1]{\vector(1,0){1}
%  \makebox(-1,1)[t]{\scriptsize{#1}}}
%\setlength{\unitlength}{0.5cm}
%\begin{figure}[ht]
%\hrule
%\begin{center}
%\begin{picture}(29,8)
%\put(0,4){\picbox{Choose \\ Compile-Time \\ Profiling \\ Strategy}}
%\put(6,4){\picbox{Compile ML Source Program with MLKit compiler}}
%\put(12,4){\picbox{Choose Target \\ Profiling Strategy}}
%\put(18,4){\picbox{Execute Target Program \\ (\texttt{run} $\ldots$)}}
%\put(24,4){\picbox{Generate \\ Profiles \\ with the graph \\ generator \texttt{rp2ps}}}
%\put(8,4){\vector(-1,-1){2}}
%\put(2.5,0){\dashbox{0.3}(6.0,2){\scriptsize{\parbox{40mm}{\begin{center}Region-
%        Annotated \\ Lambda Program\end{center}}}}}
%\put(9,4){\vector(1,-1){2}}
%\put(9,0){\dashbox{0.3}(4,2){\scriptsize{\parbox{22mm}{\begin{center}Region
%      \\ Flow \\ Graph\end{center}}}}}
%\put(20.5,4){\vector(0,-1){2}}
%\put(18.5,0){\dashbox{0.3}(4,2){\scriptsize{\parbox{22mm}{\begin{center}Profile
%      \\ Datafile\end{center}}}}}
%\put(26.5,4){\vector(0,-1){2}}
%\put(22,2){\vector(1,1){2}}
%\put(24.5,0){\dashbox{0.3}(4,2){\scriptsize{\parbox{22mm}{\begin{center}Profile
%      \\ Graphs\end{center}}}}}
%\put(1,1.5){\scriptsize \texttt{.log}\index{log@\texttt{.log}}}
%\put(13,1.5){\scriptsize \texttt{.log}\index{log@\texttt{.log}}}
%\put(13,1){\scriptsize \texttt{.vcg}\index{vcg@\texttt{.vcg}}}
%\put(17.3,1.5){\scriptsize \texttt{.rp}\index{rp@\texttt{.rp}}}
%\put(23.3,1.5){\scriptsize \texttt{.ps}\index{ps@\texttt{.ps}}}
%\end{picture}
%\caption{Overview of the MLKit profiler. Dotted boxes
%        represent output from the profiler. The file containing the output
%        is also shown, e.g. a profile goes into a \texttt{.ps} file.}
%\label{profStrategy.fig}
%\end{center}
%\hrule
%\end{figure}

We will now show an example on how to profile a concrete program that
contains a space leak and then show how the profiler can be used to
improve the program. We then explain in more detail how to specify the
profiling strategies and how the profiles are generated.

%-------------------------------------------------
\section{Example: Scanning Text Files Again}
%-------------------------------------------------

In this section, we concentrate on the general principles of
profiling. As an example, we investigate a revised version of the project {\tt
  kitdemo/scan.mlb} (see Section~\ref{scan.sec}). Instead of
asking for a list of input files to scan (as project \texttt{scan.mlb}
does), the revised version of the scan project asks for only one input
file, which it then scans
\index{scan_rev1.mlb@\texttt{scan\_rev1.mlb}}%
50~times.\footnote{Project {\tt kitdemo/scan\_rev1.mlb}.}

The first thing to do is to get an overview of the memory usage of the
program. A region profile of the program gives you just that. See
Figure~\ref{scan_rev1_1.fig}.
\begin{figure}
  \includerp{scan_rev1_1.pdf}
\caption{Memory is accumulated in the top two bands. The global
  regions \texttt{r1} and \texttt{r154248} hold the largest amount of
  memory. The graph was generated by first compiling the {\tt
    kitdemo/scan\_rev1.mlb} project with profiling enabled (option
  \texttt{-prof}). We also add the compiler options
  \texttt{-log\_to\_file}, \texttt{-Ppp}, \texttt{-Prfg}, and
  \texttt{-Ppp} for enabling printing of region flow graphs, program
  points, and cell-explicit expressions (redirected to log
  files). Then by executing \texttt{echo life.sml | run -notimer 723}
  and finally by typing \texttt{rp2ps -region -name 'Scanning life.sml
    50 times'}.}
\label{scan_rev1_1.fig}
\medskip\hrule
\end{figure}

The graph shows that region \texttt{r154248} accumulates more memory
for each time it scans the file {\tt life.sml}.

To see what happens in region \texttt{r154248}, we make an object profile of
that region, see Figure \ref{scan_rev1_2.fig}.
\begin{figure}
  \includerp{scan_rev1_2.pdf}
\caption{There seems to be a space leak at program point
  \texttt{pp120}. The graph was generated by typing \texttt{rp2ps
    -object 154248}.}
\label{scan_rev1_2.fig}
\medskip\hrule
\end{figure}
The object profile shows that program point \texttt{pp120} continually
allocates memory that is first freed when the program terminates. We
now search for \texttt{pp120} in the generated log files and in the
log file located in the basis library folder
\texttt{\$(SML\_LIB)/basis}).\footnote{Unfortunately, the MLKit
  compiler happily resets the program point counter for each
  compilation of a program unit, thus, there are multiple instances of
  the program point \texttt{pp120}.} Among other places, we find that
the program point \texttt{pp120} appears in the following fragment in
the file \texttt{basis/Int.sml.log}:
\begin{verbatim}
  fun conv attop r1T pp65 [r58484s:inf] (rad, radix, i) =
   case ... of
     ...
    | _ =>
      let ...
      in  $implodeCharsML(sat r58484s pp120, ...)
      end
\end{verbatim}
So the space leak is caused by the {\tt implodeCharsML} primitive
function being called with region {\tt r154248} instantiated for the
formal region variable {\tt r58484}.

We now search for \texttt{r154248} in file \texttt{scan\_rev1.sml.log}
and find the following fragment of the region flow graph:
\begin{small}
\begin{verbatim}
  readWord[r153984:inf] --r153984 atbot--> [*r154248*]
  toString[r59007:inf]  --r59007 attop-->  LETREGION[r154248:inf]
\end{verbatim}
\end{small}
The fragment is read as follows. The formal region variable {\tt
  r59007} is instantiated to the {\tt region}-bound region variable
{\tt r154248} in a call to {\tt toString}. Moreover, also the formal
region variable {\tt r153984} (of function {\tt readWord}) is
instantiated to {\tt r154248}. (The asterisks ({\tt *}) denote that the
node has been displayed before.)

Region flow graphs are local to each program fragment in a program. A
call to a non-local region-polymorphic function introduces an edge in
the region flow graph, but the graph says nothing about in which
module the called function is located. Thus, it may be necessary to
look in several log files to find the path from a formal region
variable to an actual region variable. By inspecting the call-explicit
programs found in {\tt basis/Int.sml.log} and {\tt
  kitdemo/lib.sml.log} one finds that both {\tt toString} and {\tt
  readWord} eventually call {\tt implode}. However, {\tt readWord} is
called only initially, thus, we conclude that the space leak is caused
by function {\tt toString} (from the {\tt Int} structure) being called
with region {\tt r154248} instantiated for the formal region variable
{\tt r59007}. Indeed, by inspecting the calls to {\tt toString} in the
call-explicit program found in {\tt scan\_rev1.sml.log}, we see that
{\tt toString} is called with actual region {\tt 154248}.

The {\tt concat} function from the initial basis catenates a list of
strings. But all the strings in the argument list to {\tt concat} are
required to be in the same region. Thus, whenever a file is reported
(see Figure~\ref{report_file.fig}), strings created by the {\tt
  Int.toString} function are put in the region that also holds the
file name for the report (which is read using the function {\tt
  readWord}); and this region is non-local to the {\tt do\_it}
function, which implements the main loop of the program.
\begin{figure}
\hrule \medskip
\begin{verbatim}
  fun report_file (filename, n, ins) =
      writeln(concat[filename, ": size = ", Int.toString n,
                     " comments: ", Int.toString ins, " (",
                     (Int.toString(percent(ins, n))
                      handle _ => "-"), "%)"])

  fun scan_file filename : (int*int) option =
      let val fd = F.openf (filename, F.O_RDONLY, F.O.flags[])
      in let val (n, ins) = scan fd
         in Posix.IO.close fd;
            report_file (filename, n, ins);
            SOME (n, ins)
         end handle NotBalanced =>
                    (writeln (filename ^ ": not balanced");
                     Posix.IO.close fd;
                     NONE)
      end handle IO.Io {name,...} =>
                 (writeln (name ^ " failed."); NONE)

  fun main () : unit =
      case readWord F.stdin of
          SOME filename =>
	  let fun do_it 0 = ()
	        | do_it n = (scan_file filename; do_it (n-1))
	  in do_it 50
	  end
        | NONE => ()
\end{verbatim}
\caption{Fragments of {\tt scan\_rev1.sml}. All the strings in the
  argument list to {\tt concat} are put in the same region.}
\label{report_file.fig}
\medskip \hrule
\end{figure}

One way of solving the space leak is to make a copy of {\tt filename}
at the call to {\tt report\_file} in function {\tt scan\_file}:
\begin{verbatim}
  fun scan_file filename : (int*int) option =
      let val fd = F.openf (filename, F.O_RDONLY, F.O.flags[])
      in let val (n, ins) = scan fd
         in Posix.IO.close fd;
            report_file (filename^"", n, ins);
            SOME (n, ins)
         end handle NotBalanced =>
                    (writeln (filename ^ ": not balanced");
                     Posix.IO.close fd;
                     NONE)
      end handle IO.Io {name,...} =>
                 (writeln (name ^ " failed."); NONE)
\end{verbatim}
Project
\index{scan_rev2@\texttt{scan\_rev2.mlb}}%
{\tt kitdemo/scan\_rev2.mlb} implements the modification.
Figure~\ref{scan_rev2_1.fig} shows a region profile of the
\texttt{scan\_rev2.mlb} project.
\begin{figure}
\includerp{scan_rev2_1.pdf}
\caption{There is no space leak: no matter how many times we scan the
  file, the project will use the same number of words. The graph was
  generated by executing \texttt{echo life.sml | run -notimer 723} and
  \texttt{rp2ps name scan\_rev2 -region}.}
\label{scan_rev2_1.fig}
\medskip\hrule
\end{figure}

%----------------------------------------
\section{Compile-Time Profiling Strategy}
%----------------------------------------

Before compiling a program for the purpose of profiling, one must decide on a
\index{profile strategy!compile-time}%
{\em compile-time profiling strategy}; see
Figure~\ref{profStrategy.fig}.  The compile-time profiling strategy
directs the embedding of profiling instructions in the generated code
and instructs the compiler whether to report a region flow graph.

Region profiling is enabled by passing the option
\index{region profiling@\texttt{-region\_profiling}}%
\texttt{-region\_profiling} (or simply \texttt{-prof}) to the MLKit
compiler. If you want the MLKit to report region-annotated programs
with program points, you should pass the option
\index{print all program points@\texttt{-print\_all\_program\_points}}%
\texttt{-print\_all\_program\_points}
to the MLKit compiler together with one or more of the options
\index{print physical size inference expression@\texttt{-print\_physical\_size\_inference\_expression}}%
\texttt{-print\_physical\_size\_inference\_expression} and
\index{print call-explicit expression@\texttt{-print\_call\_explicit\_expression}}%
\texttt{-print\_call\_explicit\_expression}..

To make the compiler report a region flow graph, pass the option
\index{print region flow graph@\texttt{-print\_region\_flow\_graph}}%
$$\texttt{-print\_region\_flow\_graph}$$
to the MLKit compiler at compile
time. The region flow graph is reported in text format.

As a running example, we use the
\index{life@\texttt{life}}%
{\tt life} program.\footnote{Program: \texttt{kitdemo/life.sml}.}  We
assume that the options \texttt{-prof},
\texttt{-print\_all\_program\_points}, and
\texttt{-print\_region\_flow\_graph} are passed to the MLKit compiler
together with the option $$\texttt{-print\_call\_explicit\_expression}$$

By also passing the option \texttt{-log\_to\_file} to the MLKit
compiler, the MLKit generates several files, of which we have {\tt
  life.log} (containing, among other things, the call-explicit
region-annotated program with program points and the region flow graph
in text layout) and the executable file {\tt run}.

%-------------------------------------------------
\section{The Log File}
%-------------------------------------------------
In the file {\tt life.log} you find the call-explicit region-annotated
program with program points and the region flow graph in text layout
for the {\tt life.sml} source file.  The region flow graph is found by
searching for \texttt{REGION FLOW GRAPH FOR PROFILING}. The graph
contains the following fragment (modified slightly to fit here):\label{reg_flow_graph.ex}
\begin{verbatim}
  cp_list[r211368:inf]
   --r211368 sat-->   [*r211368*]
   --r211368 sat--> nthgen'[r211902:inf]
                     --r211902 atbot--> LETREGION[r212422:inf]
                     --r211902 sat--> [*r211902*]
   --r211368 atbot-->   LETREGION[r212384:inf]
\end{verbatim}
The region flow graph is almost equivalent to the graph used by the
storage mode analysis (see page~\pageref{region flow graph}). In the
graph, region variables are nodes and there is an edge between two nodes
$\rho$ and $\rho'$ if $\rho$ is a formal region parameter of a
function that is applied to actual region parameter $\rho'$. It
follows that \texttt{region}-bound region variables are always leaf
nodes.

Nodes in the graph are written in square brackets, which are labeled
with the token {\tt LETREGION} or the name of the function for which
the region variable is a formal parameter. For example, the notation
\texttt{cp\_list[r211368:inf]} identifies the node \texttt{r211368},
which is a formal region parameter of the function \texttt{cp\_list}.
An asterisk inside a square bracket means that the node has been
written earlier.  Only the node identifier (i.e., the region variable)
will then be printed. The size of the region is printed after the
region variable; we use {\tt inf} for infinite regions and {\em
  size\/} for finite regions of size {\em size\/} words.

Edges are written with the {\em from node\/} identifier annotated on
them. The edge points to the \emph{to node}. The fragment
\begin{verbatim}
  cp_list[r211368:inf]
   --r211368 sat-->   [*r211368*]
\end{verbatim}
is read: there is an edge from node \texttt{r211368} to node
\texttt{r211368} and node \texttt{r211368} has been written earlier. From
the cycle in the graph, one can conclude that \texttt{cp\_list} calls
itself recursively; if you look in file {\tt life.sml}, you will
find something like
\begin{verbatim}
  fun cp_list[] = []
    | cp_list((x,y)::rest) =
          let val l = cp_list rest
          in (x,y):: l
          end
\end{verbatim}

The region flow graph can get very complicated to read due to
mutually recursive functions, which give many edges and cycles.  If the
graphs get too complicated, you may find help in the
\index{strongly connected component}%
{\em strongly connected component\/} (scc) version of the graph.  The
scc graph is found by searching for \texttt{[sccNo} in the log file.
Each scc is identified by a unique {\em scc number}. The region
variables contained in each scc is annotated on the scc node.

Consider, for example, the following fragment of the scc version of
the region flow graph for the {\tt life} program:
\begin{verbatim}
  [sccNo 97: r211904,]   --sccNo 97-->   [sccNo 96: r212427,];
\end{verbatim}
Here, we have a scc node (id 97) containing region variable
\texttt{r211904} and an edge to scc node (id 96) containing region
variable \texttt{r212427}.

%----------------------------------
\section{Runtime Profiling Strategy}
%----------------------------------
When the source program has been compiled and linked, you have an
executable file, \texttt{run}. Typing \texttt{./run} at the command prompt will
execute the program with a predefined
\index{profile strategy!runtime}%
runtime profiling strategy, which is displayed when the program is
run with the {\tt -verbose} option:
\begin{verbatim}
  ---------------------Profiling-Enabled---------------------
   The profile timer (unix virtual timer) is turned on.
   A profile tick occurs every 1th second.
   Profiling data is exported to file profile.rp.
  -----------------------------------------------------------
\end{verbatim}
You can change the
\index{profile strategy!options}%
profiling strategy by passing command line arguments directly to the
executable.  The second line says that a virtual timer is used. There
are three possible timers, each of which can be enabled using one of
the following options:\footnote{A complete description can be
    found in the manual page for \texttt{getitimer}.}

\vspace{2mm}
{\def\arraystretch{1.4}
\begin{tabular}{lp{8cm}}
{\tt -realtime} & Real time.
  \index{realtime@\texttt{-realtime} option}%
  \index{timer!real} \\
{\tt -virtualtime} & The execution time for the process. %
  \index{virtualtime@\texttt{-virtualtime} option}%
  \index{timer!virtual} \\
{\tt -profiletime} & The execution time for the process together with the time used in
the operating system on behalf of the process. %
\index{profiletime@\texttt{-profiletime} option}%
  \index{timer!prof}
\end{tabular}}
\vspace{2mm}

The third line says that a
\index{profile tick}%
{\em profile tick\/} occurs every 1 second.  A profile tick is when
the program stops normal execution, and memory is traversed to collect
profile data. The more often a profile tick occurs the more detailed
you profile (and the slower the program will run). The
\index{profiling!time slot}%
{\em time slot\/} (i.e., the time between to succeeding profile ticks) to use
is specified by the
\index{sec@\texttt{-sec} option}%
\texttt{-sec n} and
\index{microsec@\texttt{-microsec} option}%
\texttt{-microsec n} options. A time slot of half a second is
specified by \texttt{-microsec 500000} and not by \texttt{-sec
  0.5}.\footnote{The lowest possible time slot to use is system
  dependent.
}

The fourth line says that the collected profile data is exported to
the file \texttt{profile.rp}. The default file name setting can be
changed with the
\index{file@\texttt{-file} option}%
\texttt{-file name} option.

There are several other possible command-line options; use the
\texttt{-h} option or the
\index{help@\texttt{-help} option}%
\texttt{-help} option for details. When garbage collection is enabled,
options for controlling garbage collection are also available as
command-line options (see Section~\ref{gc.chap}).

%----------------------------------
\section{Regions Statistics}
%----------------------------------
If the executable file {\tt run} is executed with the option {\tt
  -showStat} then
\index{region statistics}%
{\em region statistics\/} is printed just before the program
terminates. Region statistics includes information about the use of
regions and does not depend on the specifics of the runtime profiling
strategy; in fact, region statistics includes only exact, non-sampled
values for the program. Assuming that {\tt run} is the executable file
generated by compiling the program {\tt life} with profiling enabled,
executing {\tt ./run -showStat} yields---just before the program
terminates---the region statistics shown in
Figure~\ref{region_statistics.fig}.
\begin{figure}
\hrule \medskip
\begin{verbatim}
MALLOC
  Number of calls to malloc for regions: 1
  Alloc. in each malloc call: 819200 bytes
  Total allocation by malloc: 819200 bytes (0.8Mb)

REGION PAGES
  Size of one page: 8176 bytes
  Max number of allocated pages: 25
  Number of allocated pages now: 7
  Max space for region pages: 204400 bytes (0.2Mb)

INFINITE REGIONS
  Size of infinite region descriptor: 32 bytes
  Number of calls to allocateRegionInf: 95767
  Number of calls to deallocateRegionInf: 95761
  Number of calls to alloc: 858904
  Number of calls to resetRegion: 168758
  Number of calls to deallocateRegionsUntil: 0

ALLOCATION
  Max alloc. space in pages: 39560 bytes (0.0Mb)
    incl. prof. info: 79048 bytes (0.1Mb)
  Infinite regions utilisation (79048/204400): 39%
  Number of allocated large objects: 0

STACK
  Number of calls to allocateRegionFin: 711935
  Number of calls to deallocateRegionFin: 711935
  Max space for finite regions: 10488 bytes (0.0Mb)
  Max space for region descs: 608 bytes (0.0Mb)
  Max size of stack: 61912 bytes (0.1Mb)
    incl. prof. info: 65744 bytes (0.1Mb)
    in profile tick: 0 bytes (0.0Mb)
\end{verbatim}
\caption{Region statistics for the {\tt life} program.}
\label{region_statistics.fig}
\medskip\hrule
\end{figure}

The {\tt MALLOC} part of Figure~\ref{region_statistics.fig} shows how
memory is allocated from the operating system.

Each infinite region form a linked list of one or more
\index{region pages}%
{\em region pages\/} whose size is found in the {\tt REGION PAGES}
part. The value
\begin{verbatim}
  Max number of allocated pages: 25
\end{verbatim}
multiplied by
\begin{verbatim}
  Size of one page: 8176 bytes
\end{verbatim}
gives
\begin{verbatim}
  Max space for region pages: 204400 bytes (0.2Mb)
\end{verbatim}

In the {\tt INFINITE REGIONS} part, we see the number of calls to
infinite region operations such as {\tt allocateRegionInf} and {\tt
  alloc}. The program allocates 95767 infinite regions and
de-allocates 95761; the six global regions are not de-allocated
before the region statistics is printed and the program terminates.
The program allocates 858904 objects in infinite regions. Infinite
regions have been reset 168758 times. The {\tt deallocateRegionsUntil}
operation is called whenever an exception is raised, thus, we see that
no exceptions were raised by the program.

Because objects allocated in infinite regions are not split across
different region pages, it is not always possible to
fill out a region page entirely. In the {\tt ALLOCATION} part, the value
\begin{verbatim}
  Infinite regions utilisation (79048/204400): 39%
\end{verbatim}
shows memory utilisation for infinite regions at the moment where the
program has allocated the largest amount of memory in infinite
regions.

In the {\tt STACK} part, we see that the program allocates and
de-allocates the same number of finite regions. We also see that the
space used for finite regions is 10488 bytes and that the total use of
stack space is 61912 bytes (excluding space used to hold profiling
information). The stack size values
\begin{verbatim}
    incl. prof. info: 65744 bytes (0.1Mb)
    in profile tick: 0 bytes (0.0Mb)
\end{verbatim}
can be used to see if it is necessary to profile with a smaller time
slot, which will often lower the difference between the two values.


%--------------------------------------------
\section{Processing the Profile Data File}
%--------------------------------------------
The profile data-file {\tt profile.rp} can be processed by the
\index{rp2ps@\texttt{rp2ps} options|(}%
graph generator {\tt rp2ps} (read: RegionProfile2PostScript) found in
the {\tt bin} directory.\footnote{The {\tt rp2ps} program is based on
  a Haskell profiler written by Colin Runciman, David Wakeling and Niklas
  R\"{o}jemo.} The graph generator is controlled by command line
options.

A
\index{region profile}%
\index{region@\texttt{-region} option}%
region profile is produced by typing
\begin{verbatim}
  $ rp2ps -region
\end{verbatim}
at the command prompt. The program produces a PostScript file {\tt
  region.ps} by reading profile information from the \index{profile
  data file}% profile data file {\tt profile.rp}, see
Figure~\ref{profStrategy.fig}.  A region profile for the {\tt life}
program is shown in Figure~\ref{lifeprof80.fig} on
page~\pageref{lifeprof80.fig}. The region that occupies the largest
area is at the top. If there are more regions than can be shown in
different colors, then the smallest regions are collected in an OTHER
band at the bottom.

Each region is identified with a number that matches a {\tt
  region}-bound region variable in the region-annotated program.
Infinite regions end with {\tt inf} and finite regions end with {\tt
  fin}. There are also a band named {\tt rDesc} and a band named
{\tt stack}. The {\tt rDesc} band shows the memory used on
region descriptors of infinite regions on the stack. The stack band
shows stack usage excluding finite regions and region descriptors for
infinite regions.

The vertical line marked ``Maximum allocated bytes...'' in
Figure~\ref{lifeprof80.fig} is called the {\em maximum allocation
  line}; it shows the maximum number of bytes allocated in regions and
on the stack when the program was executed. Notice that this maximum
is often lower than the sum of the maximum allocated bytes in regions
and the maximum allocated bytes on the stack. The space between the
maximum allocation line and the top band shows the inaccuracy of the
profiling strategy. To decrease the gap, it often helps to use a
smaller time slot.

The largest region shown in Figure~\ref{lifeprof80.fig} is {\tt
  r155180}. An
\index{object profile}%
\index{object@\texttt{-object} option}%
object profile of region {\tt r155180} is produced by typing
\begin{verbatim}
  $ rp2ps -object 212422
\end{verbatim}
at the command prompt. We obtain the object profile shown in
Figure~\ref{prof_eks2.fig}.
\begin{figure}
\includerp{life_ex2.pdf}
\caption{The object profile shows all allocation points allocating into region {\tt r155180}.}
\label{prof_eks2.fig}
\medskip\hrule
\end{figure}

We see that allocation point \texttt{pp15} is responsible for the
largest amount of allocations in the program. The allocation point may
be found in the region-annotated program resulting from compiling the
{\tt life} program (remember to enable printing of program points). In
general, program points may also stem from the Basis Library (search
the {.log} files in the directory {\tt basis}).

The stack profile shown in Figure~\ref{prof_eks3.fig} shows memory
usage on the stack, excluding space used by finite regions. A
\index{stack profile}%
\index{stack@\texttt{-stack} option}%
stack profile is generated by typing
\begin{verbatim}
  $ rp2ps -stack
\end{verbatim}
at the command prompt.

\begin{figure}
\includerp{life_ex3.pdf}
\caption{Memory usage on the stack excluding space for finite regions.}
\label{prof_eks3.fig}
\medskip\hrule
\end{figure}

%-------------------------------------------------------
\section{Advanced Graphs with \texttt{rp2ps}}
%-------------------------------------------------------
This section gives a quick overview of the more advanced options that can
be passed to \texttt{rp2ps}. First of all, it is possible to name the
profiles with the
\index{name@\texttt{-name} option}%
{\tt -name} option. Comments are inserted on the
x-axis with the
\index{comment@\texttt{-comment} option}%
{\tt -comment} option.

The profile data file may contain a large number of \emph{samples}
(the data collected by a profile tick is called a sample). By default,
\texttt{rp2ps} uses only 64 samples. You can alter the setting with the
\index{sampleMax@\texttt{-sampleMax} option}%
\texttt{-sampleMax} option. The following two possibilities are used to sort
out samples:

\vspace{2mm}
{
\def\arraystretch{1.4}
\begin{tabular}{lp{8cm}}
{\tt -sortBySize} & The $n$ (specified by \texttt{-sampleMax}) largest samples are
shown. %
\index{sortBySize@\texttt{-sortBySize} option} \\
{\tt -sortByTime} & The $n$ samples shown are equally distributed over time (default). %
\index{sortByTime@\texttt{-sortByTime} option}
\end{tabular}
}
\vspace{2mm}

The \texttt{-sortBySize} option is useful if your profiles have a
large gap between the top band and the maximum allocation line.  If
there is a large gap when using option \texttt{-sortBySize}, then it
may help to profile with a smaller time slot. You can use the
\index{stat@\texttt{-stat} option}%
{\tt -stat} option to see the number of samples in the profile data
file. It is printed as \texttt{Number of ticks:}.

Figure~\ref{prof_eks4.fig} shows the profile for the following
command line:
\begin{verbatim}
  $ rp2ps -region -sampleMax 50 -name life \
          -comment 0.06 "A comment at time 0.06" -sortBySize
\end{verbatim}

\begin{figure}
  \includerp{life_ex4.pdf}
\caption{It is possible to insert comments in profile graphs.}
\label{prof_eks4.fig}
\medskip\hrule
\end{figure}

The graph generator recognises several options that are not mentioned
here. Help on these options is obtained by typing \texttt{rp2ps -h} or
\index{help@\texttt{-help} option}%
{\tt rp2ps -help} at the command prompt.
\index{rp2ps@\texttt{rp2ps} options|)}%

%---------------------------------------------------------
\chapter{Controlling MLKit Compilation}
\label{controlkit.sec}
\label{startup.sec}
%---------------------------------------------------------

We have already described how to compile and run single source files
(Section~\ref{tryit.sec}) and MLB-files
(Chapter~\ref{mlb_and_modules.chap}).  In the following sections,
we give an overview of MLKit options for controlling printing and
layout of intermediate forms. One useful command-line option is
the
\index{help@\texttt{-help} option to \texttt{mlkit}}%
{\tt -help} option; Appendix~\ref{mlkithelp.app} shows the output of
executing \boxml{mlkit -help}.



%------------------------------------------------
\section{Printing of Intermediate Forms}
\label{printing_intermediate_forms.sec}
%------------------------------------------------
A series of options may be used to control
\index{Printing of intermediate forms}%
printing of intermediate forms during compilation.
A summary of the major phases that produce printable intermediate
forms is shown in Figure~\ref{phases.fig}. The phases are listed in
the order they take place in the MLKit.
\begin{figure}
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
 {\bf Phase} & {\bf Result} & {\bf Flag(s) that Print Result} \\
\hline
 Elaboration            & $\Lam$    & \hfill \boxml{$(\ast)$}\\
 Elim. of Poly. Eq.     & $\Lam$    & \hfill \boxml{$(\ast)$}\\
 Lambda Optimiser       & $\Lam$    & \boxml{-Pole} \hfill $(\ast)$\\
 Spreading              & $\RegExp$ & \hfill \boxml{$(\ast)$}\\
 Region Inference       & $\RegExp$ & \hfill \boxml{$(\ast)$}\\
 Multiplicity Inference & $\MulExp$ & \hfill \boxml{$(\ast)$}\\
 K-normalisation        & $\MulExp$ & \\
 Storage Mode Analysis  & $\MulExp$ & \boxml{-Psme} \hfill $(\ast)$\\
 Dropping of Regions    & $\MulExp$ & \boxml{-Pdre} \hfill $(\ast)$\\
                        &           & \boxml{-Pdresm} \\
 Physical Size Inference& $\MulExp$ & \boxml{-Ppse} \hfill $(\ast)$\\
 Call Conversion        & $\MulExp$ & \boxml{-Pcee} \hfill $(\ast)$\\
\hline
\end{tabular}
\end{center}
\caption{The table shows how different options correspond to printing
  different intermediate program representations.  The option
  \boxml{-debug} causes all intermediate forms marked $(\ast)$ to be
  printed.  Thus, one can select phases individually or ask to have
  all intermediate forms printed.  The phases that follow
  K-normalisation all work on K-normal forms, but, for readability,
  terms are printed as if they had not been normalised.}
\label{phases.fig}
\end{figure}

The optimiser, which rewrites a $\Lam$\index{Lambda@$\Lam$}
program, collects statistics about the optimisation. This statistics
is printed if the option $$\texttt{-statistics\_after\_optimisation}$$ %
\index{statistics after optimisation@\texttt{-statistics\_after\_optimisation}}%
\index{optimisation!statistics}%
is provided.

Storage mode analysis (see Chapter~\ref{storagemodes.sec}) results in
a $\MulExp$\index{MulExp@$\MulExp$} expression, which is printed if the option
\index{print storage mode expression@\texttt{-print\_storage\_mode\_expression}}%
\texttt{-print\_storage\_mode\_expression} is provided.  After that, region parameters
for which there are only $\Get$ effects on in the type scheme for a
region polymorphic function are removed from the $\MulExp$ expression
(see page~\pageref{bother-to-distinguish-get-n-put}).  To see the
resulting expression, turn on
\index{print drop regions expression@\texttt{-print\_drop\_regions\_expression}}%
\texttt{-print\_drop\_regions\_expression} or
$$\texttt{-print\_drop\_regions\_expression\_with\_storage\_modes}$$
The latter flag also prints storage modes.

\index{physical size inference}%
\index{region size}%
Physical size inference then determines the size in words of finite
region variables.  For instance, a finite region that will contain a
pair will have physical size two words.  To see the expression after
physical size inference, provide the option
\index{print physical size inference expression@\texttt{-print\_physical\_size\_inference\_expression}}%
\texttt{-print\_physical\_size\_inference\_expression}.  After that,
\index{call conversion}%
call conversion converts the $\MulExp$ expression to a
\index{expression!call-explicit}call-explicit expression (see
page~\pageref{call-explicit}).  To see the result, provide the option
$$\texttt{-print\_call\_explicit\_expression}$$

After that, you can inspect the code at different steps of the
transformation into machine code by providing different options (use
the \texttt{-help} option to see which.

\section{Layout of Intermediate Forms}
\label{layout_intermediate_forms.sec}
While the switches described in the previous section concern which
intermediate forms to print, the switches described in this section
%
\index{layout control}%
%
control how the different forms are printed.

The options
\index{print types@\texttt{-print\_types}}%
\texttt{-print\_types},
\index{print effects@\texttt{-print\_effects}}%
\texttt{-print\_effects}, and
\index{print regions@\texttt{-print\_regions}}%
\texttt{-print\_regions} control the printing of region-annotated types,
effects, and region allocation points (e.g., $\at\,\rho$).
All eight combinations of these three flags are possible, but if
\index{print effects@\texttt{-print\_effects}}%
{\tt -print\_effects} is turned on, it is best also to turn the two
others on so that one can see where the effect variables and region variables
that appear in arrow effects are bound.

%---------------------------------------------------------
\chapter{Calling C Functions}
\label{ccall.sec}
%---------------------------------------------------------

In this chapter, we describe how the MLKit programmer can call
\index{C!calling}%
C functions from within Standard ML programs.  The MLKit allows ML
values to be passed to C functions, which again may return ML values.
Not all ML values are represented as if they were C values. For
instance, C strings are null-terminated arrays of characters, whereas
ML strings in the MLKit are represented as a linked list of bounded
sized character arrays. To allow the programmer to conveniently
convert between C values and ML values, the MLKit provides conversion
functions and macros for commonly used data structures.

When the MLKit calls a C function, data structures returned by the
function are stored in regions that are allocated by the MLKit. For
dynamically sized objects of the resulting value, such as strings and
lists, regions are allocated by the MLKit and passed to the C function
as additional arguments; the C function must then itself allocate
space in these regions for the dynamically sized data
structures. Moreover, for those parts of the resulting value for which
the size can be determined statically, pointers to already allocated
space are passed to the C function as additional arguments.

In both cases, the MLKit uses region inference to infer the lifetime of
regions that are passed to the C function.  The region inference
algorithm does not analyse C functions. Instead, the MLKit inspects the
ML type provided by the programmer. The MLKit assumes that functions
with monomorphic types are
\index{region exomorphism}%
region exomorphisms;
\index{region endomorphism}%
region endomorphic functions may be described using ML polymorphism,
see Section~\ref{C_polymorphism.sec}.

For every C function that is called from an ML program, the order of the
additional region arguments is uniquely determined by the ML result type
of the function.  This type must be constructed from lists, records,
booleans, reals, strings, integers, and type variables.

When profiling is enabled, yet another additional argument, a program
point, is passed to the C function. This argument provides allocation
primitives with information about what points in the program
contributes with allocation; see Section~\ref{prof.sec}.

Examples of existing libraries that can be accessed from within ML
programs include database client drivers (e.g., for Postgresql) and
standard UNIX libraries providing functions such as {\tt time}, {\tt
  cp}, and {\tt fork}. There are limitations to the scheme,
however. First, because C and the MLKit do not share value
representations, transmitting large data structures between C and ML
will often involve significant copying. Second, some C libraries
require the user to set up
%
\index{call-back function}%
%
call-back functions to be executed when specific events occur. The
MLKit only has very limited functionality for letting a C function
call ML code.

%========================================================
\section{Declaring Primitives and C Functions}
\label{parPassing.sec}
%========================================================
The MLKit conforms in large parts to the Standard ML Basis Library. Part
of the functionality found in the basis library is programmed in C and
linked to the MLKit runtime system.  The declarations in system
dependent parts of the library use a special built-in identifier
called \index{prim@\texttt{prim}}\texttt{prim}, which is declared to have type
scheme $\forall \alpha \beta .  \texttt{string}
\ast \alpha \rightarrow \beta$ in the initial basis.  A primitive
function is then declared by passing its name to \texttt{prim}.  For
example, the declaration
\begin{verbatim}
  fun (s : string) ^ (s' : string) : string =
    prim ("concatStringML", (s, s'))
\end{verbatim}
declares string catenation.  The argument and result types are
explicitly stated so as to give the primitive the correct type scheme.
The string \boxml{"concatStringML"} denotes a C function
identifier.\footnote{Some primitives (e.g., \boxml{"="} and
  \boxml{":="}) are recognised and implemented in assembler by the
  compiler.} For the example declaration, the MLKit generates a call to
the C function \boxml{concatStringML} with arguments {\tt s} and {\tt
  s'}. The C function must then of course be present at link-time; if
not, the MLKit complains.\footnote{When profiling is enabled, the MLKit
  automatically appends the extension \texttt{Prof} for those
  functions that take regions (and thus a program point) as argument;
  see Section~\ref{prof.sec}.}%
A convenient way to declare a C function is to use the following
scheme:
$$\texttt{fun}~ \emph{vid} ~\texttt{(}x_1:\tau_1, \ldots, x_n:\tau_n\texttt{)}
    : \tau ~\texttt{=} ~\texttt{prim(}\emph{c\_func}, \texttt{(}
  x_1, \ldots, x_n\texttt{)} \texttt{)}
$$
The result type $\tau$ must be of the form
\begin{quote}
\begin{tabbing}
$\tau$ ::\== ~\= $\alpha$ $~|~$ {\tt int} $~|~$ {\tt bool} $~|~$ {\tt unit} \\
  \> $|$ \> $\tau_1 \ast \ldots \ast \tau_n$ $~|~$ $\tau$ {\tt list} $~|~$ {\tt real} $~|~$ {\tt string}
\end{tabbing}
\end{quote}
\noindent
If the result type is one of $\alpha$, {\tt int}, {\tt bool}, or ${\tt unit}$ then the
result value can be returned in a single register. Contrary, if the result type represents an allocated
value, the C function must be told where to store the value. For
any type that is either {\tt real} or a non-empty tuple type, and
does not occur in a list type of the result type $\tau$, the MLKit
allocates space for the value and passes a pointer to the allocated
space as an additional argument to the C function. For any type
representing an allocated value that is either {\tt string} or occurs in a
list type of the result type $\tau$, the MLKit cannot statically
determine the amount of space needed to store the value. Instead,
regions are passed to the C function as additional arguments and the C
function must then explicitly allocate space in these regions as
needed, using a C function provided by the runtime system. The order
in which these additional arguments are passed to the C function is determined
by a pre-order traversal of the result type $\tau$.  For a list type,
regions are given in the order:
\begin{enumerate}
    \item region for auxiliary pairs
    \item regions for elements (if necessary)
\end{enumerate}

We now give an example to show what extra arguments are passed to a
C function, given the result type. In the example, we use the following
(optional) naming convention:
names of arguments holding addresses of
pre-allocated space in regions
start with {\tt vAddr}, while names of arguments
holding addresses of region descriptors (to be used for allocation in a
region) start with {\tt rAddr}.
\begin{example}
  Given the result type $({\tt int} \ast {\tt string}) ~{\tt list}
  \ast {\tt real}$, the following extra ar\-gu\-ments are passed to the
  C function (in order): {\tt vAddrPair},
  {\tt rAddrLPairs}, {\tt rAddrEPairs}, {\tt rAddrEStrings} and {\tt
    vAddrReal}, see Figure \ref{args_ex1.fig}.

  Here {\tt vAddrPair} holds an address pointing to pre-allocated
  storage in which the tuple of the list and the (pointer to the) real
  should reside. The argument {\tt rAddrLPairs} holds the region
  address for the auxiliary pairs of the list. Similarly, the
  arguments {\tt rAddrEPairs} and {\tt rAddrEStrings} hold region
  addresses for element pairs and strings, respectively. The argument
  {\tt vAddrReal} holds the address for pre-allocated storage for the
  real.
\end{example}

\setlength{\unitlength}{1pt}
\begin{figure}
\hrule
\begin{center}
\begin{picture}(400,155)
\put(125,140){\framebox{$\ast$}}
\put(155,100){\framebox{\texttt{real}}}
\put(75,100){\framebox{\texttt{list}}}
\put(85,60){\framebox{$\ast$}}
\put(40,20){\framebox{\texttt{int}}}
\put(115,20){\framebox{\texttt{string}}}
\put(125,140){\line(-1,-1){29}}
\put(138,140){\line(1,-1){29}}
\put(90,97){\line(0,-1){28}}
\put(85,60){\line(-1,-1){29}}
\put(98,60){\line(1,-1){29}}

\put(115,145){\circle{10}}\put(115,145){\makebox(0,0){1}}
\put(65,105){\circle{10}}\put(65,105){\makebox(0,0){2}}
\put(75,65){\circle{10}}\put(75,65){\makebox(0,0){3}}
\put(30,25){\circle{10}}\put(30,25){\makebox(0,0){4}}
\put(105,25){\circle{10}}\put(105,25){\makebox(0,0){5}}
\put(145,105){\circle{10}}\put(145,105){\makebox(0,0){6}}

\put(200,145){\circle{10}}\put(200,145){\makebox(0,0){1}}
\put(210,142){\texttt{vAddrPair}}

\put(200,125){\circle{10}}\put(200,125){\makebox(0,0){2}}
\put(210,122){\texttt{rAddrLPairs}}

\put(200,105){\circle{10}}\put(200,105){\makebox(0,0){3}}
\put(210,102){\texttt{rAddrEPairs}}

\put(200,85){\circle{10}}\put(200,85){\makebox(0,0){4}}
\put(210,82){Integers are unboxed}

\put(200,65){\circle{10}}\put(200,65){\makebox(0,0){5}}
\put(210,62){\texttt{rAddrEStrings}}

\put(200,45){\circle{10}}\put(200,45){\makebox(0,0){6}}
\put(210,42){\texttt{vAddrReal}}

\end{picture}
\caption{The order of pointers to allocated space and infinite regions
  is determined from a pre-order traversal of the result type $({\tt
  int} \ast {\tt string}) ~{\tt list} \ast {\tt real}$.}
\label{args_ex1.fig}
\end{center}
\hrule
\end{figure}

Additional arguments holding pointers to pre-allocated space and
infinite regions are passed to the C function prior to the ML
arguments. Consider again the ML declaration
$$\texttt{fun}~ \emph{vid} ~\texttt{(}x_1:\tau_1, \ldots, x_n:\tau_n\texttt{)}
    : \tau ~\texttt{=} ~\texttt{prim(}\emph{c\_func}, \texttt{(}
  x_1, \ldots, x_n\texttt{)} \texttt{)}
$$
\noindent
The C function \emph{c\_func} must then be declared as
\begin{eqnarray}
  \texttt{int} \ \emph{c\_func} \ \texttt{(}\texttt{int}\ \emph{addr}_1,
    \ldots, \texttt{int}\ \emph{addr}_m,\ \texttt{int}\ x_1, \ldots, \texttt{int}\ x_n\texttt{)} \nonumber
\end{eqnarray}
\noindent
where \emph{addr}$_1$, $\ldots$, \emph{addr}$_m$ are pointers to
pre-allocated space and infinite regions as described above.


%========================================
\section{Conversion Macros and Functions}
%========================================
The runtime system provides a small set of conversion macros and
functions for use by C functions that need to convert between ML
values and C values. Using these conversion macros and functions for
converting between representations protects you against future
changes in the representation of ML values. The conversion macros and
functions are declared in the header
files:\index{Tagging.h@\texttt{Tagging.h}}\index{String.h@\texttt{String.h}}
\begin{verbatim}
  src/Runtime/Tagging.h
  src/Runtime/String.h
  src/Runtime/List.h
\end{verbatim}

%--------------------
\subsection{Integers}
%--------------------
There are two macros for converting between the ML representation of
integers and the C representation of integers:\footnote{These macros are the identity maps when garbage collection is disabled.}
\index{convertIntToC@\texttt{convertIntToC}}%
\index{convertIntToML@\texttt{convertIntToML}}%
\begin{verbatim}
  #define convertIntToC(i)
  #define convertIntToML(i)
\end{verbatim}
To convert an ML integer \verb|i_ml| to a C integer (type \texttt{long int}) \verb|i_c|,
write
\begin{verbatim}
  i_c = convertIntToC(i_ml);
\end{verbatim}
To convert a C integer (type \texttt{long int}) \verb|i_c| to an ML
 integer \verb|i_ml|, write
\begin{verbatim}
  i_ml = convertIntToML(i_c);
\end{verbatim}
The macros demonstrated here are used in the examples~\ref{power.ex},
\ref{power_real.ex}, and~\ref{power_exn.ex} in Section~\ref{Cexamples.sec}.

%-----------------
\subsection{Units}
%-----------------
The following constant in the conversion library denotes the ML
representation of {\tt ()}:
\index{mlUNIT@\texttt{mlUNIT}}%
\begin{verbatim}
  #define mlUNIT
\end{verbatim}

%-----------------
\subsection{Reals}
%-----------------
An ML real is represented as a pointer into a region containing the
real. To convert an ML real to a C real, we dereference the pointer. To
convert a C real to an ML real, we update the memory to contain the C
real. The following two macros are provided:
\index{convertRealToC@\texttt{convertRealToC}}%
\index{convertRealToML@\texttt{convertRealToML}}%
\begin{verbatim}
  #define convertRealToC(mlReal)
  #define convertRealToML(cReal, mlReal)
\end{verbatim}

Converting an ML real \verb|r_ml| to a C real \verb|r_c| can be done with the first macro:
\begin{verbatim}
  r_c = convertRealToC(r_ml);
\end{verbatim}

Converting from a C real to an ML real (being part of the result value of the
C function) is done in one or two steps depending on whether the real is
part of a list or not. If the real is not in a list the memory containing
the real has been allocated before the C call, see Section~\ref{parPassing.sec}:
\begin{verbatim}
  convertRealToML(r_c, r_ml);
\end{verbatim}
If the ML real is part of a list element, then space must be allocated for
the real before converting it. If \boxml{rAddr} identifies a region
for the real, you write:
\index{allocReal@\texttt{allocReal}}%
\begin{verbatim}
  allocReal(rAddr, r_ml);
  convertRealToML(r_c, r_ml);
\end{verbatim}

These macros are used in the examples~\ref{power_real.ex},
\ref{power_exn.ex} and~\ref{real_list.ex} in
Section~\ref{Cexamples.sec}.

%--------------------
\subsection{Booleans}
%--------------------
Four constants provide the values of true and false in ML and in C.
These constants are defined by the following macros:\footnote{For
  historical reasons, booleans in the MLKit are tagged even when garbage
  collection is disabled.}
\index{mlTRUE@\texttt{mlTRUE}}%
\index{mlFALSE@\texttt{mlFALSE}}%
\index{cTRUE@\texttt{cTRUE}}%
\index{cFALSE@\texttt{cFALSE}}%
\begin{verbatim}
  #define mlTRUE  3
  #define mlFALSE 1
  #define cTRUE   1
  #define cFALSE  0
\end{verbatim}

Two macros are provided for converting booleans:
\index{convertBoolToC@\texttt{convertBoolToC}}%
\index{convertBoolToML@\texttt{convertBoolToML}}%
\begin{verbatim}
  #define convertBoolToC(i)
  #define convertBoolToML(i)
\end{verbatim}
Converting booleans is similar to converting integers:
\begin{verbatim}
  b_c = convertBoolToC(b_ml);
  b_ml = convertBoolToML(b_c);
\end{verbatim}

%-------------------
\subsection{Records}
%-------------------
Records are boxed. One macro is provided for storing and retrieving
elements:
\index{elemRecordML@\texttt{elemRecordML}}%
\begin{verbatim}
  #define elemRecordML(recAddr, offset)
\end{verbatim}
An element can be retrieved from a record \verb|rec_ml| by writing
\begin{verbatim}
  e_ml = elemRecordML(rec_ml, offset);
\end{verbatim}
where the first element has \boxml{offset} 0. An element \verb|e_ml|
is stored in an ML record \verb|rec_ml| by writing
\begin{verbatim}
  elemRecordML(rec_ml, offset) = e_ml;
\end{verbatim}
Two specialized versions of the \boxml{elemRecordML} macro are
provided for
\index{first@\texttt{first}}%
\index{second@\texttt{second}}%
pairs:
\begin{verbatim}
  #define first(x)
  #define second(x)
\end{verbatim}

If the record is to be part of a list element then it is necessary to allocate the record
before storing into it. This allocation is done with the macro
\index{allocRecordML@\texttt{allocRecordML}}%
\begin{verbatim}
  #define allocRecordML(rAddr, size, vAddr)
\end{verbatim}
where \boxml{rAddr} denotes a region (i.e., a pointer to a region
descriptor), \boxml{size} is the size of the record (i.e., the number
of components), and \boxml{vAddr} is a variable in which
\boxml{allocRecordML} returns a pointer to storage for the record. The
record is then stored, component by component, by repeatedly calling
\boxml{elemRecordML} with the pointer \boxml{vAddr} as argument.

The above macros are used in examples~\ref{real_list.ex},
\ref{change_elem.ex} and~\ref{dir.ex} in Section~\ref{Cexamples.sec}.

%-------------------
\subsection{Strings}
%-------------------
Strings are boxed and always allocated in infinite regions. It is possible
to print an ML string by using the C function
\index{printStringML@\texttt{printStringML}}%
\begin{verbatim}
  void printStringML(String str);
\end{verbatim}

Strings are converted from ML to C and vice versa using the two C
functions
\index{convertStringToC@\texttt{convertStringToC}}%
\index{convertStringToML@\texttt{convertStringToML}}%
\begin{verbatim}
  void convertStringToC(String mlStr, char *cStr,
                        size_t cStrLen, int exn);
  String convertStringToML(Region rAddr, char *cStr);
\end{verbatim}
An ML string \verb|str_ml| is converted to a C
string \verb|str_c| in already allocated storage of size \boxml{size} bytes by writing
\begin{verbatim}
  convertStringToC(ctx, str_ml, str_c, size, exn);
\end{verbatim}
where \boxml{exn} is some ML exception value (see
Section~\ref{C_exceptions.sec}) to be raised if the ML string has size
greater than \boxml{size} and \texttt{ctx} is an evaluation context
obtained using the \verb|__get_ctx| primitive.

A C string is converted to an ML string in the region denoted by
\boxml{rAddr} by writing
\begin{verbatim}
  str_ml = convertStringToML(rAddr, str_c);
\end{verbatim}

The following macro returns the size of an ML string:
\index{sizeStringDefine@\texttt{sizeStringDefine}}%
\begin{verbatim}
  size_t sizeStringDefine(String str);
\end{verbatim}

These macros are used in the examples~\ref{dir.ex} and
\ref{print_string_list.ex} in Section~\ref{Cexamples.sec}.

%-----------------
\subsection{Lists}
%-----------------

Lists are always allocated in infinite regions. A list uses, as a minimum,
one region for the auxiliary pairs of the list, see Figure~\ref{listregions.fig} on page~\pageref{listregions.fig}.

We shall now show three examples of manipulating lists. The first example
traverses a list. Consider the following C function template:
\index{traverse_list@\texttt{traverse\_list}}%
\begin{verbatim}
  void traverse_list(uintptr_t* ls) {
    uintptr_t elemML;
    for ( ; isCONS(ls); ls=tl(ls)) {
      elemML = hd(ls);
      /*do something with the element*/
    }
    return;
  }
\end{verbatim}

The ML list is passed to the C function in parameter \texttt{ls}.
The example uses a simple loop to traverse the list. The parameter
\texttt{ls} points at the first constructor in the list. Each time
we have a \texttt{CONS} constructor we also have an element, see
Figure~\ref{listregions.fig}. The element can be retrieved with the
\texttt{hd} macro.  One retrieves the tail of the list by using the
\texttt{tl} macro.

The following four macros are provided in the {\tt src/Runtime/List.h}
header file:
\index{isNIL@\texttt{isNIL}}%
\index{isCONS@\texttt{isCONS}}%
\index{hd@\texttt{hd}}%
\index{tl@\texttt{tl}}%
\begin{verbatim}
  #define isNIL(x)
  #define isCONS(x)
  #define hd(x)
  #define tl(x)
\end{verbatim}

The next example explains how to construct a list backwards. Consider
the following C function template:
\index{mk_list_backwards@\texttt{mk\_list\_backwards}}%
\begin{verbatim}
  uintptr_t mk_list_backwards(Region pairRho) {
    uintptr_t *resList, *pair;
    makeNIL(resList);
    while (/*more elements*/) {
      ml_elem = ...;
      allocRecordML(pairRho, 2, pair);
      first(pair) = (uintptr_t) ml_elem;
      second(pair) = (uintptr_t) resList;
      makeCONS(pair, resList);
    }
    return (uintptr_t)resList;
  }
\end{verbatim}
First, we create the \texttt{NIL} constructor, which marks the end of
the list. Then, each time we have an element, we allocate a pair. We
store the element in the first cell of the pair. A pointer to the list
constructed so far is put in the second cell of the pair. (In this
release of the MLKit, the \boxml{makeCONS} macro simply assigns its
second argument the value of its first argument.) In the example, we
have assumed that the elements are unboxed, thus, no regions are
necessary for the elements.

The last example shows how a list can be constructed forwards. It is more
clumsy to construct the list forwards because we have to return a pointer
to the first element. Consider the following C function template.
\index{mk_list_forwards@\texttt{mk\_list\_forwards}}%
\begin{verbatim}
  uintptr_t mk_list_forwards(Region pairRho) {
    uintptr_t *pair, *cons, *temp_pair, res;

    /* The first element is special because we have to    */
    /* return a pointer to it.                            */
    ml_elem = ...
    allocRecordML(pairRho, 2, pair);
    first(pair) = (uintptr_t) ml_elem;
    makeCONS(pair, cons);
    res = (uintptr_t) cons;

    while (/*more elements*/) {
      ml_elem = ...
      allocRecordML(pairRho, 2, temp_pair);
      first(temp_pair) = (uintptr_t) ml_elem;
      makeCONS(temp_pair, cons);
      second(pair) = (uintptr_t) cons;
      pair = temp_pair;
    }
    makeNIL(cons);
    second(pair) = (uintptr_t)cons;
    return res;
  }
\end{verbatim}

We create the \texttt{CONS} constructor and pair for the first element
and return a pointer to the \texttt{CONS} constructor (the pair) as
the result. We then construct the rest of the list by constructing a
\texttt{CONS} constructor and a pair for each element. It is necessary
to use a temporary variable for the pair (\verb|temp_pair|) because we
have to update the pair for the previous element. The second component
of the last pair contains the \texttt{NIL} constructor and thus
denotes the end of the list.

The two macros \texttt{makeCONS} and \texttt{makeNIL} are provided in
the \boxml{List.h} header file:
\index{makeNIL@\texttt{makeNIL}}%
\index{makeCONS@\texttt{makeCONS}}%
\begin{verbatim}
  #define makeNIL(rAddr, ptr)
  #define makeCONS(rAddr, pair, ptr)
\end{verbatim}

%=======================================================
\section{Exceptions}
\label{C_exceptions.sec}
%=======================================================
C functions are allowed to raise exceptions and it is possible for the
ML code to handle these exceptions. A C function cannot declare
exceptions locally, however. For technical reasons, we must
first acquire an
%
\index{evaluation context}
%
evaluation context, which can be obtained using the
special built-in primitive \texttt{\_\_get\_ctx}:
\begin{verbatim}
  fun getCtx () : foreignptr =
    prim("__get_ctx", ())
\end{verbatim}

\noindent
Now, as an example, consider the following ML declaration:
\begin{verbatim}
  exception Exn
  fun raiseif0 (arg : int) : unit =
    prim("raiseif0", (getCtx(), arg, Exn))
\end{verbatim}
If we want the function \texttt{raiseif0} to raise the exception value
\texttt{Exn} if the argument (\texttt{arg}) is 0 then we use the
function \verb|raise_exn| provided by the runtime system, by
including the header file {\tt src/Runtime/Exception.h}. The C
function \boxml{raiseif0} may be defined thus:
\begin{verbatim}
  void raiseif0(Context ctx, long i_ml, uintptr_t exn) {
    long i_c;
    i_c = convertIntToC(i_ml);
    if (i_c == 0) raise_exn(ctx, exn);
    return;
  }
\end{verbatim}
Notice that the supplied context is passed to the \texttt{raise\_exn}
function, which uses the context to gain access to the region stack
and to the current exception handler.

Notice also that there is no need to make the function
\texttt{raiseif0} return the value \boxml{mlUNIT}; in case the type of
the return value is \boxml{unit} then the MLKit automatically inserts
code for returning the ML value \boxml{()} after the call to the C
function.

Exceptions are used in examples~\ref{power_exn.ex} and~\ref{dir.ex} in
Section~\ref{Cexamples.sec}.

%=======================================================
\section{Program Points for Profiling}
\label{prof.sec}
%=======================================================
To support profiling, the programmer must provide special profiling
versions of those C functions that allocate space in regions (i.e.,
that take regions as additional arguments). If profiling is enabled
and at least one pointer to a region is passed to the C function then
also a program point that represents the call to the C function is
passed.  The program point is used by the C function when allocating
space in regions, as explained in Section~\ref{prof.sec}. The program
point is passed as the last argument:
\begin{tabbing}
\indent\=  $\texttt{uintptr\_t} \ \emph{c\_funcProf} \ ($\=$\texttt{Region}\ \emph{addr}_1,
    \ldots, \texttt{Region}\ \emph{addr}_m,$\\
  \>\>$ \texttt{uintptr\_t}\ x_1, \ldots,
    \texttt{uintptr\_t}\ x_n, \texttt{long}\ \emph{pPoint}) $
\end{tabbing}
\noindent
No special version of the C function is needed if it does not allocate
into infinite regions; in this case, the same C function can be used
both when profiling is enabled and disabled.

A program point passed to a C function is an integer; it identifies the
allocation point that represents the C call in the program, see
Chapter~\ref{useOfProf.sec}.

The runtime system provides special versions of various allocation
macros and functions presented earlier in this chapter:
\index{allocRealProf@\texttt{allocRealProf}}%
\index{allocRecordMLProf@\texttt{allocRecordMLProf}}%
\index{convertStringToMLProf@\texttt{convertStringToMLProf}}%
\begin{verbatim}
  #define allocRealProf(realRho, realPtr, pPoint)
  #define allocRecordMLProf(rhoRec, ssize, recAddr, pPoint)
  String convertStringToMLProf(Region rhoString,
                               char *cStr,
                               long pPoint);
\end{verbatim}

Here is the profiling version of the C function
\verb|mk_list_backwards|:
\begin{verbatim}
  uintptr_t
  mk_list_backwardsProf(Region pairRho, long pPoint) {
    uintptr_t *resList, *pair;
    makeNIL(resList);
    while (/*more elements*/) {
      ml_elem = ...;
      allocRecordMLProf(pairRho, 2, pair, pPoint);
      first(pair) = (uintptr_t) ml_elem;
      second(pair) = (uintptr_t) resList;
      makeCONS(pair, resList);
    }
    return (uintptr_t) resList;
  }
\end{verbatim}
The example shows that it is not difficult to make the profiling
version of a C function; use the \texttt{Prof} versions of the
macros and use the extra argument \texttt{pPoint}, appropriately. The
same program point is used for all allocations in the C function,
perceiving the C function as one entity.

%=======================================================
\section{Storage Modes}
%=======================================================
As described in Chapter~\ref{storagemodes.sec} on
page~\pageref{atbit.lab}, actual region parameters contain a storage
mode at runtime, if the region is infinite.  A C function may check
the storage mode of an infinite region to see whether it is possible
to reset the region before allocating space in it. The header file
{\tt src/Runtime/Region.h} of the runtime system provides a macro
\index{is_inf_and_atbot@\texttt{is\_inf\_and\_atbot}}%
\verb|is_inf_and_atbot|, which can be used to test whether resetting
is safe, assuming that the arguments to the C function are dead.

The C function \texttt{resetRegion}, which is also provided by the
runtime system in the header file {\tt src/Runtime/Region.h}, can be
used to reset a region. Consider again the \verb|mk_list_backwards|
example. If the $\atbot$ bit of the region for the list is set, then
this region can be reset prior to constructing the list:
\index{resetRegion@\texttt{resetRegion}}%
\begin{verbatim}
  uintptr_t mk_list_backwards(Region pairRho) {
    uintptr_t *resList, *pair;
    if (is_inf_and_atbot(pairRho)) resetRegion(pairRho);
    makeNIL(resList);
    ...
  }
\end{verbatim}
The C programmer should be careful not to reset regions that
potentially contain live values. In particular, the C programmer must be
conservative and take into account possible region aliasing between
regions holding arguments and regions holding the result.
Clearly, if a region that the C function is supposed to
return a result in contains part of the value argument(s) of the function,
then the function should not first reset the region and
then try to access the argument(s).

%=======================================================
\section{Endomorphisms by Polymorphism}
\label{C_polymorphism.sec}
%=======================================================
Until now, we have seen examples only of C functions that are region
exomorphic, that is, functions that, in general, write their result
into regions that are different from those in which the arguments
reside.

A region endomorphic function has the property that the result of
calling the function is stored in the same regions that hold the
arguments to the function. Region endomorphic functions are useful
when the result of the function shares with parts of the arguments.
Consider the C function
\begin{verbatim}
  uintptr_t select_second(uintptr_t pair) {
   return second(pair);
  }
\end{verbatim}
which selects the second component of {\tt pair} (cast to an
integer); the identifier {\tt second} is defined in the header
file {\tt Tagging.h} by the macro definition
\begin{verbatim}
  #define second(x)  (*((uintptr_t *)(x)+1))
\end{verbatim}

Now, for the MLKit to make correct, that is safe, decisions about when
to de-allocate regions, the endomorphic properties of a C function
must be expressed in the region-annotated type scheme for value identifiers
to which the C function is bound. The programmer can tell the MLKit
about region endomorphic behavior of a C function by using type
variables.  For example, here is an ML declaration that binds a value
identifier {\tt second} to the C function
\verb|select_second|:\footnote{MLB-file: {\tt kitdemo/select\_second.mlb}. The C
  file {\tt select\_second.c} must be compiled (using {\tt gcc}) to
  form the object file (archive) {\tt libselect\_second.a} before the project can
  be compiled: \texttt{mlkit -no\_gc -dirlibs "." -libs "m,dl,c,select\_second" select\_second.mlb}.}
\begin{verbatim}
  fun second(pair : 'a * 'b) : 'b =
    prim("select_second", pair)
\end{verbatim}
The MLKit associates the following region-annotated type scheme to the value
identifier {\tt second}:
$$\forall \alpha_1\alpha_2\rho\epsilon.(\alpha_1 * \alpha_2, \rho)
\ar{\epsilon.\{\Get(\rho_3)\}} \alpha_2$$ Notice that the
region-annotated type scheme expresses the region endomorphic behavior
of the C function. That is, for any substitution $S$, mapping
$\alpha_1$ and $\alpha_2$ to region types and places, the type
$S((\alpha_1 * \alpha_2, \rho) \ar{\epsilon.\{\Get(\rho_3)\}}
\alpha_2)$ will express that the result is located in the same regions
as (the second projection) of the argument.


%=======================================================
\section{Compiling and Linking}
\label{comp_and_link_with_C.sec}
%=======================================================
To use a set of C functions in the ML code, one must first compile the
C functions into an object file. (Remember to include appropriate
header files.)

As an example, the file \verb|kitdemo/libmylib.c| holds a set of
example C functions. This file is compiled into an archive (in the
form of a single object file) by typing (from the shell)
\begin{verbatim}
  $ gcc -o libmylib.a -c libmylib.c
\end{verbatim}
in the {\tt kitdemo} directory. Now, to compile the file to work with
profiling, type
\begin{verbatim}
  $ gcc -DPROFILING -o libmylib-p.a -c libmylib.c
\end{verbatim}

The MLB-file \verb|mylib.mlb|, which is listed in
Figure~\ref{mylib.mlb.fig}, mentions the file \verb|mylib.sml|, which
declares a series of ML functions to be used in the file
\verb|test_mylib.sml|.
\begin{figure}
\hrule \medskip
\begin{verbatim}
  $(SML_LIB)/basis/basis.mlb
  mylib.sml
  test_mylib.sml
\end{verbatim}
\caption{Linking with external object files is done by use of the
  \texttt{prim} primitive, which in this case is used in the file
  \texttt{mylib.sml} for declaring a series of ML functions.}
\label{mylib.mlb.fig}
\medskip \hrule
\end{figure}

Once the archives have been generated, the appropriate archive can be
passed to the \texttt{mlkit} compiler, using the options
\texttt{-libs} and \texttt{-libdirs}, as follows:
\begin{verbatim}
  $ mlkit -no_gc -o mylibtest -libdirs "." \
          -libs "m,c,dl,mylib" mylib.mlb
  ...
  $ mlkit -no_gc -prof -o mylibtest-p -libdirs "." \
          -libs "m,c,dl,mylib-p" mylib.mlb
  ...
\end{verbatim}

\noindent
To learn more about the options
\texttt{-libs} and \texttt{-libdirs}, type
\begin{verbatim}
  $ mlkit --help
\end{verbatim}
on the command line.

You may consult the file \texttt{kitdemo/Makefile} to see how one can
further automate an appropriate build process.

\section{Dynamic Linking}
\label{link_at_runtime.sec}
The MLKit supports
\index{dynamic linking}%
dynamic linking at runtime.  This is done using the
\index{dlopen!\texttt{dlopen}}%
\index{dlsym!\texttt{dlsym}}%
\texttt{dlopen} and \texttt{dlsym} functions from the MLKit library
\texttt{basis/dynlink.mlb}. The function \texttt{dlopen} opens a given
library and the function \texttt{dlsym} associates a name with a given
function in the library. If the name is already linked, the exception
\texttt{Fail} is raised.

Using the functions \texttt{dlopen} and \texttt{dlsym}, as shown in
Figure~\ref{dynlib.fig}, you can call a dynamically linked library
function using a primitive call to '\texttt{:}'.

If '\texttt{:}' is called with a name that has no association,
the exception \texttt{Match} is raised.
\begin{figure}
\hrule \medskip
\begin{verbatim}
  fun isNullFP(s : foreignptr) : bool = prim("__is_null", s)
  val b = Dynlib.dlopen (SOME "libcrack.so", Dynlib.NOW, false)
  val _ = Dynlib.dlsym ("testdyn","FascistCheck",b)
  fun fascistCheck a : string option =
    let val b : foreignptr =
      prim("@:", ("testdyn", a : string,
                  "/usr/lib/cracklib_dict"))
    in if isNullFP b
       then NONE
       else SOME(prim ("fromCtoMLstring", b))
    end
\end{verbatim}
\caption{Dynamic linking of the function \texttt{FascistCheck} from the library \texttt{libcrack.so}.
  The ML function \texttt{fascistCheck} calls \texttt{FascistCheck} with the argument
  \texttt{(a,/usr/lib/cracklib\_dict)} and converts the resulting C string into
  an ML string.
  This example uses the auto conversion feature as described in
  the next section.}
\label{dynlib.fig}
\medskip \hrule
\end{figure}

%=============================================
\section{Auto Conversion}
%=============================================
\index{auto conversion}%
\label{auto_conversion.sec}
For C functions that are simple, in a sense
that we shall soon define, the MLKit can generate code that
automatically converts representations of arguments from ML to C and
representations of results from C back to ML.

Auto conversion is enabled by prefixing a {\tt @}-character to
the name of the C function, as in the following example:
\begin{verbatim}
  fun power_auto(base : int, n : int) : int =
    prim ("@power_auto", (base, n))
\end{verbatim}

\noindent
The power function may then be implemented in C as follows:
\begin{verbatim}
  long power_auto(long base, long n) {
    long p;
    for (p = 1; n > 0; --n) p = p * base;
    return p;
  }
\end{verbatim}

\noindent
No explicit conversion is needed in the C code. Auto conversion is only
supported when the arguments of the ML function are of type {\tt int} or
{\tt bool} and when the result has type {\tt unit}, {\tt int}, or {\tt
  bool}. It works also when profiling is enabled.

The example shown here is example~\ref{power_auto.ex} of
Section~\ref{Cexamples.sec}; it is part of the \verb|mylib.mlb|
project.

%--------------------------------------
\section{Examples\label{Cexamples.sec}}
%--------------------------------------
\index{C examples}%
\index{libmylib.c@\texttt{libmylib.c}}%
\index{mylib.sml@\texttt{mylib.sml}}%
Several example C functions are located in the file
\verb|kitdemo/libmylib.c|. The MLB-file \verb|kitdemo/mylib.mlb|, which
is listed in Figure~\ref{mylib.mlb.fig}, makes use of these functions.

The source file \verb|mylib.sml|, which is part of the
\verb|mylib.mlb| project, contains the following ML declarations:
\begin{verbatim}
  fun power(base: int, n: int) : int =
    prim ("power", (base, n))

  fun power_auto(base: int, n: int) : int =
    prim ("@power_auto", (base, n))

  fun power_real (base: real, n: int) : real =
    prim ("power_real", (base, n))

  fun print_string_list (ss: string list) : unit =
    prim ("print_string_list", ss)

  exception Power
  fun power_exn (base: real, n: int) : real =
    prim ("power_exn", (base, n, Power))

  exception DIR
  fun dir (directory: string) : string list =
    prim ("dir", (directory, DIR))

  fun real_list () : real list =
    prim ("real_list", ())

  fun change_elem (p : int*string) : string*int =
    prim ("change_elem", p)
\end{verbatim}

The C function implementations are summarized below (see the files
\verb|libmylib.c| and \verb|mylib.sml| in the {\tt kitdemo} directory
for detailed comments.)

\begin{example}\label{power.ex}
  The \index{power@\texttt{power}}\texttt{power} function shows how to convert
  integers with the macros \texttt{convertIntToC} and
  \texttt{convertIntToML}.
\end{example}

\begin{example}\label{power_real.ex}
  The \index{power_real@\texttt{power\_real}}\texttt{power\_real} function shows how
  to convert reals with the macros \texttt{convertRealToC} and
  \texttt{convertRealToML}.
\end{example}

\begin{example}\label{power_auto.ex}
  The \index{power_auto@\texttt{power\_auto}}\texttt{power\_auto} function shows the
  use of auto conversion, which allows for easy linking to certain C
  functions.
\end{example}

\begin{example}\label{print_string_list.ex}
  The \index{print_string_list@\texttt{print\_string\_list}}\texttt{print\_string\_list}
  example shows how to traverse a list of strings. The technique can
  easily be adopted to other data structures (e.g., to lists of lists
  of strings).
\end{example}

\begin{example}\label{power_exn.ex}
  The \index{power_exn@\texttt{power\_exn}}\texttt{power\_exn} function shows how an
  exception can be raised from a C function.
\end{example}

\begin{example}\label{dir.ex}
  The \index{dir@\texttt{dir}}\texttt{dir} function shows how a list can be
  constructed backwards.  We use the UNIX system calls
  \texttt{opendir} and \texttt{readdir} to read the contents of the
  specified directory.

  Notice also that we check the infinite regions for resetting at the
  start of the C function. The checks should be placed at the start of
  the function, orelse not inserted at all.

  If you compare the C functions \texttt{dir} and \texttt{dirProf} you
  may see how the function \texttt{dirProf} is modified to work with
  profiling.
\end{example}

\begin{example}\label{real_list.ex}
  Function \index{real_list@\texttt{real\_list}}\texttt{real\_list} constructs a list
  of reals forwards. The reals are allocated in an infinite region. It
  may be more convenient to construct the list backwards in the C
  function and then apply a list reverse function on the result list
  in the ML program.
\end{example}

\begin{example}\label{change_elem.ex}
  Function \index{change_elem@\texttt{change\_elem}}\texttt{change\_elem} shows the use of
  the macro \texttt{elemRecordML}. The result type is \texttt{string*int}. The
  function swaps the two elements in the pair. The MLKit passes an address to
  pre-allocated space for the result pair, and an infinite region for the
  result string.

  At first thought it should be enough to just swap the two arguments, and
  not copy the string into the string region, that is, one could write the
  following function:
\begin{verbatim}
?  uintptr_t
?  change_elem(uintptr_t newPair, Region stringRho, uintptr_t pair) {
?    uintptr_t firstElem_ml, secondElem_ml;
?    firstElem_ml = elemRecordML(pair, 0);
?    secondElem_ml = elemRecordML(pair, 1);
?    elemRecordML(newPair, 0) = secondElem_ml;
?    elemRecordML(newPair, 1) = firstElem_ml;
?    return newPair;
?  }
\end{verbatim}
  This function may work sometimes but it is not safe! Region
  inference expects the result string to be allocated in
  \texttt{stringRho}, and may therefore de-allocate the region
  containing the argument string, \verb|secondElem_ml|, while the
  string in the returned pair is still live. The safe version of
  \verb|change_elem| is found in \verb|libmylib.c|. See
  Section~\ref{C_polymorphism.sec} for inspiration to how a safe
  non-copying swap function can be implemented.
\end{example}


%---------------------------------------------------------
\chapter{Summary of Changes}
%---------------------------------------------------------

\section{Changes Since Version 4.6.1}
\index{changes!since version 4.6.1}%

This section provides an overview of the main changes to the MLKit
since version 4.6.1.

\subsubsection*{Simplification of the Region Type System}

To simplify the region type system, region variables are no longer
associated with type variables and the concept of word regions has
been eliminated entirely. Instead of associating type variables with
region variables, type substitutions now map type variables to region
type and places.

\subsubsection*{GC Safety Fixed}

A problem with garbage-collection safety was fixed and it is now
properly ensured that no dangling pointers appear during evaluation,
which is a necessary requirement for combining region inference and
reference-tracing garbage collection.

\section{Changes Since Version 4.3.0}
\index{changes!since version 4.3.0}%
This section provides an overview of the main changes to the MLKit
since version 4.3.0.

\subsubsection*{X64 Backend}
The
%
\index{backend!x86}%
%
x86 native backend has been replaced with an
%
\index{backend!x64}%
%
x64 native backend, which uses the GNU assembler to create native
machine code on x86 machines. The new backend also features
intra-procedural register allocation for floating-point values. The
MLKit now also features \texttt{Int64.int} as the default integer and
\texttt{Word64.word} as the default word type (\texttt{Int63.int} and
\texttt{Word63.word} when garbage collection is enabled).

\subsubsection*{Hosted at Github}
%
\index{Github!repository}%
\index{Repository!Github}%
%
The MLKit is now hosted at Github. The repository is
\begin{quote}
  \url{https://github.com/melsman/mlkit}
\end{quote}
%
\index{bug report}%
\index{Github!issue}%
%
Bug reports should be filed by submitting a Github issue. Features and
bug fixes can be submitted via Github pull requests. Comprehensive
tests are executed  using Github actions.

\subsubsection*{JavaScript Backend (SMLtoJs)}
\index{JavaScript!SMLtoJs}%

SMLtoJs is a standalone version of the MLKit that compiles to
JavaScript and makes use of MLKit's frontend and compilation
infrastructure (e.g., recompilation management). It supports large
parts of the Standard ML Basis Library. SMLtoJs does not make use of
region-based memory management. SMLtoJs has been used for hosting a
Standard ML compiler in a web browser
\cite{10.1145/2093328.2093336}. To try Standard ML in a browser, visit
the site

\begin{quote}
\url{https://diku-dk.github.io/sml-ide/}
\end{quote}

\subsubsection*{Generational Garbage Collection}
\index{garbage collection!generational}%

The non-generational pointer-tracing garbage collection technique has
been augmented with a generational version (option \texttt{-gengc}),
which in some cases is superior to ordinary reference-tracing garbage
collection, but which may also cause additional fragmentation
\cite{elshaljfp21}.

\subsubsection*{Improved Basis Library Coverage}

The Standard ML Basis library coverage has been extended to support
also the \texttt{Unix} structure, socket programming through the
%
\index{socket!programming}%
%
\texttt{Socket} structure, the \texttt{NetHostDb} structure, and the
\texttt{INetSock} structure. With the move to the x64 architecture,
the MLKit now also supports the structures \texttt{Word63},
\texttt{Word64}, \texttt{Int63}, and \texttt{Int64}.


\section{Changes Since Version 4}
\index{changes!since version 4}%
This section provides an overview of the main changes to the MLKit
since version 4, but before version 4.3.0.

\subsubsection*{Support for Compiling ML Basis Files}
\index{ML Basis Files}%
ML Basis Files allows for expressing source dependencies, exactly (as
a directed acyclic graph). ML Basis Files thus provides a mechanism
for programming ``in the very large''.

\subsubsection*{File-based Separate Compilation}
\index{separate compilation}%
The MLKit now supports file-based separate compilation, based on
dependencies established from ML Basis Files. The compiler serializes
symbol table information to disk for each compilation unit, so that
this information can be deserialized and used when compiling other
compilation units.

\subsubsection*{Updated Standard ML Basis Library}
\index{Standard ML!{Basis Library}}%
\index{Basis Library}%
The MLKit implementation of the Standard ML Basis Library now conforms to the
  specification published in \cite{basislib2004}.

\subsubsection*{Untagged Pairs, Triples and References}
\index{untagging}%
\index{tagging}%
\index{garbage collection}%
\index{value representation}%
The MLKit now support untagged representations of heap-allocated
pairs, triples, and Standard ML references, even when garbage
collection is enabled.

\section{Changes Since Version 3}
\index{changes!since version 3}%
This section provides an overview of the main changes to the MLKit
since version 3, but before version 4.

\subsubsection*{Garbage Collection}
\index{garbage collection}%
The MLKit supports reference tracing garbage collection in
combination with the region memory model. Garbage collection is
supported only in the native backend version of the MLKit. To enable
garbage collection, pass the option \texttt{-gc} to the MLKit compiler. Garbage
collection is also possible with region profiling enabled. See
Chapter~\ref{gc.chap} for more information about garbage collection
with the MLKit.

\subsubsection*{X86 Backend}
The
\index{backend!hppa}%
HPPA backend of the MLKit version 3.0 and earlier has been replaced
with an
\index{backend!x86}%
x86 native backend, which uses the GNU assembler to create native
machine code on x86 machines.

\subsubsection*{Bytecode Backend}
\index{backend!bytecode}%
For portability, the MLKit now provides a bytecode backend and a
bytecode interpreter. Which backend is used by the MLKit compiler is
determined when the MLKit itself is compiled, but it is possible to have
both a native version and a bytecode version of the MLKit compiler
installed on the same system.

\subsubsection*{Unboxing of Function Arguments}
\index{arguments!multiple}%
\index{multiple function arguments}%
\index{function arguments!multiple}%
By default, the MLKit performs a simple local unboxing analysis to
figure out if a function taking a tuple as argument can be transformed
into a function taking multiple arguments. Only functions that use
only the individual elements of the argument tuple undergo
transformation. The optimisation can be disabled by passing the option
\texttt{-no\_unbox\_function\_arguments} to the MLKit compiler.

\subsubsection*{Removal of Region Vectors}
\index{region vector!removed}%
In the MLKit version 3.0 and earlier, actual region parameters were
passed to a region polymorphic function in a {\em region vector},
which itself was allocated in a region. In version 4.0, actual region
parameters to
\index{function!region polymorphic}%
region polymorphic functions are passed in registers and on the stack.
This simplification improves pretty printing of region annotated terms
and on what function calls turn into tail calls (see
Section~\ref{simplejump.sec}).

\section{Changes Since Version 2}
\index{changes!since version 2}%
This section provides an overview of the main changes to the MLKit
since version 2.0 but before version 3.0 of the MLKit.

\subsubsection*{Modules and Separate Compilation}
The most important development since Version 2 is the ability to
compile Modules and the discipline of separate compilation. A
distinguished feature of the way modules are compiled is that module
constructs do not give rise to any code, so there is no runtime
overhead in using modules \cite{ElsmanICFP99,ElsmanThesis}. See
Chapter~\ref{mlb_and_modules.chap}.

\subsubsection*{Standard ML Basis Library}
The MLKit support a large portion of the \index{Standard ML
  Basis Library} Standard ML Basis Library, based on the Moscow ML
version of the library. To see exactly what parts of the Standard ML
Basis Library are supported, consult the MLB-file {\tt
  basis.mlb} located in the directory {\tt basis}.

\subsubsection*{Scalability}
The MLKit now compiles fairly large programs, including Hafnium's AnnoDomini
(58.000 lines of SML) and the MLKit itself (around 80.000 lines).

\subsubsection*{New Match Compiler}
The pattern compiler has been rewritten, based on Sestoft's
method~\cite{sestoft96}, which is also the basis of the Moscow ML
match compiler.

\subsubsection*{New StatObject Module}
The MLKit contains a module,
\index{StatObject}%
{\tt StatObject}, which implements the semantic objects of the static
semantics of the Core.  Originally, this was a very clean and very
inefficient implementation of the Defininion. In version 2 of the MLKit,
{\tt StatObject} was replaced by an imperative and efficient, but
complicated module.  In version 3, {\tt StatObject} uses a clean,
efficient and imperative implementation of {\tt StatObject}. This is
particularly useful for those who want to reuse the front-end of the
MLKit for other purposes.

\subsubsection*{Unboxed Representation of Lists}
\index{list} List constructors are now represented unboxed, that is,
the least significant bits of a list value is used to distinguish
between \boxml{nil} and a pointer to a pair (\boxml{::}) holding the
head and the tail of the list. Thus, a list takes up only one region
(for the auxiliary pairs) plus any regions for the elements of the
list. Consult Chapter~\ref{lists.sec} for details.

\nocite{total97,total94,btv96,elshal95,KochHojfeld96,H96,hallenberg99,brtt93,hosc-regions2004}

\bibliographystyle{alpha}
\bibliography{mlkit}

\appendix

%---------------------------------------------------------
\chapter{Command-Line Options}
\label{mlkithelp.app}
%---------------------------------------------------------
This appendix shows the output of executing
\index{help@\texttt{-help} option to \texttt{mlkit}}%
\boxml{mlkit -help}, where \boxml{mlkit} is the version of the MLKit
compiler that uses the
\index{backend!x64}%
x64 native backend.

\begin{verbatim}
MLKit v4.7.2 ( - ) [X64 Backend]

Usage: mlkit [OPTION]... [file.sml | file.sig | file.mlb]

Options:

--version, -v, -V
     Print version information and exit.

--help
     Print extended help information and exit.

--help S
     Print help information about an option and exit.

--man
     Print man-page and exit.

--SML_LIB S              (You_did_not_set_path_to_install_dir)
     Installation directory for the MLKit standard library.
     For normal execution you should not modify this value.
     However, if you wish to use the MLKit with an altered
     runtime system you can update this setting and the
     system will try to link to a runtime system found in
     the specified install directory.

--aggresive_opt, -aopt                                    (on)
     Enable aggressive optimisations, including constant
     folding and aggressive inlining. These
     optimisations are not guaranteed to be region
     safe. Turning off garbage collection automatically
     turns off this option.

--assembler S, -as S                                   (as -q)
     This option specifies the assembler used.
     On Linux the default is 'as --64'. On macOS,
     the default is 'as -q'.

--c_compiler S, -cc S (gcc -Wl,-no_pie,-stack_size,0x10000000,-stack_addr,0xc0000000)
     This option specifies which C compiler is
     used for linking. When linking with c++
     libraries, 'g++' is the linker you want.
     On Linux the default is 'gcc -no-pie',
     whereas on macOS, the default is
     'gcc -Wl,-no_pie,-stack_size,0x10000000,-stack_addr,0xc0000000'.

--chat, -verbose                                         (off)
     Print a message for each compilation step in the compiler.

--comments_in_asmcode                                    (off)
     Insert comments in assembler code.

--compile_only, -c                                       (off)
     Compile only. Suppresses generation of executable

--compiler_timings, -timings                             (off)
     Show compiler timings for each compilation phase.

--contract                                                (on)
     Contract is responsible for inlining, specialization,
     elimination of dead code, and much else (Lambda
     Expression Optimiser).

--contract_regions, -cr                                  (off)
     When this option is enabled, identically typed
     regions bound by the same letregion construct
     are unified. Moreover, region parameters to
     non-exported functions are trimmed whenever
     possible.

--cross_module_opt, -cross_opt                            (on)
     Enable cross-module optimisation including inlining
     of small functions and specialisation of small
     recursive functions. Which optimisations are performed
     across modules is controlled by individual optimisation
     flags.

--dangling_pointers, -dangle                             (off)
     When this option is disabled, dangling pointers
     are avoided by forcing values captured in
     closures to live at-least as long as the closure
     itself. So as to make garbage collection sound,
     this option is disabled by default when garbage
     collection is enabled.

--dangling_pointers_statistics                           (off)
     When enabled, the compiler prints statistics about
     the number of times strengthening of the region typing
     rules (to avoid dangling pointers during evaluation)
     effects the target program. This flag is useful only
     when the flag -gc or -no_dangle is enabled.

--debug_compiler, -debug                                 (off)
     Print intermediate forms of a program during compilation.

--debug_linking                                          (off)
     Debug linking of target code by showing which object
     files are linked together.

--debug_man_enrich                                       (off)
     Show information about why a program unit need be
     recompiled. A program unit (or a functor body)
     is recompiled if either (a) the program unit is
     modified, or (b) information about an identifier
     for which the program unit depends upon has changed.

--debug_which_at                                         (off)
     Debug storage mode analysis.

--delete_target_files                                     (on)
     Delete assembler files produced by the compiler. If you
     disable this flag, you can inspect the assembler code
     produced by the compiler.

--disable_atbot_analysis                                 (off)
     Disable storage mode analysis. That is, turn all
     allocation directives into attop.

--disable_flow_var                                       (off)
     Disable optimised compilation of control-flow
     code, such as conditional expressions.

--eliminate_explicit_records                              (on)
     Eliminate bindings of explicit records only used for
     selections. Transform
           let r = (e1,...,en) in ... #i r .. #j r ...
     into
           let x1=e1 in ... let xn=en in ... xi .. xj ...
     (Lambda Expression Optimiser).

--explicit_regions, -er                                  (off)
     Support programming with explicit regions.

--export_basis_js, -ebjs                                 (off)
     When this flag is enabled, SmlToJs writes
     pickled bases to file.eb.js files to be read by
     js-client.

--garbage_collection, -gc                                 (on)
     Enable garbage collection. When enabled, regions are
     garbage collected during execution of the program. When
     garbage collection is enabled, all values are tagged. Due
     to region inference, for most programs, the garbage
     collector is invoked less often than for systems based
     only on garbage collection. When garbage collection is
     enabled, introduction of dangling pointers are avoided by
     forcing values captured in closures to live at-least as
     long as the closure. Moreover, enabling garbage
     collection implicitly enables the preservation of tail
     calls (see the option ``preserve_tail_calls''.)

--gdb_support, -g                                        (off)
     When enabled, the compiler passes the option --g
     to `as' (The GNU Assembler) and preserves the generated
     assembler files (.s files). Passing the --g
     option to `as' makes it possible to step through
     the generated program using gdb (The GNU Debugger).

--generational_garbage_collection, -gengc                (off)
     Enable generational garbage collection. Same as option
     garbage collection except that two generations are used
     for each region.

--import_basislib, -basislib                              (on)
     Import Basis Library automatically in your projects. If
     you wish to make use of the Standard ML Basis Library
     in your projects, this option should be turned on, unless
     you wish to import the Basis Library manually in your
     projects.

--inline_names S
     Names of functions that should always be inlined
     if possible, no matter the setting of the flag
     --maximum_inline_size.

--libdirs S
     This option controls where ld looks for
     archives. The format is a comma-separated list
     of directories; see the -libs entry. The default
     is the empty list; thus 'ld' will look for
     libraries in only the system specific default
     directores. The directories are passed to 'ld'
     using the -L option.

--libs S                                              (m,c,dl)
     For accessing a foreign function residing in
     an archive named libNAME.a from Standard ML code
     (using prim), you need to add 'NAME' to this
     comma-separated list. Notice that an object file
     (with extension '.o') is an archive if it is
     renamed to have extension '.a'. You may need to
     use the -libdirs option for specifying
     directories for which ld should look for library
     archives. The libraries are passed to 'ld' using
     the -l option.

--link_code S, -link S
     Link-files to be linked together to form an
     executable.

--link_time_dead_code_elimination, -ltdce                 (on)
     Link time dead code elimination.

--load_basis_files S, -load S
     Basis files to be loaded before compilation
     proper.

--log_to_file                                            (off)
     Log to files instead of stdout.

--maximum_inline_size N                                   (70)
     Functions smaller than this size (counted in abstract
     syntax tree nodes) are inlined, even if they are used
     more than once. Functions that are used only once are
     always inlined.

--maximum_specialise_size N                              (200)
     Curried functions smaller than this size (counted in
     abstract syntax tree nodes) are specialised if all
     applications of the function within its own body are
     applied to its formal argument, even if they are used
     more than once. Functions that are used only once are
     specialised no matter their size. See also the option
     --specialize_recursive_functions.

--minimize_fixs                                           (on)
     Minimize fix constructs (Lambda Expression Optimiser).

--mlb-subdir S
     For ensuring that the smart recompilation scheme
     is not reusing target-code compiled with different
     settings, a string provided with the mlb-subdir
     option can ensure the use of consistently generated
     code. This option is Useful, in particular, when
     performing benchmarking.

--mlb_path_maps S, -mlb-path-map S
     ML Basis path map files to be used.

--namebase S                                       (dummyBase)
     Name base to enforce unique names when compiling
     mlb-files.

--no_aggresive_opt, -no_aopt
     Opposite of --aggresive_opt, -aopt.

--no_contract
     Opposite of --contract.

--no_cross_module_opt, -no_cross_opt
     Opposite of --cross_module_opt, -cross_opt.

--no_dangling_pointers, -no_dangle
     Opposite of --dangling_pointers, -dangle.

--no_delete_target_files
     Opposite of --delete_target_files.

--no_eliminate_explicit_records
     Opposite of --eliminate_explicit_records.

--no_garbage_collection, -no_gc
     Opposite of --garbage_collection, -gc.

--no_generational_garbage_collection, -no_gengc
     Opposite of --generational_garbage_collection, -gengc.

--no_import_basislib, -no_basislib
     Opposite of --import_basislib, -basislib.

--no_link_time_dead_code_elimination, -no_ltdce
     Opposite of --link_time_dead_code_elimination, -ltdce.

--no_minimize_fixs
     Opposite of --minimize_fixs.

--no_optimiser, -no_opt
     Opposite of --optimiser, -opt.

--no_preserve_tail_calls, -no_ptc
     Opposite of --preserve_tail_calls, -ptc.

--no_print_regions, -no_Pregions
     Opposite of --print_regions, -Pregions.

--no_raggedRight
     Opposite of --raggedRight.

--no_region_inference, -no_ri
     Opposite of --region_inference, -ri.

--no_register_allocation
     Opposite of --register_allocation.

--no_repository, -no_rep
     Opposite of --repository, -rep.

--no_specialize_recursive_functions
     Opposite of --specialize_recursive_functions.

--no_type_check_lambda
     Opposite of --type_check_lambda.

--no_unbox_function_arguments
     Opposite of --unbox_function_arguments.

--no_unbox_reals
     Opposite of --unbox_reals.

--no_uncurrying, -no_uncurry
     Opposite of --uncurrying, -uncurry.

--optimiser, -opt                                         (on)
     Enable optimisation of intermediate language code
     (Lambda Expressions). Which optimisations are performed
     is controlled by individual flags. The optimisations
     include function inlining, function specialisation,
     fix-minimization, unboxing of function arguments, and
     elimination of unnecessary record constructions.

--output S, -o S                                         (run)
     The name of the executable file generated by
     the Kit.

--parallel_compilation N, -j N                             (1)
     The maximum number of parallel processes used
     for compilation.

--parallelism, -par                                      (off)
     When enabled, the runtime system supports
     parallel threads.

--parallelism_alloc_unprotected, -par0                   (off)
     When enabled, allocation into a region is not
     guaranteed to be atomic.

--preserve_tail_calls, -ptc                               (on)
     Avoid the wrapping of letregion constructs around
     tail calls. Turning on garbage collection
     automatically turns on this option.

--print_K_normal_forms                                   (off)
     Print Region Expressions in K-Normal Form. Applicable,
     only after storage mode analysis has been applied.

--print_all_program_points, -Ppp                         (off)
     Print all program points when printing physical size
     inference expressions.

--print_bit_vectors                                      (off)

--print_calc_offset_program                              (off)

--print_call_explicit_expression, -Pcee                  (off)
     Print Region Expression with call annotations.

--print_clos_conv_program, -Pccp                         (off)
     Print Region Expression after closure conversion.

--print_closed_export_bases, -Pceb                       (off)
     Controls printing of closed export bases.

--print_drop_regions_expression, -Pdre                   (off)
     Print Region Expression after dropping word regions and
     regions arguments with only get-effects.

--print_drop_regions_expression_with_storage_modes, -Pdresm (off)
     Print Region Expression after dropping word regions and
     regions arguments with only get-effects. Also print
     atbot and attop annotations resulting from storage mode
     analysis.

--print_effects, -Peffects                               (off)
     Print effects in region types.

--print_excon_name                                       (off)
     Print underlying unique name when printing excons.

--print_export_bases, -Peb                               (off)
     Controls printing of export bases.

--print_fetch_and_flush_program                          (off)
     Print program with instructions for activation
     record fetching and flushing.

--print_linearised_program                               (off)
     Print a linearlised representation of the
     program unit.

--print_lvar_name                                        (off)
     Print underlying unique name when printing lvars.

--print_normalized_program                               (off)
     Print Region Expression after K-normalisation.

--print_opt_lambda_expression, -Pole                     (off)
     Print Lambda Expression after optimisation.

--print_physical_size_inference_expression, -Ppse        (off)
     Print Region Expression after physical size inference.

--print_post_elab_ast, -Ppeast                           (off)
     Print ast after elaboration.

--print_region_flow_graph, -Prfg                         (off)
     Print a region flow graph for the program fragment
     and generate a .vcg-file, which can be viewed using
     the xvcg program.

--print_region_spreaded_program, -Prsp                   (off)
     Print region-spreaded program.

--print_region_static_env0, -Prse0                       (off)
     Print imported region static environment prior to
     region inference.

--print_regions, -Pregions                                (on)
     Print region variables in types and expressions.

--print_register_allocated_program                       (off)

--print_rho_levels                                       (off)
     Print levels of region and effect variables in types and
     intermediate forms. Levels control quantification of
     region and effect variables.

--print_rho_types                                        (off)
     Print region types of region variables in types and
     intermediate forms. Possible region types are:
         p  Type of regions containing pairs.
         a  Type of regions containing arrays.
         r  Type of regions containing references.
         t  Type of regions containing triples.
         s  Type of regions containing strings.
         T  Type of regions containing other than the above
            kinds of values.

--print_simplified_program                               (off)
     Print simplified program after register
     allocation.

--print_storage_mode_expression, -Psme                   (off)
     Print Region Expression after storage mode analysis

--print_type_name_stamps, -Ptypestamps                   (off)
     Print type name stamps and their attributes in types
     and expressions.

--print_types, -Ptypes                                   (off)
     Print types when printing intermediate forms. For Lambda
     Expressions, ordinary ML types are printed, whereas for
     Region Expressions, region types are printed.

--quotation, -quot                                       (off)
     Enable support for quotations and anti-quotations.
     When enabled, the datatype
        datatype 'a frag = QUOTE of string
                         | ANTIQUOTE 'a
     is available in the initial environment. Moreover,
     values of this datatype may be constructed using
     the quotation/antiquotation syntax:
        val s = "world"
        val a : string frag list = `hello ^s - goodbye`

--raggedRight                                             (on)
     Use ragged right margin in pretty-printing of
     expressions and types.

--recompile_basislib, -scratch                           (off)
     Recompile basis library from scratch. This option
     is useful together with other options that control
     code generation.

--region_inference, -ri                                   (on)
     With this flag disabled, all values are allocated in
     global regions.

--region_profiling, -prof                                (off)
     Enable region profiling. Object code stemming
     from compiling a program with region profiling enabled
     is instrumented with profiling information. When a program
     compiled with region profiling enabled is run, the program
     produces a profile file run.rp, which can then be read
     by the profiling tool rp2ps that comes with the MLKit to
     produce profiling graphs of various forms.

--regionvar N                                             (~1)
     Uses the provided number as the id of the first
     generated region variable. When this option is
     provided together with the -c option, a file f.rv
     is written in the MLB/ directory with two numbers
     in it: the id for the first region variable
     generated and the id for the last region variable
     generated. The number given must be greater than
     any id for a top-level region/effect variable (>9).

--register_allocation                                     (on)
     Perform register allocation. Without register allocation
     enabled, programs run somewhat slower--but they run and
     you save about 15 percent on compile time.

--report_file_sig, -sig                                  (off)
     Report signatures for each file read.

--repository, -rep                                        (on)
     Use in-memory repository to avoid unnecessary
     recompilation. This flag should be disabled when
     compiling mlb-files, which make use of the file system
     as a repository.

--safeLinkTimeElimination                                (off)
     Treat this module as a library in the sense that
     the code can be eliminated if it is not used,
     even if the code has side effects.

--specialize_recursive_functions                          (on)
     Specialise recursive functions. Use the option
     maximum_specialise_size to control which functions
     are specialised. If this flag is on, functions that are
     applied only once are specialised, no matter the setting
     of maximum_specialise_size (Lambda Expression Optimiser).

--statistics_after_optimisation                          (off)
     Report optimisation statistics after optimisation of
     Lambda Expression.

--strip                                                  (off)
     If enabled, the Kit strips the generated executable.

--tag_pairs                                              (off)
     Use a tagged representation of pairs for garbage
     collection. Garbage collection works fine with a
     tag-free representation of pairs, so this option
     is here for measurement purposes.

--tag_values, -tag                                        (on)
     Enable tagging of values as used when garbage
     collection is enabled for implementing pointer
     traversal.

--type_check_lambda                                       (on)
     Type check lambda expression prior to performing region
     inference. Type checking is very fast and for normal use
     you should not disable this option. Type checking
     intermediate forms is very powerful for eliminating bugs
     in the compiler.

--unbox_function_arguments                                (on)
     Unbox arguments to fix-bound functions, for which the
     argument `a' is used only in contexts `#i a'. All call
     sites are transformed to match the new function (Lambda
     Expression Optimiser).

--unbox_reals                                             (on)
     Unbox real values and computations on real values inside
     functions. Real values stored in data structures and
     passed to functions are still boxed.

--uncurrying, -uncurry                                    (on)
     Enable uncurrying of curried functions. The uncurried
     function takes its arguments unboxed in registers or
     on the stack. For partial applications and non-
     application uses of the function, appropriate eta-
     expansions are applied.

--values_64bit                                            (on)
     Support 64-bit values. Should be enabled for
     backends supporting 64-bit integers and words.

--warn_on_escaping_puts                                  (off)
     Enable the compiler to issue a warning whenever a
     region type scheme contains a put effect on a region
     that is not quantified.

--warn_on_parallel_puts                                  (off)
     Enable the compiler to issue a warning whenever a
     par-construct is passed functions with intersecting
     put effects.

--width N, -w N                                          (100)
     Column width used when pretty printing intermediate code.
\end{verbatim}

\newpage
\index{live variable analysis|see{variable}}
\index{endomorphism|see{region endomorphism}}
\index{exomorphism|see{region exomorphism}}
\index{tuple|see{record}}
\index{$\mu$|see{type and place}}
\index{rDesc|see{region descriptor}}
\index{example programs|see{{\tt kitdemo} directory}}
\index{value declaration|see{declaration}}
\printindex

\newpage
\begin{center}
\bf Global Regions
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
\boxml{r1}&Holds values of type {\tt top}, that is, records, exceptions, and closures.\cr
\boxml{r2}&Holds values of type {\tt bot}. Because no values has type
{\tt bot}, this region contains no values. Region variables with region type {\tt bot} are used with
so-called explicit regions, which are not covered in this report.\cr
\boxml{r3}&Holds values of type {\tt string}.\cr
\boxml{r4}&Holds values of type $\tau_1 \times \tau_2$, for any types $\tau_1$ and $\tau_2$.\cr
\boxml{r5}&Holds values of type $\tau~\texttt{array}$ and $\tau~\texttt{vector}$, for any type $\tau$.\cr
\boxml{r6}&Holds values of type $\tau~\texttt{ref}$, for any type $\tau$.\cr
\boxml{r7}&Holds values of $\tau_1 \times \tau_2 \times \tau_3$, for any types $\tau_1$, $\tau_2$, and $\tau_3$.\cr
}
\hrule
\bigskip
\end{document}
