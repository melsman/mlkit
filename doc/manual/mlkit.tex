\documentclass[12pt]{book}
\usepackage{graphicx}
\usepackage[bookmarks=true]{hyperref}
\usepackage{makeidx}
\usepackage{theorem}
%\usepackage{times}                % times font
\usepackage{type1cm}               % traditional font - quite thin for screen reading
\renewcommand{\ttdefault}{cmtt}    % smaller tt-font
\newcommand{\docversion}{4.7.16}
\usepackage{alltt}
\makeindex
\input{genericmac}
\input{mac}
\input{sml}
\newcommand{\rhoword}{\rho_{\rm w}}
\title{Programming with Regions in the MLKit\\[5mm]
\large {\sc Revised for version \docversion}}
\author{Mads Tofte \and Lars Birkedal \and Martin Elsman \and
\and Niels Hallenberg \and Tommy H\o jfeld Olesen \and
Peter Sestoft}
\date{December 15, 2025 \\[3cm] \includegraphics[width=.7\textwidth]{mlkit-logo}}
\raggedbottom

{\theorembodyfont{\rmfamily} \newtheorem{example}{Example}}

\begin{document}
\maketitle

\pagestyle{headings}
\begin{center}
\bf Values and their Representation
\end{center}
\smallskip

\lstset{mathescape=true}

\hrule
\halign{\parbox[t]{25mm}{#}\hfil\ &\ \parbox[t]{12cm}{\strut#\strut}\cr
\lstinline{int}& 64 bits, untagged. Unboxed (i.e., not region allocated). One bit is used for tagging when GC is enabled. \cr
\lstinline{real}   &64 bits, untagged. Boxed (i.e., allocated in region) or unboxed.\cr
\lstinline{string} &Unbounded size. Allocated in region.\cr
\lstinline{bool}   &one 64-bit word. Unboxed.\cr
\lstinline!$\alpha$ list! & \lstinline{nil} and \lstinline{::} cells unboxed (i.e., not region allocated). Auxiliary
                pairs in one region; elements
                in zero or more regions. Size of
                auxiliary pairs: two 64-bit words (three when GC is enabled).\cr
%$\alpha$ tree & A tree and its subtrees reside in one region.
%                Elements in one region (if not unboxed).\cr
\lstinline{exn} & Exception values are boxed and are always stored in a global region.\cr
\lstinline!fn $\,\mathit{pat}$ => $\mathit{exp}$! & An anonymous function is represented by a
                boxed, untagged closure. Its size is one 64-bit word plus one word for each free
                variable of the function. Free region variables also count as variables.
                One extra word is used when GC is enabled.\cr
\lstinline!fun $\,f$ $\ldots$! & Mutually recursive region-polymorphic functions
               share the same closure, which is region-allocated, untagged,
               and whose size (in words) is the number of variables
               that occur free in the recursive declaration. One extra word is used when GC is enabled.\cr}
\hrule
\bigskip

\begin{center}
\bf Regions and their Representation
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
Finite (\lstinline!$\rho$:$n$!)& Region whose size can be determined at compile time. During
         compilation, a finite region size is given as a
         non-negative integer. After multiplicity
         inference, this integer indicates the number of times a value (of
         the appropriate type) is written into the region. Later, after
         physical size inference, the integer indicates the physical
         region size in words. At runtime, a finite region is allocated
         on the runtime stack.\cr
Infinite (\lstinline!$\rho$:INF!)& All other regions. At runtime, an infinite region
         consists of a stack allocated region descriptor, which contains pointers
         to the beginning and the end of a linked list of fixed size region
         pages.\cr }
\hrule
\medskip


\begin{center}
\bf Storage Modes (only significant for infinite regions)
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
\lstinline{atbot} & Reset region, then store value.\cr
\lstinline{sat}   & Determine actual storage mode (\lstinline{attop}/\lstinline{atbot})
              at runtime.\cr
\lstinline{attop} & Store at top of region, without destroying any values
              already in the region.\cr}
\hrule
\medskip

\tableofcontents
%---------------------------------------------------------
\chapter*{Preface}
%---------------------------------------------------------
The MLKit is a compiler infrastructure for
%
\index{Standard ML}%
%
the Standard ML programming language \cite{mthm97}. The MLKit supports all of
Standard ML, including Modules and most parts of the SML Basis Library
\cite{basislib2004}.  The MLKit features a region-based native backend that
generates efficient x64 machine code. This version of the compiler is also named
MLKit with Regions. The MLKit also features a
%
\index{JavaScript backend}%
%
JavaScript backend, which generates code for execution in web browsers. The
MLKit with Regions, which this report is about, is intended for the development
of stand-alone applications that must be reliable, fast, and space efficient.

There has always been a tension between high-level features in programming
languages and the programmer's legitimate need to understand programs at the
operational level. Very likely, if a resource conscious programmer is forced to
make a choice between the two, he will choose the latter.

The MLKit with Regions is the result of a research and development effort, which
was initiated at the University of Copenhagen in 1992.  The goal of the project
has been to develop implementation technology that combines the advantages of
using a high-level programming language, in this case Standard ML, with a model
of computation that allows programmers to reason about how much space and time
their programs use.

In most call-by-value languages, it is not terribly hard to give a model of time
usage that is good enough for elementary reasoning.

For space, however, the situation is much less satisfactory. Part of the reason
is that many programs must recycle memory while running.  For all such programs,
the mechanisms that reclaim memory inevitably become part of the reasoning.
This is true irrespective of whether memory recycling is done by a
%
\index{stack}%
%
stack mechanism or by pointer tracing garbage collection.

In the stack discipline, every point of allocation is matched by a point of
deallocation and these points are obvious from the program. By contrast, garbage
collection techniques usually separate allocation, which is done by the
programmer, from deallocation, which is done by a garbage collector.  The
advantage of using reference tracing
%
\index{garbage collection}%
%
garbage collection techniques is that they apply to a wide range of high-level
concepts now found in programming languages, for example recursive data types,
higher-order functions, exceptions, references, and objects. The disadvantage is
that it is becoming increasingly difficult for the programmer to reason about
lifetimes. Lifetimes may depend on subtle details in the compiler and in the
garbage collector.  Thus, it is hard to model memory in a way that is useful to
programmers. Also, compilers offer little assistance for reasoning about
lifetimes.

In this report, we describe how Standard ML can be equipped with a different
memory management discipline, namely a {\em region-based} memory model.  Like
the stack discipline, the region discipline is, in essence, simple and
platform-independent. Unlike the traditional stack discipline, however, the
region discipline also applies to recursive data types, references, and
higher-order functions, for which one has hitherto mostly used reference tracing
garbage collection techniques.

The reader we have in mind is a person with a Computer Science background who is
interested in developing reliable and efficient applications written in Standard
ML. Also, the report may be of interest to researchers of programming languages,
since the MLKit with Regions is a fairly bold exercise in program analysis. We
should emphasise, however, that this report is very much intended as a user's
guide, not a scientific publication.

This report consists of three parts:
\begin{description}
\item[Part I, Overview:] This part gives an overview of the ideas that underlie
  programming with regions in the MLKit.
\item[Part II, Understanding Regions:] The second part of the report
  systematically presents the language constructs of the Standard ML Language,
  showing for each construct how it can be used when programming with regions.
\item[Part III, System Reference:] In this part, we explain how to interact with
  the system, how to use the region profiler and how to call C functions from
  the MLKit.
\end{description}

The present report describes the
%
\index{MLKit!Version \docversion}%
%
MLKit Version~{\docversion}. Besides from featuring bug-fixes, this version of
the MLKit extends, and differs from, the MLKit Version~4.7.2 by the following
features:
\begin{enumerate}
\item
  %
  \index{bit stealing}%
  \index{unboxing}%
  %
  Double-ended bit-stealing. The implementation of algebraic data types now
  uses an advanced unboxing scheme that allows many data types to be implemented
  unboxed using the, otherwise non-used, 16 most-significant bits of a pointer
  or the high unused bits of 8-bit word values) \cite{10.1145/3674628}.

\item
  %
  \index{deep argument flattening}%
  %
  Deep-argument flattening. The MLKit optimiser attempts to flatten
  arguments to functions using a scheme that allows for deep flattening and
  uncurrying of arguments to functions (also across compilation unit boundaries)
  \cite{deep-elsman25}. With this scheme, if a function takes a tuple of reals
  and a curried argument of type real as arguments, those arguments that are not
  used in their boxed form will be passed unboxed.

\item Improved abbreviated pretty printing of some intermediate representations.

\item
  %
  \index{parallelism}%
  %
  Support for threads and parallelism through a fork-join thread interface
  \cite{10.1145/3591256}. The support for threads and parallelism is not
  documented in this report.

\item
  %
  \index{ReML}%
  \index{explicit regions}%
  \index{explicit effects}%
  %
  Support for explicit programming with regions and effect constraints
  through an extended syntax (ReML) that allows for annotating expressions and
  types with region and effect information \cite{10.1145/3632921}. The support
  for programming with explicit regions and effects is not documented in this
  report.

\item
  %
  \index{auto conversion}%
  %
  Improved support for auto conversion when interacting with C functions.
\end{enumerate}

Version~4.7.2 of the MLKit extends, and differs from, MLKit Version~4.3.0 by the
following features:

\begin{enumerate}
\item Type variables are no longer associated with region variables, which
  simplifies region types significantly and eases the implementation.

\item The machinery for ensuring that no dangling pointers are dereferenced
  during a garbage collection has been fixed \cite{10.1145/3591229}.

\item A move to machine code generation for the x86\_64 architecture. The port
  also features register allocation for floating point registers, holding
  intra-procedural values of type \lstinline{real}.

\item Additional Standard ML Basis Library features, including support for
  socket programming (e.g., structure \lstinline{Socket}) and general Unix
  programming (structure \lstinline{Unix}).

\item Support for generational garbage collection as a generalisation of the
  ordinary pointer-tracing garbage collector that can be used as an add-on to
  region-based memory management
  \cite{10.1007/978-3-030-39197-3_7,ELSMAN_HALLENBERG_2021}.

\item A large number of bug-fixes, performance improvements, and general new
  features, such as colorful region profile graphs...
\end{enumerate}

Further, Version~4.3.0 extends Version~4 with the following features:
\begin{enumerate}
\item Support for compiling
%
\index{ML Basis Files}%
%
ML Basis Files. ML Basis Files allows for expressing source dependencies,
exactly (as a directed acyclic graph). ML Basis Files thus provides a mechanism
for programming ``in the very large''.

\item File-based
%
\index{separate compilation}%
%
separate compilation, based on ML Basis Files.
\item An updated Standard ML Basis Library conforming to the specification
  published in \cite{basislib2004}.
\item Untagged representation of heap-allocated pairs, triples, and Standard ML
  references, even when garbage collection is enabled.
\end{enumerate}

MLKit Version~4 extends MLKit Version~3 with the following features:
\begin{enumerate}
\item Support for pointer tracing garbage collection. Pointer tracing garbage
  collection works well together with the region memory model.  While most
  de-allocations can be efficiently performed by region de-allocation, there are
  some uses of memory for which life time prediction is difficult. In these
  cases pointer tracing garbage collection does a good job in collaboration with
  region memory management \cite{hallenberg99,het02}.
\item An x86 native backend. The
  %
  \index{backend!native}%
  %
  backend support has switched from HP PA-RISC to Linux on x86 architectures.

\item A
  %
  \index{backend!bytecode}%
  \index{bytecode}%
  %
  bytecode backend. To improve portability of programs, MLKit Version 4 featured
  a bytecode backend, which generated code for execution on a stack machine with
  region primitives. The stack machine closely resembles the stack machine used
  in the OCaml and Moscow ML compilers.
\end{enumerate}

The
%
\index{MLKit!Version 3}%
%
MLKit Version~3 extends the MLKit Version~2 with support for the Standard ML
Modules language. The
%
\index{MLKit!Version 2}%
%
MLKit Version~2 is a further development of the
%
\index{MLKit!Version 1}%
%
MLKit Version~1, which was developed at Edinburgh University and University of
Copenhagen \cite{brtt93}.  We hope you will enjoy using the MLKit as much as we
have enjoyed developing it. If your experience with the MLKit gives rise to
comments and suggestions, specifically with relation to the goals and visions
expressed here, please feel free to write.  Further information is available at
the MLKit
%
\index{web site}%
%
Github web site:
\begin{tabbing}
\hskip2cm\url{https://github.com/melsman/mlkit}
\end{tabbing}

\begin{flushright}
September, 2001\\[5mm]
Mads Tofte, Lars Birkedal, Martin Elsman, Niels Hallenberg, \\
Tommy H\o jfeld Olesen, and Peter Sestoft \\[5mm]
Revised 2002, 2004, 2005, 2021 by Martin Elsman
\end{flushright}

\newpage

\section*{Contributions}
Many people have contributed to the development of the MLKit, including Peter
Bertelsen, Lars Birkedal, Martin Elsman, Niels Hallenberg, Tommy H\o jfeld
Olesen, Nick Rothwell, Mads Tofte, David N.\@ Turner, Peter Sestoft, and Carsten
Varming.

People who have contributed with bug reports and patches include, but are not
limited to (in alphabetical order) Johnny Andersen, Troels Henriksen, Koshy A
Joseph, Ken Friis Larsen, Philip Munksgaard, Henning Niss, Daniel Wang, and
Stephen Weeks.

\section*{License}
The MLKit compiler and tools are released under the GNU General Public License:

{\sc
\begin{quote}
  This program is free software; you can redistribute it and/or
  modify it under the terms of the GNU General Public License as
  published by the Free Software Foundation; either version 2 of the
  License, or (at your option) any later version.

  This program is distributed in the hope that it will be useful, but
  WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program; if not, write to the Free Software
  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
\end{quote}
}

Parts of the MLKit (the runtime system and the Basis Library) is distributed
under the MIT license: {\sc
\begin{quote}
The MIT License

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
\end{quote}
}

For details, see the file \inline{doc/license/MLKit-LICENSE} in the source
distribution.

%==============================

\part{Overview}

%---------------------------------------------------------
\chapter{Region-Based Memory Management}
\label{intro.sec}
%---------------------------------------------------------
Region-Based Memory Management is a technique for managing memory for programs
that use dynamic data structures, such as lists, trees, pointers, and function
closures.

\section{Dynamic Memory Management}
Many programming languages rely on a memory model consisting of a {\em stack}
%
\index{stack}%
%
and a
%
\index{heap}
%
{\em heap}. Typically, the stack holds temporary values, activation records,
arrays, and in general, values whose lifetime is closely connected to procedure
activations and whose size can be determined at the latest when creation of the
value begins.  The heap is what holds all the other values. In particular, the
heap holds values whose size can grow dynamically, such as lists and trees. The
heap also holds values whose lifetime does not follow procedure activations
closely (for example lists and, in functional languages, function closures and
suspensions).

The beauty of the stack discipline (apart from the fact that it is often very
efficient in practice) is that it couples allocation points and de-allocation
points in a manner that is intelligible to the programmer. C programmers
appreciate that whatever memory is allocated for local variables in a procedure
ceases to exist (and take up memory) when the procedure returns.
%
\index{C}
%
C programmers also know that counting from one to some large number, $N$, is not
best done by making $N$ recursive C procedure calls, because that would use
stack space proportional to $N$.

By contrast, programmers have much less help when it comes to managing the heap.
Two approaches prevail. The first approach is that the programmer manages memory
herself, using explicit allocation and de-allocation instructions (e.g.,
%
\index{malloc@\texttt{malloc}}
%
\lstinline{malloc} and
%
\index{free@\texttt{free}}
%
\lstinline{free} in C). For non-trivial programs this can be a very significant
burden, because it is, in general, very hard to make sure that none of the
values that reside in the memory that one wishes to de-allocate are not needed
for the rest of the computation.  This puts the programmer in a difficult
position. If one is too eager to reclaim memory in the heap, the program might
crash under some peculiar circumstances, which might be hard to find during
debugging.  If one is too conservative reclaiming memory, the program might leak
space, that is, it might use more memory than expected, perhaps eventually,
exhaust the memory of the machine.

The other prevailing approach is to use automatic garbage collection in the
heap.  Some implementors of some languages even dispense with the stack
entirely, relying only on a heap with garbage collection.  Garbage collection
techniques separate allocation, which is done by the programmer, from
de-allocation, which is done by the garbage collector.  At first, this might
seem like the perfect solution: no longer does the programmer have to worry
about whether memory that is being reclaimed really is dead, for the garbage
collector only reclaims memory that cannot be reached by the rest of the
computation. However, reality is less perfect. Garbage collectors are typically
based on the idea that if data is reachable via pointers (starting from the
stack and other root data) then those data must be kept. Consequently, programs
have to be written with care to avoid hanging on to too many pointers. Space
conscious programmers (and language implementors) can work their way around
these problems, for example by assigning \lstinline{nil} to pointers that are no
longer used.  However, such tricks often rely on assumptions about the code that
cannot be checked by the compiler and that are likely to be invalidated as the
program evolves.

\section{Checked De-Allocation of Memory}
\label{checked.sec}
Regions offer an alternative to the two approaches to memory management
discussed in the previous section.  The runtime model is very simple, at least
in principle.  The store consists of a
%
\index{region stack}
%
stack of
%
\index{region}
%
{\em regions}, see Figure~\ref{stacks.fig}.
\begin{figure}[t]
\hrule
\begin{center}
\begin{picture}(70,50)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){\lstinline!r$_0$!}}
\put(15,5){\framebox(10,5){}}
\put(20,0){\makebox(0,0){\lstinline!r$_1$!}}
\put(30,5){\framebox(10,35){}}
\put(35,0){\makebox(0,0){\lstinline!r$_2$!}}
\put(45,5){\framebox(10,10){}}
\put(50,0){\makebox(0,0){\lstinline!r$_3$!}}
\put(60,5){\makebox(0,0){$\ldots$}}
\end{picture}
\end{center}
\caption{The store is a stack of regions; every region is depicted by a box in
  the picture.}  \vskip5mm \hrule
\label{stacks.fig}
\end{figure}
Regions hold values, for example tuples, records, function closures, references,
and values of recursive types (such as lists and trees).  All values, except
those that fit within one machine word (for example integers), are stored in
regions.

The size of a region
%
\index{region size}
%
is not necessarily known when the region is allocated.  Thus a region can grow
gradually (and many regions can grow at the same time) so one might think of the
region stack as a stack of heaps. However, the region stack really is a stack in
the sense that (a) if region $r_1$ is allocated before region $r_2$ then $r_2$
is de-allocated before $r_1$ and (b) when a region is de-allocated, all the
memory occupied by that region is reclaimed in one constant time operation.

Values that reside in one region are often, but not always, of the same type. A
region can contain pointers to values that reside in the same region or in other
regions. Both forward pointers (i.e., pointers from a region into a region
closer to the stack top) and backwards pointers (i.e., pointers to an older
region) occur.

As mentioned in the preface, the present version of the MLKit supports
reference-tracing
%
\index{garbage collection}
%
garbage collection in combination with region memory management
\cite{hallenberg99}. While most de-allocations can be efficiently performed by
region de-allocation, there are some uses of memory for which it is difficult to
predict when memory can be de-allocated.  In these cases reference-tracing
garbage collection does a good job in combination with region de-allocation.

In many cases however, one can do just fine without reference-tracing garbage
collection. Without reference-tracing garbage collection the region stack is the
only form of memory management provided. Is the region model really general
enough to fit a wide variety of computations?

First notice that the pure
%
\index{stack}
%
stack discipline (a stack, but no heap) is a special case of the region
stack. Here the size of a region is known at the latest when the region is
allocated. Another special case is when one has just one region in the region
stack and that region grows dynamically.  This case can be thought of as a
%
\index{heap}
%
heap with no garbage collection, which again would not be sufficient.

But when one has many regions, one obtains the possibility of distinguishing
between values according to what region they reside in.  The MLKit has
operations for allocating, de-allocating, and extending regions. But it also has
an explicit operation for
%
\index{region!resetting}
%
resetting an existing region, that is, reclaiming all the memory occupied by the
region without eliminating the region from the region stack.  This primitive,
simple as it is, enables one to cope with most of those situations where
lifetimes simply are not nested.  Figure~\ref{slideshow.fig} shows a possible
progression of the region stack.

\begin{figure}
\hrule \medskip
\begin{center}
\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,5){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,35){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,10){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\put(60,5){\framebox(10,20){}}
\put(65,0){\makebox(0,0){$\boxml{r}_4$}}
\end{picture}
\medskip

(a)
\medskip

\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,15){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,35){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,0){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\put(60,5){\framebox(10,30){}}
\put(65,0){\makebox(0,0){$\boxml{r}_4$}}
\put(75,5){\framebox(10,20){}}
\put(80,0){\makebox(0,0){$\boxml{r}_5$}}
\end{picture}
\medskip

(b)
\medskip

\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,35){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,35){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,5){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\end{picture}
\medskip

(c)
\medskip
\end{center}
\caption{Further development of the region stack: (a) after allocation of
  $\boxml{r}_4$; (b) after growth of $\boxml{r}_1$ and $\boxml{r}_4$, resetting
  of $\boxml{r}_3$ and allocation of $\boxml{r}_5$; (c) after popping of
  $\boxml{r}_4$ and $\boxml{r}_5$ but extension of $\boxml{r}_1$ and
  $\boxml{r}_3$.}  \vskip5mm \hrule
\label{slideshow.fig}
\end{figure}

In the MLKit the vast majority of region management is done automatically by the
compiler and the runtime system.  Indeed, with one exception, source programs
are written in Standard ML, with no added syntax or special directives. The
exception has to do with resetting of regions. The MLKit provides two built-in
functions
%
\index{resetRegions@$\resetr$}%
\index{forceResetting@$\resetf$}
%
($\resetr$ and $\resetf$), which instruct the program to reset regions. Here
$\resetr$ is a safe form of resetting where the compiler only inserts region
resetting instructions if it can prove that they are safe; it prints thorough
explanations of why it thinks resetting might be unsafe otherwise. The function
$\resetf$ is for potentially unsafe resetting of regions, which is useful in
cases where the programmer jolly well knows that resetting is safe even if the
compiler cannot prove it. The function $\resetf$ is the only way we allow users
to make decisions that can make the program crash; many programs do not need
$\resetf$ and hence cannot crash (unless we have bugs in our system).

All other region directives, including directives for allocation and
de-allocation of regions, are inferred automatically by the compiler.  This
happens through a series of fairly complex program analyses and transformations
(in the excess of twenty-five passes involving three typed intermediate
languages). These analyses are formally defined and the central one, called
%
\index{region inference}
%
{\em region inference}, has been proved correct for a skeletal
language. Although the formal rules that govern region inference and the other
program analyses are complex, we have on purpose restricted attention to program
analyses that we feel capture natural programming intuitions.  Moreover, the
MLKit implementation is such that, with one exception\footnote{The exception has
to do with exceptions. When an exception is raised, a search down the stack for
a handler takes place; this search is not constant time and it involves popping
of regions on the way. However, the number of region operations is bounded by
the number of handlers that appear on the stack.}, every region directive takes
constant time and constant space to execute.  The fact that we avoid
interrupting program execution for unbounded lengths of time gives a nice smooth
experience when programs are run and should make the scheme attractive for
real-time programming.

To help programmers get used to the idea of programming with regions, the MLKit
can print region-annotated programs, that is, source programs it has annotated
with region directives. Also, it provides a
%
\index{region profiling}
%
\emph{region profiler} for examining run-time behavior.  The region profiler
gives a graphical representation of region sizes as a function of time. This
tool makes it possible to see what regions use the most space and even to relate
memory consumption back to individual allocation points in the (annotated)
source program.

To sum up, the key advantages obtained by using regions compared to more
traditional memory management schemes are
\begin{enumerate}
\item safety of de-allocation is checked by the compiler
\item the compiler can in many cases spot potential space leaks
\item region management is under the control of the user, provided one
  understands the principles of region inference
\item each of the region operations that are inserted use constant time and
  constant space at runtime
\item it is possible to relate runtime space consumption to allocation points in
  the source program; we have found region profiling to be a powerful tool for
  eliminating space leaks
\end{enumerate}
Regions are not a magic wand to solve all memory management problems.  Rather,
the region scheme encourages a particular discipline of programming. The purpose
of this report is to lay out this discipline.

\section{Example: the Game of Life}
\label{life.sec}

\index{Life!game of}
%
To illustrate the general flavor of region-based memory management, let us
consider the problem of implementing the game of Life. The game takes place on a
board that resembles a chess board, except that the size of the board can grow
as the game evolves. Thus every position has eight neighboring positions
(perhaps after extension of the board).  At any point in time, every position is
either {\em alive} or {\em dead}. A snapshot of the game consisting of the board
together with an indication of which positions are alive is called a {\em
  generation}. The rules of the game specify how to progress from one generation
to the next. Consider generation $n$ from which we want to create generation
$n+1$ ($n\geq0$). Let $(i,j)$ be a position on the board, relative to some fixed
point $(0,0)$ in the plane. Assume $(i,j)$ is alive in generation $n$. Then
$(i,j)$ stays alive in generation $n+1$ if and only if it has two or three live
neighbors in generation $n$. Assume $(i,j)$ is dead at generation $n$. Then it
is born in generation $n+1$ if and only if it has precisely three live neighbors
at generation $n$. We assume that only finitely many positions are alive
initially. An example of two generations of Life is shown below:
\begin{scriptcode}[xleftmargin=.1\textwidth]
                    0
                   0 0
                  0   00        0
       00         0   00     0000   0
       00         0   00    0000    0
                   0 0      0  0        00
                    0       0000        00
                             0000


                    0
                   0000
                  00 0 0      0 0
       00        000 0  0   0   0
       00         00 0 0    0
                   0000    0    0       00
                    0       0           00
                            0   0
                              00
\end{scriptcode}

To represent the game board, we need a data structure that can grow dynamically
(so a two-dimensional array of fixed size is not sufficient).  A simple solution
is to represent a generation by a list of integer pairs, namely the positions
that are alive. Since we want to give all pairs belonging to one generation the
same lifetime (in the computer memory, that is!)  it is natural to store all the
integer pairs belonging to one generation in the same region. Indeed region
inference forces this decision upon us, as it happens, since it requires that
all elements belonging to the same list lie in the same region. (Different lists
can lie in different regions, however.)

Thus, after having built the initial generation, we expect the region stack to
look like this
\begin{center}
\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{$l_n$: list of integer pairs representing generation $n$.}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\end{picture}
\end{center}
The computation of the next generation involves a considerable amount of list
computation.  Chris Reade has expressed the key part of the computation as shown
in Figure~\ref{xavier.fig}.
\begin{figure}
\hrule \medskip
\begin{smlcode}
let val living = alive gen
    fun isalive x = member living x
    fun liveneighbours x = length (filter isalive (neighbours x))
    fun twoorthree n = n=2 orelse n=3
    val survivors = filter (twoorthree o liveneighbours) living
    val newnbrlist = collect (filter (not o isalive) o neighbours)
                             living
    val newborn = occurs3 newnbrlist
in mkgen (cp_list(survivors @ newborn))
end
\end{smlcode}
\caption{An excerpt of (a modified version of)
Chris Reade's Game of Life program.}
\medskip

\hrule
\label{xavier.fig}
\end{figure}
Despite the extensive use of higher-order functions here, there is a great deal
of stack structure in this computation. For example, the \lstinline{survivors}
list can be allocated in a local region which can be de-allocated after the list
has been appended (\lstinline{@}) to the \lstinline{newborn} list. The
computation of \lstinline{survivors}, in turn, involves the creation of a
closure for \lstinline{(twoorthree o liveneighbours)} and additional creation of
closures as part of the computation of the application of
\lstinline{filter}. Each time \lstinline{liveneighbours} is called (by
\lstinline{filter}) additional temporary values are created.  All of this data
should live shorter than \lstinline{survivors} itself.  The details of these
lifetimes are determined automatically by the region inference algorithm, which
ensures that when the above expression terminates it will simply have created a
list containing the live positions of the new generation.

But now we have a design choice. Should we put the new generation in
the same region as the previous region or should we arrange that it is
put in a separate region? Piling all generations on top of each other
in the same region would clearly be a waste of space: only the most
recent generation is ever needed. Similarly, giving each generation a
separate region on the region stack is no good either, because it
would make the stack grow infinitely (although this could be
alleviated somewhat by resetting all regions except the topmost one).
The solution is simple, however: use two regions, one for the current
generation and one for the new generation. When the new generation has
been created, reset the region of the old region and copy the contents
of the new region into the old region. This effect is achieved by
organizing the main loop of the program as follows:
\begin{smlcode}[numbers=left,xleftmargin=25pt]
  local
    fun nthgen (p as(0,g)) = p
      | nthgen (p as(i,g)) =
        nthgen (i-1, let val g' = nextgen g
                     in show g;
                        resetRegions g;
                        copy g'
                     end)
  in
    fun iter n = #2(nthgen(n,gun()))
  end
\end{smlcode}
Here \lstinline{nthgen}
%
\index{nthgen@\texttt{nthgen}}
%
is the main loop of the program. It takes a pair as argument; the first
component of the pair indicates the number of iterations desired, while the
second, \lstinline{g}, is the current generation. The use of the \lstinline{as}
pattern in line 2 forces the argument and the result of \lstinline{nthgen} to be in
the same regions. Such a function is called a
%
\index{region endomorphism}
%
{\em region endomorphism}. In line 4, we compute a fresh generation, which lies
in fresh regions, as it happens. Having printed the generation (line 5) we then
reset the regions containing \lstinline{g}. The compiler checks that this is
safe. Then, in line 7 we copy \lstinline{g'} and the target of this copy must be
the regions of \lstinline{g}, because \lstinline{nthgen} is a region
endomorphism (see Figure~\ref{doublecopy.fig}).  All in all, we have achieved
that at most two generations are live at the same time (a fact that can be
checked by inspecting the region-annotated code, if one feels passionately about
it).\footnote{The source file for the life program is
\boxml{kitdemo/life.sml}. Running programs is described in
Section~\ref{tryit.sec}. When run with n=10000 under Linux on an x64 box, the
memory consumption (resident memory, measured using \lstinline{top}) quickly
reaches 500Kb and stays there for the remaining generations.}

\begin{figure}
\hrule
\begin{center}
\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{$l_n$: list of integer pairs representing generation $n$.}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\end{picture}
\medskip

(a)
\medskip

\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{$l_n$}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\put(50,5){\framebox(45,25){\parbox{4cm}{$l_{n+1}$: list of integer pairs representing generation $n+1$.}}}
\put(70,0){\makebox(0,0){$\boxml{r1}$}}
\end{picture}
\medskip

(b)
\medskip

\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{copy of $l_{n+1}$}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\end{picture}
\medskip

(c)
\medskip

\end{center}
\caption{ Using double-copying in the game of Life: (a) generation number $n$
  resides in region \lstinline{r0}; (b) generation $(n+1)$ has been built in
  \lstinline{r1}; (c) region \lstinline{r0} has been reset, the new generation copied
  into \lstinline{r0} and \lstinline{r1} has been de-allocated.}  \vskip5mm \hrule
\label{doublecopy.fig}
\end{figure}

The above device, which we refer to as
%
\index{double copying}
%
{\em double copying}, can be seen as a much expanded version of what is often
called ``tail recursion optimisation''.  In the case of regions, not just the
stack space, but also region space, is re-used.  Indeed, double copying is
similar to invoking a copying garbage collector on specific regions that are
known not to have live pointers into them.  But by doing the copying ourselves,
we have full control over when it happens, we know that the cost of copying will
be proportional to the size of the generation under consideration and that all
other memory management is done automatically by the region mechanism. Because
each of the region management directives that the compiler inserts in the code
are constant time and space operations, we have now avoided unpredictable
interruptions due to memory management. This avoidance of unpredictable
interruptions might not be terribly important for the purpose of the game of
Life, but if we were writing control software for the ABS brakes of a car,
having control over all costs, including memory management, would be crucial!

% left lower right upper
\newcommand{\includerp}[1]{\includegraphics[trim=12mm 25mm 37mm 37mm, clip, width=\textwidth]{#1}}
%\newcommand{\includerp}[1]{\includegraphics[trim=16mm 27mm 41mm 41mm, clip, width=\textwidth]{#1}}

\begin{figure}
\includerp{life50.pdf}
\caption{A region profile of two hundred generations of the ``Game of Life'',
  showing region sizes as a function of time (50 snapshots).}
\label{lifeprof50.fig}
\end{figure}

Region profiles for two hundred generations of \lstinline{life} starting from
the configuration shown earlier appear in Figures~\ref{lifeprof50.fig} and
\ref{lifeprof100.fig}.  The highest amount of memory used for regions during the
computation is 45KiB. Figure~\ref{lifeprof100.fig}, which has data collected
from 100 snapshots of the computation, clearly shows that most of the 45KiB are
reclaimed between every two generations of the game. It turns out that the game
essentially stabilises with a small number of live positions on the board after
roughly 150 generations.  This stabilisation is clearly reflected in the region
profile.

\begin{figure}
\includerp{life100.pdf}
\caption{Region profile of two hundred
  generations of the ``Game of Life'', showing region sizes as a
  function of time (100 snapshots).}
\label{lifeprof100.fig}
\end{figure}

Figure~\ref{lifeprof50.fig} is from the same computation, but it only includes
data from 50 snapshots. In the figures, we can see that the largest region is
\lstinline{r332640}. To find out what this region contains, however, one needs to
know about the methods described in Part~\ref{understanding.sec}.

\section{Try it!}
This section tells you how to repeat the profiling experiment shown above.

Compile the SML program \inline{kitdemo/life.sml} as follows. First, make a
personal copy of the \inline{kit/kitdemo} directory, place yourself in it,
and execute the command:\footnote{We assume that the MLKit compiler command
\boxml{mlkit} is somehow available through your \boxml{PATH} environment
variable.}
\begin{scriptcode}[mathescape=false]
  $ mlkit -no_gc -prof life.sml
\end{scriptcode}
The option \lstinline{-prof} enables region profiling and the option
\lstinline{-no_gc} disables reference tracing garbage collection. After the
MLKit has compiled the program \inline{life.sml}, the executable life program
is available as \inline{kitdemo/run}.

Next, you may execute \lstinline{run}, as follows:
\begin{scriptcode}[mathescape=false]
  $ ./run -microsec 500
\end{scriptcode}
This command will make a profiling snapshot every 500 microseconds (i.e., every
half millisecond). If you are satisfied with less fine-grained information,
choose a larger number; it will speed up execution. If you just type
\begin{scriptcode}
  ./run
\end{scriptcode}
there will be one snapshot per second.

Finally, you create a Postscript file and convert it into a pdf-file as
follows:\footnote{The program \boxml{rp2ps} can be found in the
\boxml{kit/bin} directory.}
%
\index{rp2ps@\texttt{rp2ps}}%
%
\begin{scriptcode}
  $ rp2ps -region -name 'Game of life - 100 snapshots' \
          -sampleMax 100
  $ ps2pdf region.ps region.pdf
\end{scriptcode}
The option \lstinline!-sampleMax $N$! instructs \lstinline{rp2ps} to show at
most $N$ snapshots (evenly distributed over the duration of the computation).

%--------------------------------------------------
\chapter{Making Regions Concrete}
%--------------------------------------------------
In this chapter, we give a brief overview of how the abstract memory model
presented in the last chapter is mapped down to conventional memory. In doing
so, we shall introduce notation and concepts that will be used extensively in
what follows.

\section{Finite and Infinite Regions}
\label{fininf.sec}
Not every region has the property that its size is known at compile-time, or
even when the region is first allocated at runtime.  As we have seen, one
typical use of a region is to hold a list, and in general there is no way of
knowing how long a given list is going to be.

For efficiency reasons, however, the MLKit distinguishes between two kinds of
regions: those regions whose size it can determine at compile-time and those it
cannot.
%
\index{region size}
%
These regions are referred to as
%
\index{region size!finite}
%
{\em finite} and
%
\index{region size!infinite}
%
{\em infinite} regions, respectively.\footnote{``finite'' and ``unbounded''
would have been better terms, but it is too late to change that.}  Finite
regions are always allocated on the
%
\index{runtime stack}
%
runtime stack.  An infinite region is represented as a linked list of fixed-size
%
\index{region pages}
%
pages.  The runtime system maintains a free list of such pages. An infinite
region is represented by a
%
\index{region descriptor}
%
{\em region descriptor}, which is a record kept on the runtime stack.  The
region descriptor contains two pointers: one to the first and one to the last
region page in the linked list that represents the region.  Allocating an
infinite region involves getting a page from the
%
\index{free list}
%
free list and pushing a region descriptor onto the runtime stack. Popping a
region is done by appending the region pages of the region and the free list
(this is done in constant time) and then popping the region descriptor off the
runtime stack.

At runtime, every region is represented by a 64-bit entity, called a
%
\index{region name}
%
{\em region name}. If the region is finite, the region name is a pointer into
the stack, namely to the beginning of the region. If the region is infinite, the
region name is a pointer to the region descriptor of the region.

The
%
\index{multiplicity}
%
{\em multiplicity} of a region is a statically determined upper bound on the
number of times a value is put into the region. The MLKit operates with three
multiplicities: 0, 1 and $\infty$, ordered by $0<1<\infty$. Multiplicities
annotate binding occurrences of region variables. An expression of the form
\begin{center}
  \lstinline!let region $\rho:m$ in $e$ end!
\end{center}
where $m$ is a multiplicity, gives rise to an allocation of a region, which is
finite if $m<\infty$, and infinite otherwise.

\section{Runtime Types of Regions}
\label{runtimetypes.sec}

Every region has a
%
\index{runtime type}
%
runtime type. The following runtime types exist: {\sc pair\_rt}, {\sc
  array\_rt}, {\sc ref\_rt}, {\sc triple\_rt}, {\sc string\_rt}, {\sc top\_rt},
and {\sc bot\_rt}. Not surprisingly, regions of runtime type {\sc string\_rt}
contain values of ML type \lstinline{string}. Regions of runtime type {\sc pair\_rt},
{\sc array\_rt}, {\sc ref\_rt}, and {\sc triple\_rt} contain pairs, arrays,
references, and triples, respectively.  Regions with runtime type {\sc top\_rt}
can contain all other forms of allocated values, that is, constructed values,
such as tuples (that are not pairs or triples), records (that do not contain two
or three fields), and function closures. Regions of runtime type {\sc bot\_rt}
are not present at runtime and are associated only with so-called \emph{explicit
region variables}, which we shall not discuss in this document.

It is often, but not always, the case that all values that reside in the same
region have the same type (considered as representations of ML values).

\section{Allocation and De-Allocation of Regions}
\label{aldeal.sec}

The analysis that decides when regions should be allocated and de-allocated is
called {\em region inference}. Region inference inserts several forms of memory
management directives as directives into the program.  The target language of
region inference is called
%
\index{RegExp@$\RegExp$}
%
$\RegExp$.

In $\RegExp$, region allocation and de-allocation are explicit, they are always
paired, and they follow the syntactical structure of the source program.  If $e$
is an expression in $\RegExp$, then so is%
%
\index{let region@\texttt{let region}}
%
\begin{center}
  \lstinline!let region $\rho$ in $e$ end!
\end{center}
Here $\rho$ is a
%
\index{region variable}
%
{\em region variable}. At runtime, first a region is allocated and bound to
$\rho$. Then $e$ is evaluated, presumably using the region bound to $\rho$ for
storing values. Upon reaching \lstinline{end}, the program pops the region.

Region inference also decides, for each value-producing expression, into which
region (identified by a region variable) the value will be put.

We emphasise that region variables and \lstinline{region} bindings are not present in
source programs. The source language is unadulterated Standard ML, so programs
that run on the MLKit should be easy to port to any other Standard ML
implementation.

%Conceptually, there is also a normal runtime stack, which holds temporary values,
%return addresses and so on, but in practice the two stacks are merged into one, which
%we refer to as the runtime stack.

\section{Two Backends}
\index{backend!native}%
\index{backend!bytecode}%

The MLKit provides two different backends, one that generates native code for
the x64 architecture (running Linux or macOS), the {\em native backend\/} and
one that generates JavaScript \cite{10.1145/2093328.2093336}.\footnote{Previous
versions of the MLKit also supported a bytecode backend that allowed for
generated bytecode to be executed by a region based abstract machine
\cite{kam02} and which was used in the context of a web-server plugin for
Standard ML code \cite{eh03,smlserver07}; support for this backend has
terminated, however.}

Whereas the native x64 backend makes use of regions as its basic memory
management discipline, SMLtoJs compiles Standard ML programs to JavaScript and
makes use of JavaScript's garbage collection mechanisms for allocating and
deallocating memory. In this report, we shall only be concerned about the native
backend, for which the linear address space is partitioned into a stack and a
heap, which holds region pages, all of the same size.\footnote{With the
exception that objects that do not fit into a page are allocated using
\boxml{malloc} and freed with \boxml{free}.}

For the x64 native backend, programs compile into a sequence of instructions,
for example for moving word-size data between two registers or between a
register and a memory location.  More complex operations, such as function
application, are expressed by sequences of more detailed instructions. The
native backend implements Iterated Register Allocation \cite{appel96} for
assigning machine registers to temporary variables, using the runtime stack for
spilling.  Although register allocation as well as other issues, such as the
interaction between hardware cache strategies and code selection, are important
for generating efficient code on modern architectures, we do not want to go to
that level of detail here. Our primary concern is with establishing a model that
the user can safely use as a worst-case model of what happens at runtime.

\section{Boxed and Unboxed Values}
\label{boxing.sec}
\index{boxing}%
\index{value!boxed}%
\index{value!unboxed}%

As is common with implementations of programming languages, we distinguish
between {\em boxed\/} and {\em unboxed\/} representations of values.  An {\em
  unboxed\/} value is one that fits in one machine word (i.e., 64 bits) without
being represented as a pointer to allocated data for the value. A {\em boxed
  value\/}, on the other hand, is one that is represented by a word-sized pointer
to the value itself, which is stored in one or more regions.

The MLKit uses unboxed representation for integers, booleans, words, the unit
value, and characters.  The MLKit uses boxed representation for pairs, records
(with at least one element), reals, exception values, function closures, and
many constructed values (i.e., data types). Some data types, such as lists and
booleans, are represented unboxed, however, which is possible by using the lower
and higher bits in pointers to discriminate between the constructed values.

A boxed value may reside in a finite or an infinite region.  Unboxed values are
not stored in regions, except when they are part of a boxed value. For example,
the integer \lstinline{3} by itself is stored as the (binary representation) of the
value 3 in a register or in a machine word. However, the pair \lstinline{(3,4)} is
represented as a pointer to two consecutive words in a region, the first of
which contains the binary representation of 3 and the second of which contains
the binary representation of 4.

\section{Intermediate Languages}
The MLKit native compiler compiles Standard ML programs via a sequence
of typed intermediate languages into x64 machine code.

The intermediate languages that we shall refer to in the following are
(in the order in which they are used in the compilation process):
\begin{description}
\item[\Lam:]
  %
  \index{Lambda@$\Lam$}
  %
  A lambda-calculus like intermediate language. The main difference between the
  Standard ML Core Language and $\Lam$ is that $\Lam$ only has trivial patterns
  and allows functions to take
  %
  \index{arguments!multiple}%
  \index{multiple function arguments}%
  \index{function arguments!multiple}%
  %
  multiple arguments.
\item[\RegExp:]
  %
  \index{RegExp@$\RegExp$}
  %
  Same as \Lam, but with explicit region annotations (such as the \lstinline{region}
  bindings mentioned in Section~\ref{aldeal.sec}). Region variables have their
  runtime type (Section~\ref{runtimetypes.sec}) as an attribute, although, for
  brevity, the pretty printer omits runtime types when printing expressions,
  unless instructed otherwise.
\item[\MulExp:]
  %
  \index{MulExp@$\MulExp$}
  %
  Same as $\RegExp$, but now every binding region variable occurrence is also
  annotated with a multiplicity (Section~\ref{fininf.sec}) in addition to a
  runtime type.  Again, the default is that the runtime type is not printed.
  The terms of $\MulExp$ are polymorphic in the information that annotate the
  nodes of the terms. That way, $\MulExp$ can be used as a common intermediate
  language for a number of the internal analyses of the compiler, which add more
  and more information on the syntax tree.  The analysis that computes
  multiplicities is called the
  %
  \index{multiplicity analysis}
  %
  {\em multiplicity analysis}.
\end{description}
The MLKit compiles Standard ML records into $\Lam$-tuples and it compiles
Standard ML match expressions and other constructs containing patterns into
simpler $\Lam$-constructs.

The MLKit contains a
%
\index{Lambda optimiser}
%
$\Lam$ optimiser, which will happily rewrite $\Lam$ terms when it is clear that
this rewrite results in faster programs (as long as the rewrite cannot lead to
increased space usage).

Region inference takes $\Lam$ to be the source language. Region inference
happens after the $\Lam$ optimiser has had a go at the $\Lam$ term.  Therefore,
it was not really true when we said that region inference simply annotates
source programs; we ignored the translation from SML to $\Lam$ and the $\Lam$
optimiser. Thus, one has to get used to (mostly minor) differences between the
source language and the intermediate languages of the compiler if one wants to
read programs in their intermediate forms. Moreover,
%
\index{Standard ML!Modules}
%
Modules Language constructs are eliminated during compilation from the
intermediate languages (see Chapter~\ref{mlb_and_modules.chap} for details of
compiling with Modules in the MLKit).

When we want to show the result of the analyses, we usually show a $\MulExp$
expression.

\section{The Runtime System}
The
%
\index{runtime system}
%
runtime system is written in C. It is small (less than 30Kb of code when
compiled).  It contains operations for allocating and de-allocating regions,
extending regions, obtaining more space from the operating system, recording
region profiling information, and performing low-level operations for use by the
Standard ML Basis Library.

It is possible to call
%
\index{C!calling}
%
C functions from MLKit code if you use the native backend.  The MLKit takes care
of the memory allocation, by allocating regions for the result of the call
before the call and de-allocating the regions at some point after the call.  The
C functions can build ML data structures such as lists through abstract
operations provided by the MLKit runtime system. See Chapter~\ref{ccall.sec} for
further details.

\section{Compiling Programs with the MLKit}
\label{tryit.sec}

The MLKit is a
%
\index{batch compilation}
%
batch compiler. Thus, executing a program consists of first compiling the
program and then running the generated target program. Because the MLKit stores
files in the directories where your source files are located, you should make a
personal copy of these directories.  Before you try any of the examples below,
make a personal copy of the \lstinline{kitdemo} directory, which is part of the
distribution, and run the MLKit on your own copy.

\section{Compiling with the MLKit Compiler}

The mechanism the MLKit provides for compiling programs is to give the
program source(s) as argument to the MLKit command
%
\index{mlkit@\texttt{mlkit}!executable}
%
\inline{mlkit}.  Together with the sources, a series of options may be passed to
the \inline{mlkit} command. Let us assume that the UNIX command \inline{mlkit}
is available on your system.\footnote{The \boxml{README} file in the distribution
tells you how to install the MLKit.}

Compiling an
%
\index{MLB-file}
%
MLB-file (which may list several SML source files) is similar to compiling a
single SML source file. However, we shall postpone the in-depth discussion of
how to compile MLB-files to Chapter~\ref{mlb_and_modules.chap}.

As an example, to compile the file \inline{projection.sml} located in the
\inline{kitdemo} directory, first go to this directory and execute the following
command:
\begin{scriptcode}[mathescape=false]
  $ mlkit -no_gc projection.sml
\end{scriptcode}
Execution of this command will result in an executable file \inline{run}, placed
in the \inline{kitdemo} directory.

To see some internal representations of the \inline{projection.sml} program, as
produced during compilation, try pass the command-line options
\lstinline{-print_types} and \lstinline{-print_drop_regions_expression} to the
\lstinline{mlkit} command, as follows:
\begin{scriptcode}[mathescape=false]
  $ rm -rf MLB
  $ mlkit -no_gc \
          -print_types \
          -print_drop_regions_expression \
          projection.sml
\end{scriptcode}
Removing the \inline{MLB} directory is necessary to avoid the MLKit to recognise
that it can reuse the previous result of compiling the \inline{projection.sml}
program.  A shorter version of the compilation command is
\begin{scriptcode}[mathescape=false]
  $ mlkit -no_gc -Ptypes -Pdre projection.sml
\end{scriptcode}
To get more information about which options you can pass to the MLKit at the
command-line, try executing \lstinline{mlkit -help}. The output of executing
this command is shown in Appendix~\ref{mlkithelp.app}. For instance, you may add
the flag \lstinline{-w 40} to specify that MLKit should pretty-print output
using a width of 40 character columns.

\section{Running Compiled Programs}
If no errors were found during compilation, the MLKit produces a
%
\index{target program}
%
{\em target program} in the form of an executable file, called \lstinline{run}. The
MLKit places \lstinline{run} in the working directory.

Running the target program is done from the UNIX shell by typing
%
\index{run@\texttt{run}}
%
\begin{scriptcode}
  $ ./run
\end{scriptcode}
For small programs, the file will probably be around 250Kb large, even for the
trivial examples considered in this chapter.  This is because it contains the
MLKit runtime system and compiled code for the parts of the SML Basis Library
that are needed for linking.

Running the programs presented in this chapter is not particularly exciting,
because none of them produce output! However, as an exercise, try compile and
execute the
%
\index{hello world@\texttt{hello world}}
%
\inline{helloworld.sml} program, which, like all other example files in this
document, is located in the
%
\index{kitdemo directory@\texttt{kitdemo} directory}
%
\lstinline{kitdemo} directory.


\part{The Language Constructs of SML}
\label{understanding.sec}

%---------------------------------------------------------
\chapter{Records and Tuples}
\label{records.sec}
%---------------------------------------------------------
In this chapter we describe construction of
%
\index{record}
%
records and selection of record components. We also use records to introduce
%
\index{type!region-annotated}
%
{\em region-annotated types} and
%
\index{effect}
%
{\em effects}, which are crucial for understanding when regions are allocated
and de-allocated.

\section{Syntax}

As part of the SML to
%
\index{Lambda@$\Lam$}
%
$\Lam$ translation, all SML records and SML tuples are compiled into $\Lam$
tuples. The components of $\Lam$ tuples are numbered from left to right,
starting from 0.  Selection is a primitive operation, both in $\Lam$ and in the
other intermediate languages. This primitive is printed using SML notation
\lstinline!#$i$!. Components are numbered from 0: the $i$th components of a tuple
of type $\tau_1\ast\ldots\ast\tau_n$ is accessed by \lstinline!#$i$!, for $0\leq
i\leq n-1$.

The tuple constructor in $\Lam$ is written as in SML:
\begin{center}
  \lstinline!($e_1$, $\ldots$, $e_n$)!
\end{center}
However, the corresponding expression in $\RegExp$ and $\MulExp$ takes the form
\begin{center}
  \lstinline!($e_1$, $\ldots$, $e_n$) at $\rho$!
\end{center}
%
\index{at@\texttt{at}}%
%
where $\rho$ is a
%
\index{region variable}
%
region variable indicating where the tuple should be put.  In the case $n=0$,
the \lstinline!at $\rho$! is not printed, because the empty tuple is not allocated; it is
just a constant that fits in a
%
\index{register}
%
register at runtime.

Records are evaluated left to right.

\section{Example: Basic Record Operations}
\label{proj.ex}

Consider the source program
\begin{smlcode}
  val xy = ((),())
  val x = #1 xy;
\end{smlcode}
Here is the resulting $\MulExp$ program:\footnote{Program
  \boxml{kitdemo/projection.sml}. Running programs is described in
  Section~\ref{tryit.sec}, including how to print intermediate language representations.}
\begin{smlcode}
  let val xy = ((), ())at r4;
      val x = #0 xy
  in {|xy: (_,r4), x: _|}
  end
\end{smlcode}
There are several things to notice from this example.
\begin{enumerate}
\item The $\MulExp$ program contains a free region variable, \lstinline{r4}.
  Notice that the construction of the pair \lstinline{xy} has been annotated by
  ``\lstinline{at r4}'', indicating where the pair should be put;
\item The expression \lstinline+{|xy: (_,r4), x: _|}+ is an example of a
  %
  \index{frame}
  %
  {\em frame expression}. A frame enumerates the components that are exported
  from a compilation unit.  A frame is similar to a record, except that its
  components are variables, each annotated with a type scheme and a region
  variable, if the value is boxed. (In records, the components can only have
  types, not general type schemes.) In the example, the type of the frame is
  \lstinline+{|xy: (unit*unit, r4), x: unit|}+.  The type shows that, after the
  program unit has been evaluated, \lstinline{xy} will reside in \lstinline{r4}.  In the
  the above example, printing of types was suppressed. Thus types were
  abbreviated to \lstinline{_}.
\end{enumerate}

\section{Region-Annotated Types}
\label{reganntypes.sec}

ML type inference infers a type for every expression in the program.
Region inference extends this idea by inferring for each expression a
%
\index{type with place}%
\index{region-annotated type}
%
{\em (region-annotated) type with place}. We use $\mu$ to range over
types with places
$$\mu ~~ ::= ~~ (\tau,\rho)~~|~~\tau$$ where $\tau$ is a {\em region-annotated
  type}, which again can contain other region-annotated types with places. The
region-annotated type with place of an expression is the ML type of the
expression decorated with extra region information; every type constructor that
represents boxed values (e.g., pairs and strings) is paired with a region
variable, indicating where the value is to be put at runtime. Type constructors
that represents unboxed values (e.g., integers and booleans) are not paired with
a region.
%
\index{boxing}%
\index{value!boxed}%
\index{value!unboxed}%

Here are some examples of region-annotated types with places:
\begin{description}
\item[\fbox{$\boxml{unit}$}] The type of 0-tuples.  Integers, booleans, and
  0-tuples are represented
  %
  \index{boxing}
  %
  unboxed at runtime (rather than being stored in regions), see
  Section~\ref{boxing.sec}.
\item[\fbox{$(\boxml{string}, \rho)$}] The type of strings in region $\rho$.
\item[\fbox{$\bigl(\boxml{int} \ast (\boxml{string}, \rho_1), \rho_2\bigr)$}]
  The type of pairs in $\rho_2$ whose first component is an integer and whose
  second component is a string in region $\rho_1$.
\end{description}

One can get the MLKit to print the region-annotated types with places that it
infers for binding occurrences of variables.  The above example then becomes
\begin{smlcode}
  let val xy:(unit*unit,r4) = ((), ())at r4;
      val x:unit = #0 xy
  in {|xy: (unit*unit,r4), x: unit|}
  end
\end{smlcode}

\section{Effects and Regions}
\label{effects.sec}

We now describe the general principle that the MLKit uses to decide when it is
safe to put
%
\index{let region@\texttt{let region}}
%
\lstinline{region} binding around an expression.

Here is an example of an SML program that first creates a pair and then selects
a component of the pair, after which the pair is garbage:\footnote{Program
\boxml{kitdemo/elimpair.sml}. To avoid constant case-folding, one need to pass the option \boxml{-no\_cfold} to the MLKit:
\boxml{mlkit -no\_gc -no\_cfold -Pdre elimpair.sml}.}
\begin{smlcode}
  val n = let val pair = if true then (3+4, 4+5)
                         else (4, 5)
          in #1 pair
          end
\end{smlcode}
The MLKit compiles the declaration into the $\MulExp$ program shown in
Figure~\ref{elimpair.fig}.  The compiler compiles the program as it is, without
reducing the conditional to its \lstinline{then} branch.
\begin{figure}
\hrule\medskip
\begin{smlcode}
   let val n =
         let region r9:1;
             val pair = case true of
                          true => (3 + 4, 4 + 5)at r9
                        | _ => (4, 5)at r9
         in  #0 pair
         end
   in  {|n: _|}
   end
\end{smlcode}
\caption{Region inference decides that the pair is to be allocated in a local,
  finite region; the region will be de-allocated as soon as the pair becomes
  garbage.}
\medskip\hrule
\label{elimpair.fig}
\end{figure}
During evaluation, a region (denoted by \lstinline{r9}) is introduced before the pair
is allocated; it remains on the region stack until the projection of the pair is
evaluated, after which the region is de-allocated.

The ``\lstinline{:1}'' on the binding occurrences of \lstinline{r9} is a multiplicity
indicating that there is only one store operation into the region. (The
%
\index{multiplicity analysis}
%
multiplicity analysis has discovered that there is at most one store from the
\lstinline{then} branch and at most one store from the \lstinline{else} branch and that at
most one of the branches will be chosen.) Thus, the pair will be allocated in a
little region on the runtime stack.

But how does the MLKit know that it is safe to
%
\index{region!de-allocation}
%
de-allocate \lstinline{r9} when the
%
\index{region@\texttt{region}}
%
region goes out of scope?

The answer lies in the fact that the MLKit infers for every expression
not just a region-annotated type with place, but also a so-called
%
\index{effect}
%
{\em effect}.  An effect is a finite set of
%
\index{effect!atomic}
%
atomic effects. Two forms of atomic effect are
%
\index{put@{$\Put$}}
%
$\Put(\rho)$ and
%
\index{get@{$\Get$}}
%
$\Get(\rho)$, where $\rho$ as usual ranges over region variables. The atomic
effect $\Put(\rho)$ indicates that a value is being stored in region $\rho$ and
$\Get(\rho)$ indicates that a value is being read from region $\rho$.  In our
example, the region inference algorithm considers the sub-expression ($e_0=$)
\begin{smlcode}
  let val pair = case true of
                    true => (3 + 4, 4 + 5)at r9
                  | _ => (4, 5)at r9
  in  #0 pair
  end
\end{smlcode}
and finds that it has region-annotated type \lstinline{int} and effect
$\{\Put(\boxml{r9}), \Get(\boxml{r9})\}$.

Whenever a region variable occurs free in the effect of an expression but occurs
free neither in the region-annotated type with place of the expression nor in
the type of any program variable that occurs free in the expression then that
region variable denotes a region that is used only locally within the
expression.  That this is true is of course far from trivial, but it has been
proved for a skeletal version of $\RegExp$.  Consequently, when this condition
is met, the region inference algorithm wraps a
%
\index{let region@\texttt{let region}}
%
\lstinline{region} binding of the region variable around that expression.

In our example, there are no free variables in $e_0$; moreover, \lstinline{r9}
occurs in the effect of $e_0$ but not in the region-annotated type with place of
$e_0$. Thus, the region inference algorithm inserts a \lstinline{region} binding of
\lstinline{r9} around $e_0$.

\section{Runtime Representation}
A
%
\index{record!runtime representation of}
%
record with 0 components (the value of type
%
\index{unit@\texttt{unit}}
%
\lstinline{unit}) is represented unboxed.  A record with $n$ components ($n\geq 1$) is
represented boxed, as a pointer to precisely $n$ words in a
region.\footnote{When garbage collection (GC) is enabled, $n+1$ words are used
to hold a record with $n$ components.}  Notice that records are not
tagged. Avoiding tags is possible when the reference tracing garbage collector
is disabled, because
%
\index{equality!polymorphic}
%
polymorphic equality is compiled into
%
\index{equality!monomorphic}
%
monomorphic equality functions that do not have to examine the type of objects
at runtime \cite{ElsmanTIC98}.

$\Lam$, $\RegExp$, and $\MulExp$ allow one to express unboxed tuples, also in
the case of function calls and returns. For functions that take a tuple as
parameter, the MLKit passes the argument tuple unboxed
%
\index{arguments!multiple}%
\index{multiple function arguments}%
\index{function arguments!multiple}%
\index{record!unboxed}%
%
if it can see that the boxed representation of the tuple is not needed by the
function. The MLKit does not at present unbox records returned from
functions. See Section~\ref{region-polymorphic-functions.sec} on
page~\pageref{region-polymorphic-functions.sec} for details about unboxed
function arguments.

A tuple is not allocated until its components have been evaluated.

When reference-tracing garbage collection is enabled, records and tuples are
tagged (with an extra tag-word) unless they are of size two or three (pairs or
triples), in which case they will reside in regions of runtime type {\sc
  pair\_rt} or {\sc triple\_rt}, respectively. Such regions are treated
specially by the reference-tracing garbage collector.

%---------------------------------------------------------
\chapter{Basic Values}
%---------------------------------------------------------
In this chapter we describe how basic values such as integers, reals,
strings, and booleans are represented in the MLKit. The MLKit complies to
the Definition of Standard ML (Revised)
%
\index{Standard ML!{1997 revision}}
%
and to large parts of the Standard ML Basis Library;\footnote{See the MLKit web
site for a link to the Standard ML Basis Library.}
%
\index{Standard ML!{Basis Library}}%
\index{Basis Library}
%
that is, as a programmer, you can refer to components of the Standard ML Basis
Library through the
%
\index{initial basis}
%
{\em initial basis}, in which all programs are compiled.  Throughout this
chapter, we introduce some of the top-level bindings that are provided by the
initial basis.

\section{Integers and Words}
\label{integers.sec}

Values of type
%
\index{integer}
%
\lstinline{int} are represented as unboxed 64-bit signed integers. When reference
tracing garbage collection is enabled in the MLKit, one bit is used for tagging,
thus in this case values of type \lstinline{int} are really 63-bit signed integers;
Chapter~\ref{gc.chap} describes how to compile programs with garbage collection
enabled. The structure \lstinline{Int} provides many useful operations on integers of
type \lstinline{int}.\footnote{To see what operations are available in the \boxml{Int}
structure, consult the file \boxml{basis/INTEGER.sml}.}  The MLKit also defines
the structures
%
\index{Int31 structure@\lstinline{Int31} structure}
%
\lstinline{Int31},
%
\index{Int32 structure@\lstinline{Int32} structure}
%
\lstinline{Int32},
%
\index{Int63 structure@\lstinline{Int63} structure}
%
\lstinline{Int63}, and
%
\index{Int64 structure@\lstinline{Int64} structure}
%
\lstinline{Int64} for operations on 31-bit, 32-bit integers, 63-bit, and 64-bit
integers. When garbage collection is enabled, values of type \lstinline{Int64.int} and
\lstinline{Int32.int} (for historical reasons) are represented boxed, whereas values
of type \lstinline{Int31.int} and \lstinline{Int63.int} are represented unboxed. When
garbage collection is enabled, the structure \lstinline{Int} is identical to the
structure \lstinline{Int63}. When garbage collection is disabled, the structure \lstinline{Int} is identical to the structure \lstinline{Int64}.

The following operations on integers are pre-defined at top level:
%
\index{=@\texttt{=}}%
\index{<>@\texttt{<>}}%
\index{<@\texttt{<}}%
\index{>@\texttt{>}}%
\index{<=@\texttt{<=}}%
\index{>=@\texttt{>=}}%
\index{+@\texttt{+}}%
\index{-@\texttt{-}}%
\index{div@\texttt{div}}%
\index{mod@\texttt{mod}}%
\index{*@\texttt{*}}%
\index{~@\verb+~+}%
\index{abs@\texttt{abs}}
%
\begin{smlcode}
  infix   4 = <> < > <= >=
  infix   6 + -
  infix   7 div mod  *
  val ~   : int -> int
  val abs : int -> int
\end{smlcode}

In fact, these operations are overloaded and will work on values of other
integer types as well, even on values of type \lstinline{IntInf.int}, which denotes
arbitrarily-sized integers.

Operations on 8-bit, 31-bit, 32-bit, 63-bit, and 64-bit unsigned words are available
in the structures
%
\index{Word8 structure@\lstinline{Word8} structure}
%
\lstinline{Word8},
%
\index{Word31 structure@\lstinline{Word31} structure}
%
\lstinline{Word31},
%
\index{Word32 structure@\lstinline{Word32} structure}
%
\lstinline{Word32},
%
\index{Word63 structure@\lstinline{Word63} structure}
%
\lstinline{Word63}, and
%
\index{Word64 structure@\lstinline{Word64} structure}
%
\lstinline{Word64}.

Similarly as for integers, when garbage collection is enabled, the structure
\lstinline{Word} is identical to the structure \lstinline{Word63} and values of
type \lstinline{Word64.word} are represented boxed. Contrary, when garbage
collection is disabled, the structure \lstinline{Word} is identical to the
structure \lstinline{Word64} and values of type \lstinline{Word64.word} are
represented unboxed.

\section{Reals}

The
%
\index{initial basis}
%
initial basis provides the following top-level operations on reals:
%
\index{=@\texttt{=}}%
\index{<>@\texttt{<>}}%
\index{<@\texttt{<}}%
\index{>@\texttt{>}}%
\index{<=@\texttt{<=}}%
\index{>=@\texttt{>=}}%
\index{+@\texttt{+}}%
\index{-@\texttt{-}}%
\index{*@\texttt{*}}%
\index{/@\texttt{/}}%
\index{~@\verb+~+}%
\index{abs@\texttt{abs}}%
\index{real@\texttt{real}}%
\index{trunc@\texttt{trunc}}%
\index{floor@\texttt{floor}}%
\index{ceil@\texttt{ceil}}%
\index{round@\texttt{round}}
%
\begin{smlcode}
  infix     4 < > <= >=
  infix     6 + -
  infix     7  * /
  val ~     : real -> real
  val abs   : real -> real
  val real  : int -> real
  val trunc : real -> int
  val floor : real -> int
  val ceil  : real -> int
  val round : real -> int
\end{smlcode}

\noindent
Values of type \lstinline{real} are implemented as 64-bit floating point numbers.
They are always boxed when they appear in data structures, that is, they are
each represented as a pointer to a 64-bit
%
\index{alignment}
%
word, which reside in a region of runtime type {\sc top\_rt}.

A real constant $c$ in the source program is translated into an expression of
the form
%
\index{at@\texttt{at}}
%
\lstinline!$c$ at $\rho$!, where $\rho$ is a region variable, indicating the
region into which the real will be stored.

The MLKit will do its best to eliminate regions holding reals by unboxing reals
and representing them in floating point registers or on the runtime stack. Thus,
in internal representations, MLKit distinguishes between (boxed) reals and
unboxed 64-bit floating point values (of type \lstinline{f64}). MLKit supports that
values of type \lstinline{f64} are passed to and returned from functions in
floating point registers. Values of type \lstinline{f64} may also be stored in
closures.

The structures \inline{Real}, \inline{IEEEReal}, and \inline{Math} provide other
useful operations on reals.\footnote{Consult the files \boxml{basis/REAL.sig},
\boxml{basis/IEEE\_REAL.sig}, and \boxml{basis/MATH.sig}.}

\section{Characters and Strings}
The
%
\index{initial basis}
%
initial basis provides the following top-level operations on characters and strings:
%
\index{=@\texttt{=}}%
\index{^@\verb+^+}%
\index{ord@\texttt{ord}}%
\index{chr@\texttt{chr}}%
\index{str@\texttt{str}}%
\index{size@\texttt{size}}%
\index{explode@\texttt{explode}}%
\index{implode@\texttt{implode}}%
\index{concat@\texttt{concat}}%
\index{substring@\texttt{substring}}
%
\begin{smlcode}
  infix         4 =
  infix         6 ^
  val ord       : char -> int
  val chr       : int -> char
  val str       : char -> string
  val size      : string -> int
  val explode   : string -> char list
  val implode   : char list -> string
  val ^         : string * string -> string
  val concat    : string list -> string
  val substring : string * int * int -> string
\end{smlcode}

\noindent
Characters are represented as 64-bit words, although only 8 bits are used to
store the character. Characters are always unboxed, also when garbage collection
is enabled.

A string is represented by a 64-bit pointer into an infinite region. A string is
stored in a region page if it fits in the page; otherwise, it is allocated using
\inline{malloc} and linked with the region so that it can be \inline{free}ed
when the region is deallocated. The internal string representation is completely
transparent to the programmer, who does not have to worry about the actual size
of region pages. Characters of a string take up only 8 bits of memory each. The
size of a string is kept along with the characters that make up the string. For
compatibility with many C routines, the character sequence is null-terminated.

Calls to \lstinline{ord}, \lstinline{chr}, \lstinline{str}, and \lstinline{size}
take constant time and space.  Calls of \lstinline{explode},
\lstinline{implode}, \lstinline{concat}, \lstinline{substring}, and
\lstinline!^! take time and space proportional to the sum of the size of their
input and their output.

The string and character operations can raise exceptions, as detailed in the
Standard ML Basis Library documentation.

The structures \lstinline{Char}, \lstinline{String}, \lstinline{CharVector},
\lstinline{Byte}, and \lstinline{StringCvt} provide other useful operations on
characters and strings.\footnote{Consult the files \boxml{basis/CHAR.sig},
\boxml{basis/STRING.sig}, \boxml{basis/MONO\_VECTOR.sml},
\boxml{basis/BYTE.sig}, and \boxml{basis/STRING\_CVT.sml}.}

\section{Booleans}

The boolean values \lstinline{true} and \lstinline{false} are represented as
64-bit words, although only one bit is used to denote the value.  Booleans are
unboxed. The
%
\index{initial basis}
%
initial basis provides the following top-level operations on booleans:
%
\index{=@\texttt{=}}%
\index{not@\texttt{not}}
%
\begin{smlcode}
  infix   4 =
  val not : bool -> bool
\end{smlcode}

\noindent
The structure \lstinline{Bool} provides other useful operations on
booleans.\footnote{Consult the file \boxml{basis/BOOL.sig}.}

%---------------------------------------------------------
\chapter{Lists}
\label{lists.sec}\index{list}
%---------------------------------------------------------

Section~\ref{lsyn.sec} gives a summary of the list concept in Standard ML,
introduces the notion of the \emph{auxiliary pairs} of a list and presents the
syntax of constructors and de-constructors in the intermediate languages.
Section~\ref{listtypes.sec} introduces region-annotated list types and show how
they correspond to the layout of lists in memory.
Section~\ref{listexamples.sec} gives a small example.

\section{Syntax}
\label{lsyn.sec}

In Standard ML, all lists are constructed from the two constructors
%
\index{::@\texttt{::}}
%
\lstinline{::} (read: cons) and
%
\index{nil@\texttt{nil}}
%
\lstinline{nil}.  As a shorthand, one can write
\begin{center}
  \lstinline![$\exp_1$, $\cdots$, $\exp_n$]!
\end{center}
for
\begin{center}
  \lstinline!$\exp_1$ :: $\cdots$ :: $\exp_n$ :: nil!
\end{center}
which in turn is short for
\begin{center}
  \lstinline!op :: ($\exp_1$, $\cdots$, op ::($\exp_n$,nil)$\cdots$)!
\end{center}
where $\exp$ ranges over expressions.  The type schemes of \lstinline{nil} and
\lstinline{::} (cons) are
$$
\mbox{\lstinline{nil}} \mapsto\forall\alpha.\alpha\,\kw{list}\qquad
\mbox{\lstinline{::}} \mapsto\forall\alpha.\alpha\ast\alpha\,\kw{list}\to\alpha\,\kw{list}
$$ Notice that \lstinline{::} is always applied to a pair. The construction of
the pair and the application of \lstinline{::} should, in principle, not be
confused: the pair and the constructed value are in principle separate values
inasmuch as they have different type.  For example, the declaration
\begin{smlcode}
  val p = (2, nil)
  val mylist = (op ::) p
  val n = #1 p
\end{smlcode}
is legal in Standard ML. We refer to the pairs to which \lstinline{::} is
applied as
%
\index{pair!auxiliary}
%
{\em auxiliary pairs (of the list data type)}.

Decomposition of list values in Standard ML is done by
%
\index{pattern matching}
%
pattern matching.  A pattern can extract the pair to which \lstinline{::} is
applied. Pattern matching on pairs can then give access to the components of the
pair.
\begin{smlcode}
  val abc = ["a", "b", "c"]
  val op :: p = abc    (* binds p to the pair ("a", ["b","c"]) *)
  val (x::y::_) = abc  (* binds x to "a" and y to "b" *)
\end{smlcode}
In the last declaration, the pattern \boxml{(x::y::\_)} is short for the pattern
\begin{center}
  \lstinline!(op ::(x, op ::(y, _)))!
\end{center}
which combines decomposition of constructed values with decomposition of pairs.

The intermediate languages $\Lam$, $\RegExp$, and $\MulExp$ have SML-like
constructs for applying constructors, but they decompose constructed values by
applying a
%
\index{decon@\texttt{decon}}
%
de-constructor primitive, not by pattern matching.
%
\index{at@\texttt{at}}
%
\begin{center}
\begin{tabular}{|c|c|}\hline
$\Lam$, $\RegExp$, or $\MulExp$ & \\ \hline
\lstinline!nil!                 & create \lstinline!nil! value \\
\lstinline!::($e$)!             & create \lstinline!::! (cons) value \\
\lstinline!decon_::($e$)!       & cons decomposition \\
\hline
\end{tabular}
\end{center}
In $\Lam$, which has essentially the same type system as SML, $\kw{decon\_::}$,
the decomposition function for \lstinline{::}, has type
$\forall\alpha.\alpha\,\kw{list}\to\alpha\ast\alpha\,\kw{list}$.  In addition,
$\Lam$, $\RegExp$, and $\MulExp$ have a simple case construct:
\begin{center}
  \lstinline!case $e$ of :: => $e_1$ | _ => $e_2$!
\end{center}
where $e$ must have list type. For convenience, MLKit will layout $\MulExp$
\lstinline{case} constructs of the form
\begin{center}
  \lstinline!case $x$ of :: => let $y$ = decon_:: $x$ in $e_1$ end | _ => $e_2$!
\end{center}
as
\begin{center}
  \lstinline!case $x$ of :: $y$ => $e_1$ | _ => $e_2$!
\end{center}

\section{Physical Representation}
\label{ublists.sec}

The empty list is represented by an odd, unboxed integer.  A non-empty list is
represented as a pointer to a pair of two words in a region, the first of which
contains the head of the list and the second of which contains the
representation of the tail of the list. In other words, the physical
representation does not distinguish a \lstinline{::} cell from the auxiliary
pair to which \lstinline{::} is applied. Since \lstinline{nil} is represented by
an odd number and since word addresses are always even, \lstinline{nil} can be
distinguished from the representation of a non-empty list.

As a consequence, there is no cost involved in applying \lstinline{::} to an
auxiliary pair or in applying the decomposition operator \lstinline{decon_::} to
a non-empty list.

\section{Region-Annotated List Types}
\label{listtypes.sec}

In Standard ML, all elements of a given list must have the same type.  We extend
this constraint to region inference by saying that all element values in the
same list must reside in the same region(s) and that all auxiliary pairs of the
same list must reside in the same region.
\begin{figure}
\hrule

\begin{center}
\begin{picture}(75,35)(0,0)
\put(0,0){\framebox(30,10){\lstinline{"a"}}}
\put(0,10){\framebox(30,10){\lstinline{"b"}}}
\put(0,20){\framebox(30,10){\lstinline{"c"}}}
%
\put(40,0){\framebox(30,10){$(\qquad,\kw{nil})$}}
\put(40,10){\framebox(30,10){$(\qquad,\kw{::})$}}
\put(40,20){\framebox(30,10){$(\qquad,\kw{::})$}}
%
\put(50,5){\vector(-1,1){20}}
\put(50,15){\vector(-1,0){20}}
\put(50,25){\vector(-1,-1){20}}
%
\put(60,15){\line(3,0){15}}
\put(60,25){\line(3,0){15}}
%
\put(75,15){\line(0,-1){7}}
\put(75,25){\line(0,-1){7}}
%
\put(75,18){\vector(-1,0){5}}
\put(75,8){\vector(-1,0){5}}
%
\put(15,-5){\hbox{$\rho_1$}}
\put(55,-5){\hbox{$\rho_2$}}
\end{picture}
\end{center}
\caption{Layout of the list
  \lstinline!["a","b","c"]:((string,$\rho_1$),[$\rho_2$])list! in memory. The
  auxiliary pairs of the list reside in $\rho_2$.  Each auxiliary pair takes up
  two words; the constructors \lstinline{::} (cons) and \lstinline{nil} are
  represented unboxed.}  \medskip

\hrule
\label{listregions.fig}
\end{figure}

Thus, region inference does not distinguish between a list and its
%
\index{list!tail}%
\index{list!auxiliary pairs}%
\index{auxiliary pairs}%
%
tail.  Indeed, a typical use of an infinite region is to hold all the auxiliary
pairs of a list. For an example, Figure~\ref{listregions.fig} shows how the list
\lstinline{["a","b","c"]} is laid out in memory.

In general, the
%
\index{type!region-annotated}%
\index{list!region-annotated type}
%
region-annotated type of a list takes the form
$$(\mu,[\rho])\kw{list}$$ where $\mu$ is the region-annotated type with place of
the members of the list and where $\rho$ is the region where the auxiliary pairs
of the list are stored.  For example, the region-annotated type
$$((\kw{string},\rho_1),[\rho_2])\kw{list}$$ classifies lists that have their
auxiliary pairs in a region $\rho_2$ and strings in a region $\rho_1$.

Notice that the \kw{list} type constructor is not paired with a region variable.
The reason is that the physical representation of lists treats the constructors
as unboxed in the sense described in Section~\ref{ublists.sec}.

Very importantly, not all lists need to live in the same regions.  Formally,
\lstinline{nil} and \lstinline{::} have the following region-annotated type
schemes:
\begin{eqnarray*}
\kw{nil} & \mapsto & \forall\alpha\rho.(\alpha,[\rho])\kw{list}\\
\kw{::}  & \mapsto & \forall\alpha\rho\epsilon.(\alpha\ast(\alpha,[\rho])\kw{list},\rho)
\ar{\epsilon.\emptyset} (\alpha,[\rho])\kw{list}
\end{eqnarray*}
Despite its verbosity, the type scheme for \lstinline{::} deserves careful
study. It is polymorphic not just in types (signified by the bound type variable
$\alpha$) but also in the region signified by the bound region variables $\rho$,
and, in the case of \lstinline{::}, in the effect signified by the
%
\index{effect variable}
%
\emph{effect variable} $\epsilon$.  The $\epsilon.\emptyset$ appearing on the
function arrow is called an
%
\index{arrow effect}
%
{\em arrow effect}.  Occurring in a function type, an arrow effect describes the
effect of applying the function.  In this case, the effect is empty, as only
unboxed values are manipulated by \lstinline{::}.  The effect variable
$\epsilon$ is used for expressing dependencies between effects (examples follow
in Chapter~\ref{hof.sec}). Due to the fact that the variables are universally
quantified, every occurrence of a list can, potentially, be in its own
regions. But notice that the type of \lstinline{::} forces the element, which is
consed onto the list, to be in the same regions as the already existing elements
of the list.  Similarly, the type forces the auxiliary pairs to be in one region
($\rho$).

\section{Example: Basic List Operations}
\label{listexamples.sec}
The MLKit compiles the program\footnote{Program \boxml{kitdemo/onetwothree.sml}.}
\begin{smlcode}
  let val l = [1, 2, 3];
      val (x::_) = l
  in x
  end
\end{smlcode}
into the $\RegExp$ program shown in Figure~\ref{listprint.fig}.
\begin{figure}
\hrule \medskip
\begin{smlcode}
   let val it =
         let region r9:INF;
             val l = [1,2,3] at r9
         in  case l of
             :: v91 => #0 v91 | _ => raise Bind
         end
   in  {|it: _|}
   end
\end{smlcode}
\caption{Example showing construction and de-construction of a small list.
  Layout of the list \lstinline{l} is analogous to Figure~\ref{listregions.fig}.  The
  infinite region \lstinline{r9} holds the auxiliary pairs of the list. Notice also
  that \lstinline{v91} is not bound to an explicit expression \lstinline{decon\_:: l};
  instead, the pretty-printing abbreviates such immediate bindings by hoisting
  the bound variable (here \lstinline{v91}) into a pattern in the case construct.}
\label{listprint.fig}
\medskip

\hrule
\end{figure}


%---------------------------------------------------------
\chapter{First-Order Functions}
%---------------------------------------------------------
In this chapter, we shall treat
%
\index{function}%
\index{function!first-order}
%
functions that are declared with \lstinline{fun} and that are first-order (i.e.,
that neither take functions as arguments nor produce functions as
results). Higher-order functions are treated in Chapter~\ref{hof.sec}.  Region
polymorphism works uniformly over all types; we use lists as an example of the
general scheme.

\section{Region-Polymorphic Functions}
\label{region-polymorphic-functions.sec}

\index{region polymorphism|(}%
%
It would be a serious limitation if all lists produced by a series of calls to a
function were stored in the same region, for then all those lists would have to
be kept alive until the last time one of them were used. The solution that the
MLKit offers to this problem is {\em region-polymorphic functions}, that is,
functions that are passed regions at runtime.

When one declares a function that, when called, produces a fresh list, then the
region inference algorithm will automatically insert extra
%
\index{region parameter!formal}
%
formal region parameters in the function declaration.  At every place one refers
to the function, for example because one calls the function, the region
inference algorithm inserts
%
\index{region parameter!actual}
%
actual region parameters that tell the function where to put its result. This is
all done automatically; the user does not have to introduce region parameters or
pass them as arguments. Even so, it is useful to understand the general
principle, so that one can make good use of region polymorphism.

The syntax of a (single) function declaration in $\MulExp$ is:
\begin{center}
  \lstinline!fun $f$ at $\rho_0$ [$\rho_1$, $\cdots$, $\rho_k$] ($x_1$,$\cdots$,$x_n$) = $e$!
\end{center}
Here $\rho_0$ denotes the region in which the closure for $f$ is stored,
$\rho_1, \ldots,\rho_k$ are the
%
\index{region parameter!formal}
%
{\em formal region parameters}, $x_1,\cdots,x_n$ are value parameters, and $e$
is the body of the function.  In general, calls to a function $f$ takes the form
\begin{center}
  \lstinline!$f$ [$\rho_1'$, $\cdots$, $\rho_k'$] ($e_1'$, $\cdots$, $e_n'$)!
\end{center}
where \lstinline![$\rho_1'$, $\cdots$, $\rho_k'$]! are
%
\index{region parameter!actual}
%
{\em actual region parameters} and $e_1',\cdots,e_n'$ are expressions denoting
the arguments to the call. Notice that region parameters are enclosed in
brackets (\boxml{[ ]}), which should not cause confusion with ML lists. In the
special case $k=0$, no region parameters are passed to the function, and we
shall often omit the brackets in this case.

Unlike for Standard ML, functions are allowed to be passed multiple value
arguments, without having them passed in a boxed tuple. In the case $n=1$, we
often omit the surrounding brackets $\verb+(+ \cdots \verb+)+$.

Different calls of $f$ can use different actual regions; this feature is
essential for obtaining good separation of lifetimes.  For an example, consider
the following program:
\begin{smlcode}
  fun fromto (a, b) = if a>b then []
                      else a :: fromto(a+1, b)
  val l = #1(fromto(1,10), fromto(100,110));
\end{smlcode}
The corresponding $\MulExp$ program is shown in Figure~\ref{fromto.fig}.
\begin{figure}[htb]
\hrule
\medskip
\begin{smlcode}
   let fun fromto at r1 [r13:INF] (v126, v127) =
           case v126 > v127 of
             true => nil
           | _ => :: (v126, fromto[r13] (v126 + 1, v127))at r13;
       val l =
         let region r23:INF, r27:1
         in  #0 (fromto[r4] (1, 10), fromto[r23] (100, 110))at r27
         end
   in  {|fromto: (_,r1), l: _|}
   end
\end{smlcode}
\caption{The region-annotated version of \lstinline{fromto} shows that
  \lstinline{fromto} is region-polymorphic. (Program:
  \inline{kitdemo/fromto.sml}, printed by passing the option
  \inline{-print_drop_regions_expression} (or \inline{-Pdre}) to the MLKit
  compiler.)}
\medskip

\hrule
\label{fromto.fig}
\end{figure}

There are several things to notice about the region annotated program.  First,
notice that the function {\tt fromto} represents its argument \lstinline{(a,b)}
%
\index{arguments!multiple}%
\index{multiple function arguments}%
\index{function arguments!multiple}%
\index{arguments!flattening}%
\index{deep argument flattening}%
%
unboxed; the MLKit figures out that the function does not use the boxed
representation of the argument and transforms all calls to the function to pass
the argument unboxed (on the runtime stack and in registers if possible). This
kind of \emph{argument flattening} is supported also for nested tuple arguments
and is the mechanism also behind uncurrying and passing floating point arguments
in registers \cite{deep-elsman25}.

Second, notice that \lstinline{r13} is a formal region parameter of
\lstinline{fromto} and that \lstinline{r13} is passed along in the recursive
call
%
\lstinline{fromto[r13] (v126 + 1, v127)}. Here the notation
%
\lstinline{(v126 + 1, v127)}
%
(without an \lstinline{at} annotation) denotes the passing of the unboxed record
to the function \lstinline{fromto}.

%
\index{fromto@\texttt{fromto}}
%
Finally, notice that the regions that hold the two lists generated by this
program are distinct.  The list that escapes to top level is stored in the
global region \lstinline{r4}, whereas the list that does not escape is stored in
the local region \lstinline{r23}.

\section{Region-Annotated Type Schemes}
\label{regtych.sec}
A
\index{type scheme!region-annotated}%
\index{region-annotated type scheme}%
{\em (region-annotated) type scheme\/} takes the form
$$\sigma::=\lsigma$$
where $\alpha_1,\ldots,\alpha_n$ are type variables,
$\rho_1,\ldots,\rho_k$ are region variables,
$\epsilon_1,\ldots,\epsilon_m$ are
\index{effect variable!bound}%
effect variables, and $\tau$ is a region-annotated type.
%
The types of \lstinline{nil} and \lstinline{::} in Section~\ref{listtypes.sec}
are examples of
%
\index{region polymorphism}
%
region-annotated type schemes.

There is a close connection between, on the one hand, the formal and actual
%
\index{region parameter}
%
region parameters found in $\RegExp$ (and $\MulExp$) programs, and, on the other
hand, the region-annotated type schemes that the region inference algorithm
assigns to recursively declared functions. The formal region parameters of a
function stem from the bound region variables of the region-annotated type
scheme of that function.  The actual region parameters which annotate a call of
the function are the region variables to which the bound region variables are
instantiated at that particular application.

For example, the region-annotated type scheme of \lstinline{fromto} from
Figure~\ref{fromto.fig} is
$$\forall\rho_{13}\epsilon. [\kw{int}, \kw{int}]
\ar{\epsilon.\{\Put(\rho_{13})\}} (\kw{int},[\rho_{13}])\kw{list}$$ where we use
the syntax $[\tau_1, \ldots, \tau_n], n \geq 1$ to denote an unboxed tuple of
types $\tau_1, \ldots,\tau_n$. This syntax is not to be confused with the
auxiliary region variables of type constructors (e.g., the list $[\rho_{13}]$ in
the region-annotated type scheme of \lstinline{fromto}.)

At the last call of \lstinline{fromto} in Figure~\ref{fromto.fig}, the type
scheme is instantiated to the region-annotated type
$$[\kw{int}, \kw{int}] \ar{\epsilon'.\{\Put(\rho_{23})\}}
(\kw{int},[\rho_{23}])\kw{list}$$

The instantiation of bound variables of the type scheme that yields this
region-annotated type is
$$\{\rho_{13}\mapsto\rho_{23}, \epsilon\mapsto\epsilon'\}$$ In general, the
actual region parameters that annotate a call of a region-polymorphic function
are obtained from the range of the substitution by which the type scheme of the
function is instantiated at that application.

\index{type scheme with place!region-annotated}%
\index{region-annotated type scheme with place}%
%
Region-polymorphic functions also have to be allocated somewhere.  Therefore,
the region information associated with a region-polymorphic function is a {\em
  (region-annotated) type scheme with place}, that is, a pair $(\sigma,\rho)$.
Indeed, every binding of a variable to a boxed value (whether the binding is
done by \lstinline{fun}, \lstinline{let}, or \lstinline{fn}) associates a
region-annotated type scheme with place to the binding occurrence.  (In the case
of \lstinline{let}, the type scheme will have no quantified region and effect
variables, however, and in the case of \lstinline{fn}, the type scheme will have
no quantified variables at all.)  In the following, when we refer to ``the
region-annotated type (scheme) with place'' of some variable, we mean the
region-annotated type (scheme) with place that is associated with the binding
occurrence of the variable. The region type scheme should be clearly
distinguished from instances of the type scheme, which decorate non-binding
occurrences of the variable.

The region-annotated type scheme with place of a variable bound to an unboxed
value is always on the form $\sigma$ (no specified place), where $\sigma$ is the
region-annotated type scheme associated with the variable (see
Section~\ref{reganntypes.sec}).

\section{Endomorphisms and Exomorphisms}

The \lstinline{fromto} function from Section~\ref{regtych.sec} has the property
that it can put its result in regions that are separate from the regions where
its argument lies. This is not surprising, if one looks at the declaration of
the function; it creates a brand new list that does not share with the argument
\lstinline{(a,b)}, except for the integers \lstinline{a} and \lstinline{b},
which may end up in the list.  The freshness of the generated list is evident
from the region type scheme of the function; the region variable in the result
type does not appear in the argument type.

Not all region-polymorphic functions create brand new values. Very often, a
region-polymorphic function simply adds values to regions that are determined by
the argument to the function. A good example is the list append function from
the initial basis:\footnote{File \boxml{kitdemo/append.sml}.}
\begin{smlcode}
  infixr 5 @
  fun [] @ ys = ys
    | (x::xs) @ ys = x :: (xs @ ys)
  val l = [1] @ [2,3]
\end{smlcode}
Append successively conses the elements of the first list onto the second list.
Thus, \lstinline{ys} and \lstinline{xs @ ys} must be in the same
regions. However, the auxiliary pairs of \lstinline{xs} and \lstinline{ys} need
not be in the same regions, although the elements of \lstinline{xs} and
\lstinline{ys} clearly must be in the same regions, because they end up in the
same list. These properties of the append function \lstinline{@} are summarised
in its inferred region-annotated type scheme:
$$\begin{array}{c}\forall\alpha\rho_{19}\rho_{17}\epsilon.
   [ (\alpha,[\rho_{17}])\kw{list},
      (\alpha,[\rho_{19}])\kw{list} ]
\ar{\epsilon.\{\Get(\rho_{17}),\Put(\rho_{19})\}} (\alpha,[\rho_{19}])\kw{list}\end{array}
$$ When one writes a function, it is a good idea to consider whether one wants
the function to create values in fresh regions or whether one wants it to add
values to existing regions.  Adding to existing regions can of course make these
regions too large and long-lived, because the entire region will be alive for as
long as one of the values in the region may be needed in the future.

\begin{figure}[htb]
\hrule
\medskip
\begin{smlcode}
   let fun @ at r1 [r19:INF] (v129, v130) =
           case v129 of
             nil => v130
           | :: v98 => :: (#0 v98, @[r19] (#1 v98, v130))at r19;
       val l =
         let region r35:INF
         in  @[r4] ([1] at r35, [2,3] at r4)
         end
   in  {|@: (_,r1), l: _|}
   end
\end{smlcode}
\caption{The region-annotated version of {\tt append}.}
\medskip
\hrule
\label{append.fig}
\end{figure}

The $\MulExp$ version of the append function is listed in
Figure~\ref{append.fig}. At the application of \lstinline{@}, the region
annotated type scheme for \lstinline{@} is instantiated to the region annotated type
$$[ (\kw{int},[\rho_{35}])\kw{list},
      (\kw{int},[\rho_4])\kw{list} ]
\ar{\epsilon'.\{\Get(\rho_{35}),\Put(\rho_4)\}} (\kw{int},[\rho_4])\kw{list} $$

To avoid passing regions that are never used, the MLKit introduces only formal
region variables for those bound region variables in the type scheme for which
there appears at least one
%
\index{put@{$\Put$}}
%
$\Put$ effect in the type of the function.  Reading a value is done simply by
following a pointer to the value, irrespective of what region the value resides
in, whereas storing a value in a region uses the name (see
Section~\ref{fininf.sec}) of the region.  This omitting of region parameters
explains why $\rho_{17}$ does not become a formal region parameter of
\lstinline{@} and why $\rho_{35}$ is not passed to \lstinline{@} at the call
site. This optimisation, which is called
%
\index{region!dropping of}
%
{\em dropping of regions}, is the key reason why the MLKit takes the trouble to
distinguish between $\Put$ and
%
\index{get@{$\Get$}}
%
$\Get$ \label{bother-to-distinguish-get-n-put}effects.

Here are two more examples to highlight the difference between functions that
can put values in fresh regions and functions that add values to existing
regions:
\begin{smlcode}
  fun cp1 [] = []
    | cp1 (x::xs) = x :: cp1 xs
  fun cp2 (l as []) = l
    | cp2 (x::xs) = x :: cp2 xs
\end{smlcode}
Here \lstinline{cp1} can copy the auxiliary pairs of a list into a fresh
region, whereas \lstinline{cp2} always copies the auxiliary pairs of a
list into the same region:
\begin{eqnarray*}
\kw{cp1}&\mapsto&\forall\alpha\rho\rho'\epsilon.
     (\alpha,[\rho])\kw{list} \ar{\epsilon.\{\Get(\rho),
           \Put(\rho')\}} (\alpha,[\rho'])\kw{list}\\
\kw{cp2}&\mapsto&\forall\alpha\rho\epsilon.
     (\alpha,[\rho])\kw{list} \ar{\epsilon.\{\Get(\rho),
           \Put(\rho)\}} (\alpha,[\rho])\kw{list}
\end{eqnarray*}
As we saw in Section~\ref{life.sec}, there are cases where it is useful to copy
a list from one region into another region, so as to make it possible to
de-allocate the old region. This copying can be used as a kind of
programmer-controlled garbage collection in cases where garbage has accumulated
in the original region.

Because it is often useful to distinguish between functions that can put their
result into fresh regions and functions that simply add to regions determined by
their value argument, we shall refer informally to the former functions as
%
\index{region exomorphism}
%
{\em region exomorphisms} and the latter as
%
\index{region endomorphism}
%
{\em region endomorphisms}. Notice that these terms do not provide a clear-cut
distinction. Often, functions have both an endomorphic and an exomorphic side to
them. Also notice that even a region exomorphic function can be forced to act as
an endomorphism by the calling context. As an example, consider the expression
\begin{center}
  \lstinline!if true then cp1 l else l!
\end{center}
Because the two branches of the conditional are required to have the same
region-annotated type with place, \lstinline{l} and \lstinline{cp1 l} are forced
to be in the same regions.

\section{Polymorphic Recursion}
\label{polyrec.sec}

A
%
\index{recursion!polymorphic}
%
recursive region-polymorphic function

\begin{center}
  \lstinline!fun $f$ at $\rho_0$ [$\rho_1$, $\cdots$, $\rho_k$] ($x_1$, $\cdots$, $x_n$) = $e$!
\end{center}
may call itself inside its own body ($e$) with regions that are different from
its own formal region parameter (\lstinline![$\rho_1$, $\cdots$, $\rho_k$]!).
This feature is called \emph{polymorphic recursion in regions}, named after
polymorphic recursion, the analogous concept for types.  Polymorphic recursion
in regions is vital for achieving good memory management in connection with
recursion.  Unfortunately, it also makes the region inference problem
considerably more challenging, but that is a different story \cite{tofbir98}.

We now show a typical use of polymorphic recursion in regions, namely merge
sorting of lists. The basic idea of merge sort is simple: first split the input
list into two lists $l$ and $r$ of roughly equal length.  Then sort $l$ and $r$
recursively and merge the results into a single sorted list.  When programming
with regions, we need to plan which of these lists we want to reside in the same
regions. We do not want to waste space. In particular, if $n$ is the length of
the list, it would be quite irresponsible to use $O(n\hbox{log}\,n)$ space, say.
Let us aim at arranging that the sorting function is a region exomorphism that
does not produce any values in its result regions except the sorted list. To
sort $n$ elements, we shall need $n$ list cells (to hold the input list) plus
roughly $2\times(n/2)$ list cells to hold $l$ and $r$, the two lists that arise
from splitting the input list. To sort $l$ recursively, we need space for the
two lists obtained by splitting $l$ and so on. The space consumption grows to a
maximum of $3n$ list cells (including the $n$ cells to hold the input), before
any merging is done.  By the time all of $l$ is sorted, that is, just before $r$
is sorted recursively, we have the following lists: the input ($n$ cells), $l$
($n/2$ cells), $l$ sorted ($n/2$ cells), $r$ ($n/2$ cells). Continuing this way,
at the rightmost merge of two lists of length at most one, approximately $4n$
list cells are live.  Then a series of final merges occur.  Code that uses these
ideas is listed in
%
\index{cp@\texttt{cp}}%
\index{msort@\texttt{msort}}%
\index{merge sort}%
\index{projects!compiling}%
\index{projects!running}
%
Figure~\ref{msort.fig}.\footnote{MLB-file \boxml{kitdemo/msort.mlb}, file
\boxml{kitdemo/msort.sml}. To compile the project, go to the \boxml{kitdemo}
directory and execute \boxml{mlkit msort.mlb} from the shell. The MLKit places
an executable file \boxml{run} in the \boxml{kitdemo} directory. For an
in-depth description of how to compile and run MLB-files and SML-files, see
Chapter~\ref{mlb_and_modules.chap}.}
\begin{figure}[hbt]
\hrule
\medskip
\begin{smlcode}
  fun cp [] = []
    | cp (x::xs) = x :: cp xs

  (* exomorphic merge *)
  fun merge (xs, []) : int list = cp xs
    | merge ([], ys) = cp ys
    | merge (l1 as x::xs, l2 as y::ys) =
       if x<y then x :: merge(xs, l2)
       else y :: merge(l1, ys)

  (* splitting a list *)
  fun split (x::y::zs, l, r) = split(zs, x::l, y::r)
    | split ([x], l, r) = (x::l, r)
    | split ([], l, r) = (l, r)

  (* exomorphic merge sort *)
  fun msort []  = []
    | msort [x] = [x]
    | msort xs = let val (l, r) = split(xs, [], [])
                 in merge(msort l, msort r)
                 end
\end{smlcode}
\caption{Merge sorting of lists.}
\label{msort.fig}
\medskip\hrule
\end{figure}

The exomorphic merge function is a bit inefficient in that it copies one
argument when the other is empty, but the exomorphism ensures that
\lstinline{msort l} and \lstinline{msort r} are not forced into the same
regions. The polymorphic recursion in regions makes it possible for
\lstinline{xs}, \lstinline{l}, \lstinline{r}, \lstinline{msort l}, and
\lstinline{msort r} all to be in distinct regions. For example, in the call
\lstinline{msort l}, the polymorphic recursion makes it possible for
\lstinline{l} to be in a region different from \lstinline{xs} and it also makes
it possible for the result of the call to be in a region different from the
result of \lstinline{msort xs}.

Based on the above analysis we conclude that the space required by
\lstinline{msort xs} is approximately $4nc_1+c_2{\rm log}_2n$ plus the extra
stack space required for the final merges, where $n$ is the length of
\lstinline{xs}, $c_1$ is the size of a list cell (2 words in this case) and
$c_2$ is the space on the runtime stack used by one recursive call of
\lstinline{msort} (probably less than 10 words).

Because \lstinline{merge} is not tail-recursive, a merge requires space both for
its two input lists, for its output list, and for temporaries stored on the
stack.  When one of the lists becomes empty, \lstinline{merge} calls
\lstinline{cp}, which allocates less for each iterative call than
\lstinline{merge} does. Each return from \lstinline{merge} allocates a list cell
(two words), so the maximum space usage is reached when the last element of the
result of the merge is constructed (which happens when the recursion is
deepest). Here the space used is (we show $n = 200,000$ list elements as an
example)
\begin{center}
\begin{tabular}{lrr}
{\bf data} & {\bf size (words)} &$n=200,000$\\ \hline
input list& $2n$ & 3,200,000 bytes\\
$l$ & $n$ & 1,600,000 bytes\\
$l$ sorted & $n$ & 1,600,000 bytes\\
$r$ & $n$ & 1,600,000 bytes\\
$r$ sorted & $n$ & 1,600,000 bytes\\
result list & $2n$ & 3,200,000 bytes\\ \hline
total in regions& $8n$ & 12,800,000 bytes
\end{tabular}
\end{center}

It turns out that each iterative call of \lstinline{merge} pushes three
registers on the stack, so that stack size will be approximately $3\times
8\times n$ bytes, which for $n=200,000$ is 4,800,000 bytes, just before the
merged list is constructed, bottom-up. The total space consumption for sorting
200,000 integers should therefore be roughly 14,400,000 bytes (i.e.,
12,800,000-3,200,000+4,800,000).

To check the above analysis, we sorted 200,000 integers with the region profiler
enabled.  As one sees in Figures~\ref{msortregion.fig} and \ref{msortstack.fig},
the space usage found by region profiling correspond well to the results of our
analysis.
\begin{figure}%[t]
\includerp{msortregion.pdf}
\caption{Region profiling of \lstinline{msort} sorting 200,000 integers. The
  high-level mark denotes the maximum amount of memory allocated in regions and
  on the stack. Notice that the amount of memory used in regions and the amount
  of memory used on the stack may not top on the same time, which shows by the
  high-level mark being lower than the sum of the maximum stack usage and the
  maximum memory used in regions.}
\label{msortregion.fig}
\end{figure}

\begin{figure}%[t]
\includerp{msortstack.pdf}
\caption{Stack profiling of \lstinline{msort} sorting 200,000 integers.}
\label{msortstack.fig}
\end{figure}

In Chapter~\ref{storagemodes.sec}, we shall see how one can use resetting of
regions to reduce the space usage drastically, to roughly $2nc_1$.
%
\index{region polymorphism|)}%

%---------------------------------------------------------
\chapter{Value Declarations}
\label{valdecl.sec}
%---------------------------------------------------------

Although region inference is based on types and effects, it is also to some
extent syntax dependent. That is, two programs that are equivalent in their
input-output behavior can easily have very different memory behavior. In this
chapter, we discuss how to write
%
\index{declaration!value}
%
declarations so as to obtain good results with region inference. The region
inference rules that underlie the MLKit with Regions are related to the scope
rules of ML, so we start by a (very informal) summary of the scope rules of ML
declarations.

\section{Syntax}
A Standard ML {\em value declaration} binds a value to a value
%
\index{scope rules|(}
%
variable. For example, the result of evaluating the value declaration
\begin{smlcode}
  val x = 3 + 4
\end{smlcode}
is the
%
\index{environment}
%
environment $\{\kw{x}\mapsto 7\}$. More generally, evaluation of a
value binding \lstinline!val $\id$ = $\exp$! proceeds as follows. Assume
the result of evaluating $\exp$ is a value, $v$.  Then the result of
evaluating \lstinline!val $\id$ = $\exp$! is the environment $\{\id\mapsto
v\}$.

The value declaration is just one form of Core Language declaration (the others
being type and exception declarations). We use $\dec$ to range over
declarations. Declarations can be combined in several ways. For example,
%
\index{declaration!sequential}
%
$$\dec_1\kw{;}\dec_2$$ is a {\em sequential declaration}. The identifiers
declared by this declaration are the identifiers that are declared by $\dec_1$
or $\dec_2$; moreover, identifiers declared in $\dec_1$ may be referenced in
$\dec_2$. The
%
\index{;@\texttt{;}}
%
semicolon is associative. Thus, in a sequence
$\dec_1\kw{;}\ldots\boxml{;}\dec_n$ of declarations, identifiers declared in
$\dec_i$ may be referenced in $\dec_{i+1},\ldots,\dec_n$ ($1\leq i\leq n$).

The Core Language has two forms of
%
\index{declaration!local}%
\index{let@\texttt{let}}%
%
local declarations. The expression
\begin{center}
  \lstinline!let $\dec$ in $\exp$ end!
\end{center}
declares identifiers whose scope does not extend beyond $\exp$. Similarly, the
declaration
%
\index{local@\texttt{local}}
%
\begin{center}
  \lstinline!local $\dec_1$ in $\dec_2$ end!
\end{center}
first declares identifiers (in $\dec_1$) whose scope does not extend beyond
$\dec_2$ and then uses these declarations to perform the declarations in
$\dec_2$. An identifier is declared by the entire local construct if and only if
it is declared by $\dec_2$.

\section{Scope Versus Lifetime}
\label{scope.sec}

Scope
%
\index{lifetime|(}
%
is a syntactic concept: a declaration of an identifier contains a binding
occurrence of the identifier; the scope of the declaration is the part of the
ensuing program text whose free occurrences of that identifier are bound by that
binding occurrence. By contrast, lifetime, as we use the word, is a dynamic
concept. A value is ``live'' if and only if the remainder of the computation
uses it (or part of it). The traditional
%
\index{stack}
%
stack discipline couples these two concepts very closely. For example,
in the pure stack discipline, the evaluation of
\begin{center}
  \lstinline!let $\dec$ in $\exp$ end!
\end{center}
in an environment $E$ proceeds as follows. First evaluate $\dec$ to yield an
environment, $E_1$. Then evaluate $\exp$, in the environment $E$ extended with
$E_1$, to yield value $v$. Then $v$ is the result of evaluating the
\lstinline{let} expression in $E$. In implementation terms: first push an
environment $E_1$ onto the stack, use it to evaluate the expression in the scope
of the declaration, and then pop the stack. That this idea works in
%
\index{block structure}
%
block-structured languages hinges on a number of carefully made language design
decisions. In functional and object-oriented languages, memory cannot be managed
that simply. The problem is that while environments can be managed in a
stack-like manner, the values in the range of the environment cannot (unless one
uses regions, that is). For example consider the ML expression:
\begin{smlcode}
  local
     val private = [2,3,5,7,11,13]
  in
     fun smallPrime (n:int) : bool = List.member n private
  end
\end{smlcode}

Although the scope of the declaration is only the declaration of
%
\index{smallPrime@\texttt{smallPrime}}
%
\kw{smallPrime}, \lstinline{private} is accessed (at runtime) whenever
\lstinline{smallPrime} is called.  Thus, the lifetime of the list of small
primes is at least as long as the lifetime of the \lstinline{smallPrime}
function itself.

The region discipline still has a coupling between scope and lifetimes, but,
because we want to be able to handle recursive data types and higher-order
functions, the coupling is less tight.  The ground rule of region inference
%
\index{region inference!ground rule}%
\index{let region@\texttt{let region}}%
%
is that as long as a value variable is in scope, the value bound to it at
runtime will remain allocated. More precisely:
\begin{quote}
  Ground Rule: The region rules forbid transforming an expression $\exp$ into
  \lstinline!let region $\rho$ in $\exp$ end! if $\exp$ is in the scope of an
  identifier that has $\rho$ free in its region-annotated type scheme with
  place.
\end{quote}
For an example, consider
\begin{smlcode}
  let
     val list = [1,2,3]
     val n = length list
     val r = sin(real n)
  in
     cos(r)
  end
\end{smlcode}
At runtime, the list bound to \lstinline{list} is not used (i.e., it is not
live) after its length has been computed; similarly, the value of \lstinline{n}
is not live after it has been converted to a floating point number, and so
on. In short, at runtime, we have a sequence of short, non-overlapping
lifetimes.

With region inference, however, the list bound to \lstinline{list} will stay
allocated throughout the evaluation of the remainder of the \lstinline{let}
expression.\footnote{One can force de-allocation of the list by inserting
\lstinline!val _ = resetRegions(list)! after the declaration of \lstinline{n};
but, as we shall see, there are less draconian ways of achieving the same
result.}

For a more interesting example of the consequences of the Ground Rule, consider
the following declarations, taken from a program that computes prime numbers
using the
%
\index{Sieve of Eratosthenes}
%
Sieve of Eratosthenes:
\begin{smlcode}
  fun cp [] = []
    | cp (x::xs) = x :: cp xs

  fun sift (n, []) = []
    | sift (n, (x::xs)) = if x mod n = 0 then sift(n,xs)
                          else x::sift(n,xs)
  fun sieve (a as ([], p)) = a
    | sieve (x::xs, p) = let val rest = sift(x,xs)
                         in sieve(cp rest,x::p)
                         end
\end{smlcode}
Here \lstinline{sift(n, l)} produces a list of the numbers from \lstinline{l}
that are not divisible by \lstinline{n}; \lstinline{sieve(xs, p)} repeatedly
calls \lstinline{sift}, adding primes to the front of \lstinline{p}, until the
list of numbers remaining in the sieve becomes empty. The programmer has
employed the copying technique suggested in Section~\ref{life.sec} to avoid that
the lists that are bound to \lstinline{rest} during the repeated filtering all
are put in the same region. The programmer's intention is that the \lstinline{cp rest}
should overwrite \lstinline{x::xs} by a copy of \lstinline{rest}, so that
space consumption would be bounded by a constant times the size of the input.
But it does not work as intended; because \lstinline{rest} is in scope at the
recursive application of \lstinline{sieve}, the list that is bound to
\lstinline{rest} will stay allocated for the duration of that call, which is in
fact the remainder of the entire computation!

In many cases, the solution is simply to shorten the scope of the declaration.
In the above example, a good solution is to move the application of
\lstinline{sieve} outside the \lstinline{let}:
\begin{smlcode}
  fun sieve (a as ([], p)) = a
    | sieve (x::xs, p) =
          sieve let val rest = sift(x,xs)
                in (cp rest,x::p)
                end
\end{smlcode}

That the copying really overwrites the input list relies, in part, on region
resetting (Chapter~\ref{storagemodes.sec}).  But it also relies on region
polymorphism and on the Ground Rule.  Rewriting the application of
\lstinline{sieve} ensures that the list bound to \lstinline{rest} will not live
to see the recursive call of \lstinline{sieve}.  Unless forced by context to do
otherwise, \lstinline{sift} will create a list using fresh regions. Because
\lstinline{cp} is also
%
\index{region exomorphism}
%
exomorphic, there will be no sharing between \lstinline{rest} and the other
lists. The region variable that denotes the region that holds the auxiliary
pairs of \lstinline{rest} appears in the effect of the (revised) \lstinline{let}
expression. However, this region variable does not occur free in the
region-annotated type scheme with place of any value variable in scope at that
point, not even in the region-annotated type scheme with place of
\lstinline{sieve}, which only has the region that contains \lstinline{sieve}
itself free in its region-annotated type scheme with place.  Consequently,
region inference wraps the \lstinline{let} expression by a \lstinline{region}
declaration of the region variable in question:
\begin{smlcode}
  fun sieve (a as ([], p)) = a
    | sieve (x::xs, p) =
        sieve let region r10
                  val rest = sift[r10](x,xs)
              in (cp rest,x::p)
              end
\end{smlcode}

\section{Shortening Lifetime}
Informally, region inference forces the lifetime of an identifier to be at least
its scope. Improving memory performance therefore sometimes requires making
scopes of identifiers smaller.  Useful
%
\index{program transformation}%
\index{lifetime|)}%
\index{lifetime!shortening}%
%
program transformations include:

\subsubsection*{Inwards let floating}
\begin{quote}
\index{let floating}%
Transform
\begin{center}
  \lstinline!let val $\id_1$ = $\exp_1$ val $\id_2$ = $\exp_2$ in $\exp$ end!
\end{center}
into
\begin{center}
  \lstinline!let val $\id_2$ = let val $\id_1$ = $\exp_1$ in $\exp_2$ end in $\exp$ end!
\end{center}
provided $\id_1$ does not occur free in $\exp$.
\end{quote}

\subsubsection*{Application extrusion:}
\begin{quote}
  \index{application extrusion}
  %
  Transform
  \begin{center}
    \lstinline!let $\dec$ in $f$($\exp$) end!
  \end{center}
  into
  \begin{center}
    \lstinline!$f$ let $\dec$ in $\exp$ end!
  \end{center}
provided $f$ is an identifier that is not declared by $\dec$.
\end{quote}

Application extrusion is particularly useful in connection with
%
\index{tail recursion}
%
tail recursion; the reader will see it employed several times in what follows.
%
\index{scope rules|)}

%---------------------------------------------------------
\chapter{Static Detection of Space Leaks}
\label{spaceleak.sec}
%---------------------------------------------------------

``Space leak'' is the informal term used when a program uses much more memory
than one would expect, typically because of memory not being re-cycled as early
as it could (or not at all).

If a region-polymorphic function with region-annotated type scheme $\sigma$ has
a $\Put$ effect on a region variable that is not amongst the bound region
variables of $\sigma$, then one quite possibly has a space leak; every
application of the function may write values into a region that is the same for
all calls of the function. For example, consider the source
program\footnote{Program \boxml{kitdemo/escape.sml}.}
\begin{smlcode}
  fun g () =
    let val x = [5,7]
        fun f y = (if y>3 then x@x else x;
                   5)
    in
      f 1; f 4
    end
\end{smlcode}
Here \lstinline{f} has type $\kw{int}\to\kw{int}$; yet, when the expression
\lstinline{y>3} evaluates to \lstinline{true}, an append operation is performed
that produces a list in the same region as \lstinline{x}. The first call of
\lstinline{f} will not cause the append operation to be called, but the second
one will. One can say that \lstinline{f} has a space leak in that it can write
values into a more global region, namely a region that is allocated at the
beginning of the body of \lstinline{g}. The sequence of calls to \lstinline{f}
accumulates copies of \lstinline{x@x} in that region, although none of these
lists are accessible anywhere.  In this particular case, the values are not even
part of the result type of \lstinline{f}, so the writing is a side-effect at the
implementation level, even though there are no references in the program.

The region-annotated type scheme inferred for \lstinline{f} is
$$\forall\epsilon.\kw{int} \ar{\epsilon.\{\Put(\rho_{11})\}} \kw{int}$$ where
the region-annotated type of \kw{x} is
$$(\kw{int},[\rho_{11}])\kw{list}$$ Here we see that $\rho_{11}$ is free in the
region-annotated type scheme and appears with a $\Put$ effect.

\section{Warnings About Space Leaks}
The MLKit can be instrumented to issue a warning each time it meets a function
that is declared using \lstinline{fun} and has a free $\Put$ effect occurring
somewhere in its type scheme. The way to tell the MLKit to issue the warnings is
by passing the option
%
\index{put-effect!escaping}
%
\inline{-warn_on_escaping_puts} to the MLKit compiler. In practice, this warning
mechanism is a valuable device for predicting space leaks.  The region-annotated
version of our example function \lstinline{g} is listed in
Figure~\ref{escape_mulexp.fig}. During compilation of \lstinline{g}, the MLKit issues
the following warning:\footnote{To provoke the warning, one has to disable
in-lining in the
%
\index{optimiser}
%
{\Lam} optimiser; this is done by passing the option
\inline{-maximum_inline_size 0} (or \inline{-max_inl_sz 0}) to the MLKit
compiler together with the option \inline{-warn_on_escaping_puts}.}
\begin{figure}
\hrule
\medskip
\begin{smlcode}
   let fun g at r1 () =
           let region r11:INF;
               val x = [5,7] at r11;
               region r21:1;
               fun f at r21 y =
                   let val _ = case y > 3 of
                                 true => @[r11] (x, x)
                               | _ => x
                   in  5
                   end;
               val _ = f 1
           in  f 4
           end
   in  {|g: (_,r1)|}
   end
\end{smlcode}
\caption{The region-annotated version of \lstinline{g}.}
\medskip
\hrule
\label{escape_mulexp.fig}
\end{figure}
\begin{small}
\begin{scriptcode}
 *** Warnings ***
f has a type scheme with escaping put effects on region(s):
r11, which is also free in the type schemes with places of :  x
\end{scriptcode}
\end{small}
We are told that the program might space leak in region \lstinline{r11}.
Looking at the function \lstinline{f}, we see that this region is an actual
region parameter to \lstinline{@}. It follows that the problem is the call to
\lstinline{@}.

\section{Fixing Space Leaks}
Often one can fix a space leak by delaying the creation of the value that causes
the space leak. In the above example, we can move the construction of the list
into \lstinline{f}:\footnote{Program \boxml{kitdemo/escape1.sml}.}
\begin{smlcode}
fun g () =
    let fun mk_x () = [5,7]
        fun f y = let val x = mk_x()
                  in if y>3 then x@x else x; 5
                  end
    in f 1; f 4
    end
\end{smlcode}
Of course, this means that the list will be reconstructed upon each
application of \lstinline{f}. Another solution is to move the creation of
the list as close to the calls as possible and then pass the list as
an extra argument:\footnote{Program \boxml{kitdemo/escape2.sml}.}
\begin{smlcode}
fun g () =
    let fun f (x,y) = (if y>3 then x@x else x; 5)
    in let val x = [5,7]
       in f(x, 1); f(x, 4)
       end
    end
\end{smlcode}
Both solutions stop warnings from being printed, but the second solution is
better than the first: \lstinline{f} still has a $\Put$ effect on the regions
containing \lstinline{x}, but the difference is that these are now represented
by bound region variables in the type scheme of \lstinline{f}. This
quantification has the advantages that (1) allocation of space for the list is
delayed until the list is actually used and (2), the list can be de-allocated
after the calls have been made (whereas in the original version, \lstinline{x}
occurs free in the declaration of \lstinline{f} and will be kept alive as long
as \lstinline{f} can be called.)

At other times, there is no clean way of avoiding escaping $\Put$ effects.  One
example is found in the
%
\index{TextIO@\texttt{TextIO}}%
\index{openIn@\texttt{openIn}}%
\index{openOut@\texttt{openOut}}%
%
\lstinline{TextIO} structure of the Basis Library:
\begin{smlcode}
  exception CannotOpen
  fun raiseIo fcn nam exn =
    raise IO.Io {function = fcn^"", name = nam^"", cause = exn}

  fun openIn (f: string) : instream =
    {ic=prim("openInStream", (f,CannotOpen)),
     name=f} handle exn => raiseIo "openIn" f exn

  fun openOut(f: string): outstream =
    {oc=prim("openOutStream", (f,CannotOpen)),
     name=f} handle exn => raiseIo "openOut" f exn
\end{smlcode}
As explained in Chapter~\ref{exceptions.sec}, when a unary exception constructor
is applied to a value, both the argument value and the resulting constructed
value are forced into a particular global region. Thus, the application
\begin{center}
  \lstinline!IO.Io {function = fcn^"", name = nam^"", cause = exn}!
\end{center}
has a potential space leak in it; every time we apply the exception constructor,
the resulting exception value will be put into a global region. This particular
space leak is perhaps not something that would keep one awake at night, because
most programs do not make a large number of failed attempts to open files, but
it is useful to be warned about this potential problem.  Notice, however, that
the string arguments to \lstinline{raiseIo} are copied inside the body of
\lstinline{raiseIo}, so that they are not forced to be placed in the global
string region.

%---------------------------------------------------------
\chapter{References}
\label{refs.sec}
%---------------------------------------------------------
Section~\ref{refbasics.sec} gives a brief summary of references in Standard ML;
it may be skipped by readers who know SML.  Thereafter, we discuss runtime
representation of references and region-annotated reference types.

\section{References in Standard ML}
\label{refbasics.sec}

A reference is a memory address (pointer).  Standard ML has three
built-in operations on
%
\index{reference}
%
references
%
\index{ref@\texttt{ref}}%
\index{"!@\texttt{"!}}%
\index{:=@\texttt{:=}}%
\medskip

\[
\begin{array}{lcll}
\kw{ref} & \mapsto & \forall\alpha.\alpha\to\alpha\,\REF & \mbox{create reference} \\
\kw{!}   & \mapsto & \forall\alpha.\alpha\,\REF\to\alpha & \mbox{de-referencing} \\
\kw{:=}  & \mapsto & \forall\alpha.\alpha\,\REF\ast\alpha\to\UNIT & \mbox{assignment}
\end{array}
\]
\medskip

\noindent
If the type of a reference $r$ is $\tau\,\REF$ then one can store values of type
$\tau$ (only) at address $r$.  A reference is a value and can therefore be bound
to a value identifier by a \lstinline{val} declaration. While the value stored
at a reference may change, the binding between variable and reference does not
change. We show an example, because this point can be confusing to programmers
who are familiar with mutable variables in languages like C and Pascal:
\begin{smlcode}
  val it =
    let val x : int ref = ref 3
        val y : bool ref = ref true
        val z : int ref = if !y then x else ref 5
    in z:= 6; !x
    end
\end{smlcode}
Because \lstinline{!y} evaluates to true, \lstinline{z} becomes bound to the
same reference ($r$) as \lstinline{x}.  So, the subsequent assignment to
\lstinline{z} changes the contents of the store at address $r$ to contain 6.
Because \lstinline{x} and \lstinline{z} are aliases, the result of the
\lstinline{let} expression is the contents of the store at address $r$ (i.e.,
6).

\section{Runtime Representation of References}
The MLKit translates an SML expression of the form $\kw{ref}~\exp$ into an
expression of the form (assuming $\exp$ translates into $e$)
$$\kw{ref}\,\at\,\rho~ e$$ which is evaluated as follows. First $e$ is
evaluated. Assume that this evaluation yields a value $v$. Here $v$ may be a
%
\index{boxing}%
%
boxed or an unboxed value.  Next, a 64-bit word is allocated in the region
denoted by $\rho$; let $r$ be the address of this word. Then $v$ is stored at
address $r$ and $r$ is the result of the evaluation.

\begin{figure}
\hrule
\begin{center}
\begin{picture}(50,20)
\put(8,5){\hbox{$\ldots$}}
\put(20,5){\framebox(20,10){$v$}}
\put(15,8){\hbox{$r:$}}
\put(25,0){\kw{r35}}
\put(8,0){\kw{r34}}
\put(45,0){\kw{r36}}
\put(45,5){\hbox{$\ldots$}}
\end{picture}
\end{center}
\caption{Creating a reference allocates one word in a region on the region
  stack. Here, the region is drawn as a finite region, but it could equally well
  be infinite.}
\label{refsv.fig}
\medskip
\hrule
\end{figure}


The situation is depicted in Figure~\ref{refsv.fig}. The value $v$ can be
unboxed as shown in Figure~\ref{refs.fig}. Or it may be boxed, in which case $v$
is an address.

Notice that a reference really is a pointer in the implementation.  In
particular, a reference is not tagged, so the register allocator may choose to
store a particular reference in a register. The content of the reference is also
always one word, either an unboxed value (e.g., an integer or a boolean) or a
pointer (if the content is boxed).  So the content of a reference is not tagged
either.

De-referencing a reference $r$ is done by reading the content of the memory
location $r$.  Notice that de-referencing does not require knowledge of what
region the word with address $r$ resides in.

Assigning a value $v$ to a reference $r$ simply stores $v$ in the memory at
address $r$. When $v$ is an unboxed value, the assignment can be regarded as
copying $v$ into the memory cell $r$; otherwise $v$ is a pointer, which the
assignment stores in the memory cell $r$.  Either way, assignment is a
constant-time operation.

\section{Region-Annotated Reference Types}

The general
%
\index{type!region-annotated}%
%
form of a region-annotated reference type is:
$$(\mu\,\REF,\rho)$$ Informally, a reference $r$ has this type if it is the
address of a word in the region denoted by $\rho$ and, moreover, $\mu$ is the
region-annotated type with place of the contents of that word.  For example,
assume $\rho$ is bound to some region name, say \kw{r35}; then the evaluation of
the declaration ~\lstinline!val x = ref at $\rho$ 3! results in the environment
$\{\kw{x}\mapsto r\}$, where $r$ is the address of a word with contents 3
residing in region \kw{r35}, see Figure~\ref{refs.fig}.  The type of the
variable \kw{x} is \lstinline!(int ref, $\rho$)!.

\begin{figure}
\hrule
\begin{center}
\begin{picture}(50,20)
\put(8,5){\hbox{$\ldots$}}
\put(20,5){\framebox(20,10){\kw{3}}}
\put(15,8){\hbox{$r:$}}
\put(25,0){\kw{r35}}
\put(8,0){\kw{r34}}
\put(45,0){\kw{r36}}
\put(45,5){\hbox{$\ldots$}}
\end{picture}
\end{center}
\caption{Creating a reference allocates one word in a region on the region
  stack. Here, the region is drawn as a finite region, but it could equally well
  be infinite.}
\label{refs.fig}
\medskip
\hrule
\end{figure}

References are treated like all other values by region inference.  The
region-annotated type schemes given to the three built-in operations are:

\[
\begin{array}{lcl}
\kw{ref} & \mapsto & \forall\alpha\rho\epsilon.\alpha \ar{\epsilon.\{\Put(\rho)\}}(\alpha~\REF,\rho)\\
\kw{!}   & \mapsto & \forall\alpha\rho\epsilon.(\alpha~\REF,\rho)\ar{\epsilon.\{\Get(\rho)\}} \alpha \\
\kw{:=}  & \mapsto & \forall\alpha\rho\epsilon.[(\alpha~\REF,\rho), \alpha] \ar{\epsilon.\{\Get(\rho)\}} \UNIT
\end{array}
\]

\noindent
The type scheme for \kw{:=} has in it a $\Get$ effect on the region holding the
reference. Although the operator does not actually read the value, the presence
of the value is necessary for it to be updated.  Assigning a value $v$ to a
reference $r$ does not make a copy of $v$ (unless $v$ is unboxed). Instead,
\kw{:=} updates the content of the reference $r$ to point to $v$.

The advantage of the chosen scheme for handling references is that reference
creation, de-referencing, and assignment all are constant-time operations. The
disadvantage is that if two values may be assigned to the same reference, then
they are forced to be in the same regions (cf. the region-annotated type schemes
given above).

If we compile the example from Section~\ref{refbasics.sec}, we get the program
shown in Figure~\ref{otherrefs.fig}.\footnote{Program \boxml{kitdemo/refs3.sml}.}
\begin{figure}
\hrule
\medskip
\begin{smlcode}
   let val it =
         let region r9:INF;
             val x = ref at r9 3;
             region r11:1;
             val y = ref at r11 true;
             val z = case !y of true => x | _ => ref at r9 5;
             val _ = z := 6
         in  !x
         end
   in  {|it: _|}
   end
\end{smlcode}
\caption{Region-annotated reference creation.}
\label{otherrefs.fig}
\medskip
\hrule
\end{figure}
The region denoted by \kw{r9} contains the memory word whose address is bound to
\kw{x} and \kw{z}, and whose contents is first 3, then 6.  The region denoted by
\kw{r11} contains a single boolean.  Also notice that the word containing 5 is
designated \kw{r9}, because the \lstinline{then} and \lstinline{else} branches
must be given the same region-annotated type with place. Finally, notice that
all references will be reclaimed automatically at the end of the \lstinline{let}
construct that bind \kw{r9} and \kw{r11}.

\section{Local References}

References
%
\index{reference!local}%
%
that are created locally within a function and that do not escape the function
naturally reside in regions that are local to the function body.  For example,
the declaration:\footnote{Program \boxml{kitdemo/refs1.sml}.}
\begin{smlcode}
  fun id x = let val r = ref x in ! r end
\end{smlcode}
is compiled into
\begin{smlcode}
  let fun id at r1 x =
          let region r11:1 in !(ref at r11 x) end
  in  {|id: (_,r1)|}
  end
\end{smlcode}
Here \kw{r11} will be implemented as one word on the runtime stack.  The
evaluation of \lstinline!ref at r11 x! moves the argument \kw{x} to that word on
the stack. At the end of the inner \lstinline{let}-scope, the word (i.e., region
\kw{r11}) is popped off the stack.

Now, let us turn to an example of a memory cell whose lifetime extends the scope
of its declaration, because it is accessible via a function (in Algol
terminology, the reference is an {\em own variable}
%
\index{variable!own}%
%
of the function.)\footnote{Program \boxml{kitdemo/refs2.sml}.}
\begin{smlcode}
  local
    val r = ref ([]:string list)
  in
    fun memo_id x = (r:= x:: !r; x)
  end
  val y = memo_id "abc"
  val z = memo_id "efg";
\end{smlcode}
Provided that in-lining by the optimiser is restricted to in-line only those
functions that are applied once,\footnote{To restrict the optimiser accordingly,
provide the option \inline{-maximum_inline_size 0} (or \inline{-max_inl_sz 0})
to the MLKit compiler.} this example compiles into
\begin{smlcode}
  let val r = ref at r6 nil;
      fun memo_id at r1 x =
          let val _ = := (r, :: (x, ! r)at r4) in x end;
      val y = memo_id "abc";
      val z = memo_id "efg"
  in  {|memo_id: (_,r1), y: (_,r3), z: (_,r3)|}
  end
\end{smlcode}
and the MLKit warns us that there is a possible space leak:\footnote{Warnings
are printed only if the option \inline{-warn_on_escaping_puts} is passed to the
MLKit compiler along with the option \inline{-max_inl_sz 0}. See
Chapter~\ref{spaceleak.sec}.}
\begin{scriptcode}
 *** Warnings ***
memo_id  has a type scheme with escaping put effects on region(s):
r4, which is also free in the type schemes with places of :  r
\end{scriptcode}

\section{Hints on Programming  with References}

There is no need to shy away from using references when programming with
regions. However, one needs to be aware of the restriction that values that may
be assigned to the same references are forced to live in the same region, and
that this region with all its values will be alive for as long as the reference
is live. If the contents type is unboxed (e.g., \kw{int}), there is no problem,
for in that case, no region for the contents is allocated. But one should avoid
creating long-lived references that are assigned many different large values.

%---------------------------------------------------------
\chapter{Recursive Data Types}
\label{datatypes.sec}
%---------------------------------------------------------
This chapter describes how the MLKit treats recursive data types. We have
already seen how one recursive datatype, namely lists, is handled. This chapter
deals with the general case.

\section{Spreading Data Types}

The MLKit performs an analysis called
%
\index{spreading}%
%
``spreading of data types''.  Spreading of datatypes analyses
\lstinline{datatype} declarations.  This analysis of a \lstinline{datatype}
declaration uses information about the type constructors that appear in the
types of the constructors of the data type(s) introduced by the declaration, but
it does not use information about the use of the data type.

Spreading determines (a) a so-called
%
\index{arity}%
%
arity of every type name that the data type declaration introduces and (b) a
region-annotated type scheme for every value constructor introduced by the data
type declaration.

In the Definition of Standard ML every type name has an attribute, called its
arity \cite[page 15]{mthm97}. The arity of a type name is the number of type
arguments it requires. For example, \kw{int} has arity 0 while the type name
introduced by the following declaration of binary trees has arity 1:
%
\index{tree@\texttt{tree}}%
\index{tree!binary}%
\index{Lf@\texttt{Lf}}%
\index{Br@\texttt{Br}}%
\index{datatype@\texttt{datatype}}%
%
\begin{smlcode}
  datatype 'a tree = Lf | Br of 'a * 'a tree * 'a tree;
\end{smlcode}

The MLKit extends the notion of arity (in it's internal languages) to account
for regions and effects. For lists, for example, we need a region for holding
the pairs to which \kw{::} is applied. For the type
\begin{smlcode}
  datatype 'a foo = A | B of ('a * 'a) * ('a * 'a)
\end{smlcode}
the type of \kw{B} introduces the possibility of three region variables (one for
each star). Region variables that are induced by the types of constructors and
that do not hold the constructed values themselves are called
%
\index{region variable!auxiliary}%
%
{\em auxiliary region variables}. For example, the \kw{list} type
\begin{smlcode}
  datatype 'a list = nil | op :: of 'a * 'a list
\end{smlcode}
has one auxiliary region variable, namely the region variable that describes
where the pairs of type \lstinline{'a * 'a list} (i.e., the auxiliary
%
\index{pair!auxiliary}%
%
pairs), reside.

Besides auxiliary regions, one sometimes needs auxiliary effects.  For an
example, consider the type declaration
\begin{smlcode}
  datatype V = N of int | F of V -> V
\end{smlcode}
Here one needs an arrow effect for the function type \lstinline{V -> V}.  We
refer to such an arrow effect as an
%
\index{arrow effect!auxiliary}%
%
{\em auxiliary arrow effect} of the data type in question.

We define the \emph{(internal) arity} of a type name $t$ to be a triple
$(n,k,m)$ of non-negative integers, where $n$ is the usual Standard ML
arity of the type name, $k$ is the
%
\index{region arity}%
%
\emph{region arity} of $t$, and $m$ is the
%
\index{effect arity}%
%
\emph{effect arity} of $t$. The region and effect arities indicate the number of
auxiliary regions and arrow effects of the data type, respectively.

For efficiency purposes, we have found it prudent to restrict the maximal number
of auxiliary regions a data type can have to one for each kind of runtime type
of regions and to restrict the maximal number of auxiliary effects to 1.
Otherwise, the number of auxiliary regions can grow exponentially in the size of
the program:
\begin{smlcode}
  datatype t0 = C
  datatype t1 = C1 of t0 * t0
  datatype t2 = C2 of t1 * t1
  ...
\end{smlcode}
Here the number of auxiliary region variables would double for each new data
type declaration.  Furthermore, all type names introduced by a
\lstinline{datatype} declaration are given the same arity (a
\lstinline{datatype} declaration can declare several types simultaneously).

Because of the limit on the number of auxiliary region variables, spreading of
data type declarations sometimes unifies two auxiliary region variables that
would otherwise be distinct; but it only unifies auxiliary region variables that
have the same runtime type. The practical consequence of these restrictions is
that applying a constructor to a value $v$ sometimes forces identification of
regions of $v$ that hold otherwise unrelated parts of $v$.

The automatic memory management that we have discussed for lists extends to
other recursive data types without problems. For example, binary trees are put
into regions and are subsequently de-allocated (in a constant time operation)
when the region is popped. The next section goes through an example to
illustrate the point.

The MLKit attempts to use an unboxed representation for value constructors when
possible. We have already seen how cons (i.e., \lstinline{::}) and
\lstinline{nil} use an unboxed representation (Chapter~\ref{lists.sec}). The
MLKit uses an advanced scheme for
%
\index{unboxing}%
%
unboxing that uses both the unused least significant bits and the unused most
significant bits of pointer-values for tagging constructors
\cite{10.1145/3674628}. Section~\ref{unboxing.sec} documents this scheme and
describes how the programmer can learn about MLKit's unboxing decisions. Before
presenting unboxing scheme in details, we first give an example of a tree
\lstinline{datatype} declaration for which MLKit will use an unboxed
representation that utilises the unused least-significant bits of pointer values
for storing constructor tags.

\section{Example: Balanced Trees}
Consider the program in Figure~\ref{balpre.fig}.\footnote{MLB-file:
  \boxml{kitdemo/trees.mlb}, file \boxml{kitdemo/trees.sml}.}
\begin{figure}
\hrule
\medskip
\begin{smlcode}
  datatype 'a tree = Lf | Br of 'a * 'a tree * 'a tree

  (* preorder traversal of tree *)
  fun preord (Lf, xs) = xs
    | preord (Br(x,t1,t2),xs) =
        x::preord(t1,preord(t2,xs))

  (* building a balanced binary tree from a list *)
  fun balpre [] = Lf
    | balpre (x::xs) =
       let val k = length xs div 2
       in Br(x, balpre(take(xs, k)),
                balpre(drop(xs, k)))
       end

  (* preord o balpre is the identity *)
  val it = print(implode(preord(balpre(explode
      "Greetings from the MLKit\n"),[])));
\end{smlcode}
\caption{Example showing recycling of memory used for an intermediate data
  structure. The function \kw{balpre} builds a balanced binary tree from a list
  and \kw{preord} then flattens the tree to a list (after which the tree is
  garbage).}
\medskip \hrule
\label{balpre.fig}
\end{figure}
We would hope that the balanced tree produced by \kw{balpre} is
removed after it has been collapsed into a list by \kw{preord}.  And
indeed it is. Here is the proof:
\begin{smlcode}
  val it =
    let region r125:INF
    in  print
        let region r127:INF
        in  implode[r125]
            let region r131:INF
            in  preord[r127]
                (let region r135:INF
                 in  balpre[r131]
                     let region r139:1
                     in  explode[r135] "Greetings from the Kit\n"
                     end
                 end,
                 nil
                )
            end
        end
    end
\end{smlcode}
The exomorphic behavior of \kw{balpre} causes the tree to be allocated in region
\kw{r131}, which is de-allocated after the call to \kw{preord}.

This is the kind of certainty about lifetimes we are aiming at.  Imagine, for
example, that the trees under consideration were terms representing different
intermediate forms in a compiler. Then one would like to know that (possibly
large) syntax trees are not kept in memory longer than needed.

\section{Unboxing Schemes}
\label{unboxing.sec}

\index{unboxing}%
\index{value!unboxed}%

The MLKit uses a uniform representation of values, which is important for
compiling generic code (e.g., functions) separately from the code that uses
it. Still, under these constraints there are many possibilities for securing a
compact data representation. The MLKit uses tagged regions for some types of
values (instead of tagging the values themselves) and, as we have seen for lists
and binary trees, datatypes with a single unary constructor that takes boxed
arguments are implemented using the lower-bit tags in pointers to discriminate
between the constructors.

MLKit does not stop here.
%
\index{bit stealing}%
%
It tries hard to represent data type constructors unboxed by utilising
(otherwise) non-used bits in pointer-values. On most modern architectures,
pointers are aligned to point only at word-addresses, which leaves the three
least-significant bits unused and which allows MLKit to represent lists and
trees unboxed, as we have seen earlier. Moreover, only the least 48 bits are
used for representing pointers; the remaining 16 most-significant bits are
unused on modern 64-bit architectures.

When we have a datatype $t$ with $u$ unary constructors and $n$ nullary
constructors, if $0 \leq u < 2^{16}$ and if all arguments to the unary
constructors are known to be boxed (or not using the most-significant bits), we
can represent the type $t$ unboxed, using the high bits for tagging. If $u = 0$,
we call the type $t$ an
%
\index{enum-unboxed}%
\index{unboxing!enum}%
%
\emph{enum-unboxed} type. We call the type $t$ a
%
\index{low-unboxed}%
\index{unboxing!low}%
%
\emph{low-unboxed} type if $u = 1$ and the argument to the unary constructor is
boxed, and a
%
\index{high-unboxed}%
\index{unboxing!high}%
%
\emph{high-unboxed} type if $u > 1$ and if all arguments to the unary
constructors are known to be boxed. In the worst case, when none of the above
conditions are satisfied, MLKit uses a boxed representation of the datatype
$t$. When $t$ is a high-unboxed type, we use the 16 most significant bits to
discriminate between the unary and nullary constructors (for GC safety, MLKit
also sets the least significant bit for the nullary constructors). MLKit uses an
iterative algorithm to determine the boxity for mutually recursive
\lstinline{datatype} declarations, which also include data types with a single
unary constructor. For simplicity of region inference, region inference assumes
that, for mutually recursive \lstinline{datatype} declarations, either all the
declared types are unboxed or they are all boxed.

As an example, MLKit implements the following datatype as a high-unboxed
type:\footnote{Program \boxml{kitdemo/high-unb.sml}.}

\begin{smlcode}
  datatype t = Leaf of string | Empty | Children of t list
\end{smlcode}

\noindent
MLKit recognises that the arguments to $t$'s unary constructors are either boxed
or use only lower bits for tagging (i.e., \kw{t list}). The higher bits are thus
available for discriminating between the three constructor values. We can get
MLKit to report on boxing decisions by passing the compile-time flag
\kw{-report\_boxities}:
\begin{scriptcode}
  $ mlkit -no_gc -report_unboxing high-unb.sml | grep Boxities
  *** Boxities: [t:hub]
\end{scriptcode}

\noindent
Indeed, MLKit reports that it has decided for \kw{t} to be high-unboxed.

More formally, MLKit distinguishes between the following \emph{boxities}
($\kappa$):
%
\index{unboxing!boxity}%
\index{boxity}%

\[
\begin{array}{lclp{8cm}}
  \kappa & ::= & \kw{lub} & low-unboxed \\
         & |   & \kw{hub} & high-unboxed \\
         & |   & \kw{box} & boxed \\
         & |   & \kw{enum} & enumeration (only nullary-constructors) \\
         & |   & \kw{single}~\kappa & single unary-constructor datatype
\end{array}
\]

\noindent
When MLKit analyses a set of simultaneously declared data types, it
starts with an optimistic guess for each type and checks if the guess is valid
according to a series of rules:

\begin{enumerate}
\item No unary constructor of a type with boxity \kw{hub} can take a value as
  argument that uses the upper (i.e., most significant) 16 bits.
\item No type with boxity \kw{lub} can have more than one unary constructor. We
  admit here that MLKit could relax this condition and allow up to four unary
  constructors.
\item Unary constructors of types with boxity \kw{lub} must take boxed
  arguments.
\end{enumerate}

\noindent
If a rule is violated, an attempt is made with less optimistic assumptions.

Many types may be implemented unboxed using this scheme, including data types
for representing grammars, datatypes for representing union-find structures, and
data types representing finite maps, such as patricia trees
\cite{10.1145/3674628}.

To obtain good boxity decisions, it may sometimes be beneficial for a programmer
to make sure that an argument to a constructor is indeed boxed. Consider the
following mutually recursive \lstinline{datatype} declaration:\footnote{Program
\boxml{kitdemo/expdec.sml}.}
\begin{smlcode}
  datatype exp = LET of dec * exp | ADD of exp * exp | INT of int
       and dec = VALBIND of string * exp
\end{smlcode}

\noindent
MLKit reports the following boxity decisions:
\begin{scriptcode}
  $ mlkit -no_gc -report_boxities expdec.sml | grep Boxities
  *** Boxities: [exp:box,dec:box]
\end{scriptcode}

\noindent
We see that both \kw{exp} and \kw{dec} are represented boxed, which means that
not only will the arguments to \kw{LET}, \kw{ADD}, and \kw{VALBIND} be
represented boxed in designated regions, each value of the \kw{exp} and \kw{dec}
types will be represented as a pointer to two region-allocated words, one word
for storing the constructor tag and one word holding a pointer to the
constructor argument (in the case of the \kw{INT} constructor, the argument will
be unboxed).

If instead, we arrange that the argument to the \kw{INT} constructor is boxed,
the algorithm will determine that \kw{exp} is high-unboxed and \kw{dec} has
boxity \kw{single box}.\footnote{Program \boxml{kitdemo/expdec2.sml}.} For
arranging that the argument to the \kw{INT} constructor is boxed, we enclose the
integer in a singleton record (\lstinline!INT of {value:int}!), which MLKit
will always represent boxed:

\begin{scriptcode}
  $ mlkit -no_gc -report_boxities expdec2.sml | grep Boxities
  *** Boxities: [exp:hub,dec:single box]
\end{scriptcode}

We see that now \kw{exp} is represented unboxed and \kw{dec} is represented
unboxed and without storing constructor tags at all!

%---------------------------------------------------------
\chapter{Exceptions}
\label{exceptions.sec}\index{exception}
%---------------------------------------------------------

Standard ML
%
\index{exception}%
\index{exception constructor}%
%
exception constructors are introduced by
%
\index{exception declaration}%
\index{exception@\texttt{exception}}%
%
{\em exception declarations}. The two most basic forms are
\begin{center}
  \lstinline!exception $\mathit{excon}$!
\end{center}
and
\begin{center}
  \lstinline!exception $\mathit{excon}$ of $\mathit{ty}$!
\end{center}
for introducing nullary and unary exception constructors, respectively.
%Unary exception constructors are typically
%used when one wants to raise an exception that contains a
%reason (represented by a value of type {\it ty}).

Exception declarations need not occur at top level. For example, a function body
may contain exception declarations.

\section{Exception Names}
Each evaluation of an exception declaration creates a fresh
%
\index{exception!generative}%
\index{exception name}%
%
{\em exception name\/} and binds it to the exception constructor. This is
sometimes referred to as the {\em generative\/} nature of Standard ML
exceptions.

MLKit implements an exception name as a pointer to a pair
consisting of an integer and a string pointer; the string pointer
points to the name of the exception, which is a global constant in the
target program. The string is used for printing the name of the
exception if it ever propagates to top level. The memory cost of
creating the pair is, as always with pairs, two words.

\section{Exception Values}

Standard ML has a type
%
\index{exn@\texttt{exn}}%
%
{\tt exn} of
%
\index{exception value}%
%
{\em exception values}.  An exception value is either a
%
\index{exception value!nullary}%
%
{\em nullary\/} exception value or a
%
\index{exception value!constructed}%
%
{\em constructed\/} exception value. A nullary exception value is a pointer to a
word that points to an exception name. A constructed exception value is a pair
$(\ename,v)$ of an exception name $\ename$ and a value $v$; we refer to $v$ as
the {\em argument\/} of $\ename$.  This representation of exception values
allows for the exception name of an exception value to be fetched in the same
way irrespective of whether the exception value is nullary or constructed.

Referring to a nullary exception constructor allocates no memory. By contrast,
applying a unary exception constructor to an argument constructs a constructed
exception value. The memory cost of such an application is two words for holding
the pair $(\ename, v)$.

The distinction between nullary and unary exception constructors is important in
the MLKit because our region inference analysis takes a simple-minded approach
to exceptions:
\begin{quote}
  All exception names and nullary exception values are put into a certain
  %
  \index{region!global}%
  %
  global region and thus never reclaimed automatically. A constructed exception
  value is put in a region that is live at least as long as the exception
  constructor is in scope.
\end{quote}
We therefore make the following recommendations:
\begin{enumerate}
\item Put exception declarations at top level, if possible.  That way, the
  memory required by exception names will be bounded by the program size.
\item Avoid applying unary exception constructors frequently; there is no harm
  in raising and handling constructed exception values frequently; it is the
  creation of many different constructed exception values that can lead to space
  leaks. Nullary constructors may be raised without incurring memory costs.
\end{enumerate}

\section{Raising Exceptions}

An expression of the form
%
\index{exception!raising}%
%
\begin{center}
  \lstinline!raise $\mathit{exp}$!
\end{center}
is evaluated as follows. First {\it exp}, an expression of type \kw{exn}, is
evaluated to an exception value.  Then the runtime
%
\index{stack}%
%
stack is scanned from top to bottom in search of a handler that can handle the
exception. A register points to the top-most exception handler; the exception
handlers are linked together as a linked list interspersed with the other
contents of the runtime stack.  If a matching handler is found, the runtime
stack is popped down to the handler. This popping includes popping of regions
that lie between that stack top and the handler. Put differently, consider an
expression of the form
%
\index{let region@\texttt{let region}}%
%
\lstinline!let region $\rho$ in $e$ end!; if $e$ evaluates to an exception
packet, then the region bound to $\rho$ is de-allocated and the packet is also
the result of evaluating the \lstinline{let region} expression.

We have not attempted to design an analysis that would estimate how far down the
stack a given exception value might propagate. Of course, it would not be a very
good idea to allocate a constructed exception value in a region that is popped
before the exception is handled!  This is why we put all exception names in
%
\index{region!global}%
%
global regions.

\section{Handling Exceptions}

The ML expression form
%
\index{exception!handling}%
%
\begin{center}
  \lstinline!$\mathit{exp}_1$ handle $\mathit{match}$!
\end{center}
is compiled into a $\MulExp$ expression of the form
\begin{lstlisting}
  let region $\rho$
  in let f = fn at $\rho$ $\mathit{match}$
     in $e_1$ handle f
     end
  end
\end{lstlisting}
where $f$ is a fresh variable.  So first a handler (expressed as a function) is
evaluated and stored in some region $\rho$. This region will always have
multiplicity one and therefore be a finite region which is put on the stack.
Then $e_1$, the result of compiling $\mathit{exp}_1$, is evaluated.  If $e_1$
terminates with a value, the \lstinline!let region! construct will take care of
de-allocating the handler.  If $e_1$ terminates with an exception, however, $f$
is applied.

Thus the combined cost of raising an exception and searching for the appropriate
handler takes time proportional to the depth of the runtime stack in the worst
case.

Handling of exceptions is the only operation that takes time that cannot be
determined statically, provided one admits arithmetic operations as
constant-time operations.

\section{Example: Prudent Use of Exceptions}

Figure~\ref{prudentexn.fig} shows an example of good use of exceptions with
MLKit.
%
\index{hd@\texttt{hd}}%
\index{tl@\texttt{tl}}%
%

\begin{figure}
\hrule
\medskip
\begin{smlcode}
  exception Hd               (* recommendation 1 *)

  fun hd [] = raise Hd
    | hd (x::_) = x

  exception Tl

  fun tl [] = raise Tl
    | tl (_ ::xs) = xs

  exception Error of string

  local
    val error_f = Error "f"  (* recommendation 2 *)
  in
    fun f l =
        hd(tl(tl l)) handle _ => raise error_f
  end

  val r = f [1,2,3,4]
\end{smlcode}
\caption{Prudent use of exceptions with MLKit.\label{prudentexn.fig}}
\medskip
\hrule
\end{figure}

The application \lstinline!Error "f"! has been lifted out from the body of
\kw{f}. No matter how many times \kw{f} is applied, it will not create
additional exception values.\footnote{Program \boxml{kitdemo/exceptions.sml}.}

%---------------------------------------------------------
\chapter{Resetting Regions}
\label{storagemodes.sec}
%---------------------------------------------------------

The idea of region resetting was introduced in Section~\ref{checked.sec}.
%
\index{region!resetting}%

This chapter gives an informal explanation of the rules that govern
resetting. Knowing these rules is useful, irrespective of whether one makes the
MLKit decide on region resetting, or prefers to control resetting explicitly in
the program.

Resetting only makes sense for infinite regions.  Resetting a region is a
constant-time operation.  Because the same region variable can be bound
sometimes to a finite region and sometimes to an infinite region at runtime,
resetting a region can involve a test at runtime.

The MLKit contains an analysis, called the {\em storage mode analysis}, which
has two purposes:
\begin{enumerate}
\item Inserting automatic resetting of infinite regions, when possible.
\item Checking applications of $\resetr$ (and
  %
  \index{forceResetting@$\resetf$}%
  %
  $\resetf$) so as to report on the safety of the resetting requested by the
  programmer.
\end{enumerate}

As a matter of design, one might wonder whether it would not be sufficient to
rely on the user to indicate where resetting should be done. However, checking
whether resetting is safe at a particular point chosen by the user is of course
no easier than checking whether resetting is safe at an arbitrary point in the
program, so one might as well let the compiler insert region resetting whenever
it can prove that it is safe.

In this chapter, we describe the principles that underlie the storage mode
analysis. Even if one is willing to insert $\resetr$ and $\resetf$ instructions
in the program, one still needs to understand these principles, so as to be able
to act upon the messages that are generated by the system in response to
explicit $\resetr$ and $\resetf$ instructions.

\section{Storage Modes}

As we have seen in previous chapters, region inference decorates every
%
\index{allocation point}%
\index{at@\texttt{at}}%
%
allocation point with an annotation of the form $\fw{at}\,\rho$, indicating into
what region the value should be stored.

Now the basic idea is that storing a value into a region can be done in one of
two ways, at runtime. One either stores the value at the
%
\index{top of region}%
%
{\em top\/} of the region, thereby increasing the size of the region; or one
stores the value into the
%
\index{bottom of region}%
%
{\em bottom\/} of the region, by first resetting the region (so that it contains
no values) and then storing the value into the region.

The storage mode analysis transforms an allocation point $\fw{at}\,\rho$
into
%
\index{attop@\texttt{attop}}%
%
$\fw{attop}\,\rho$ when it estimates that $\rho$ contains live values at
the allocation point, whereas it transforms it into
%
\index{atbot@\texttt{atbot}}%
%
$\fw{atbot}\,\rho$ if it can prove that the region will contain no live values
at that allocation point. The tokens $\fw{attop}$ and $\fw{atbot}$ are called
%
\index{storage mode}%
%
{\em storage modes}.

\index{region polymorphism}%
%
Region polymorphism introduces several interesting problems. Let $f$ be a
region-polymorphic function with formal region parameter $\rho$ and consider an
allocation point $\fw{at}\,\rho$ in the body of $f$.  Whether it is safe for $f$
to store the value at bottom in the region depends not only on the body of $f$
but also on the context in which $f$ is called.

For example, consider the compilation unit
\begin{smlcode}
  fun f [] = []
    | f (x::xs) = x+1 :: f xs

  val ll = [1,2,3]
  val l2 = if true then f l1 else l1
  val x::_ = l1
\end{smlcode}

\noindent
When \kw{f} creates the empty list, it can potentially reset the
%
\index{region!auxiliary}%
%
auxiliary region intended for the
%
\index{pair!auxiliary}%
%
auxiliary pairs of the list. In the above program, however, the conditional
forces \kw{f l1} and \kw{l2} to be in the same region as \kw{l1}.  Because
\kw{l1} is live after the application of \kw{f}, this application must not use
\fw{atbot} as storage mode.  Indeed, even if we removed the last line of the
program, the application could still not use \fw{atbot}, because \kw{l1} is
exported from the compilation unit and thus potentially used by subsequent
compilation units.

By contrast, consider\footnote{Program \boxml{kitdemo/sma1.sml}.}
\begin{smlcode}
  fun f [] = []
    | f (x::xs) = x+1 :: f xs

  val n = length(let val l1 = [1,2,3]
                 in if true then f l1 else l1
                 end)
\end{smlcode}

\noindent
When \kw{f} creates the empty list, it is welcome to reset the region that holds
\kw{l1}, because by that time, \kw{l1} is no longer needed! (\kw{f} traverses
\kw{l1}, but when it reaches the end of the list, \kw{l1} is no longer used.)
Indeed, the MLKit will replace the list \kw{[1,2,3]} by \kw{[2,3,4]}. The
ability to replace data in regions is crucial in many situations (as we
illustrated with the game of Life in Section~\ref{life.sec}).

Because the MLKit allows for separate compilation, it cannot know all the call
sites of a region-polymorphic function, when it is declared.  Therefore, when
considering an allocation point $\fw{at}\,\rho$ inside the body of some
region-polymorphic function $f$ that has $\rho$ as a formal region parameter,
one cannot know at compile time whether to use \fw{attop} or \fw{atbot} as
storage mode.  Instead, the storage mode analysis operates with a third kind of
storage mode named \fw{sat}, read: ``somewhere at''. Consider an application of
$f$ for which $\rho$ is instantiated to some region variable $\rho'$, say. At
runtime, $\rho'$ is bound to some region name (Section~\ref{fininf.sec}) $r'$.
Then $r'$ is combined with a definite storage mode (i.e., \fw{attop} or
\fw{atbot}), to yield $r$, say, which is then bound to $\rho$.  When $r'$ was
originally created (by a
%
\lstinline{let region}%
%
expression), $r'$ was also made to contain an indication of whether it is an
infinite region or a finite region.\footnote{On machines\label{atbit.lab} that
have at least four bytes per word, the two least significant bits of a pointer
to a word will always be 00. These two bits hold extra information in the
%
\index{region name}%
%
region name.  One bit, called the ``atbot bit'', holds the current storage mode
of the region. Another bit, called the ``infinity bit'', indicates whether the
region is finite or infinite.}  At runtime, an allocation point
%
\lstinline!sat $\rho$!%
%
in the body of $f$ will test $r$ to see whether the region is infinite and
whether the value should be stored at the top or at the bottom.\footnote{When
$\rho$ has multiplicity infinity, $r'$ must be the name of an infinite region,
so the runtime check on whether $r$ has its infinity bit set is omitted.}

The relevant parts of the result of compiling the last example are shown in
Figure~\ref{sma1.fig}.  To see the storage modes, pass the option
%
\index{print drop regions expression with storage modes@\texttt{-Pdresm}}%
%
$$\kw{-print\_drop\_regions\_expression\_with\_storage\_modes}$$ to the MLKit
  compiler (or \kw{-Pdresm}).

\begin{figure}
\hrule
\medskip
\begin{smlcode}
   let fun f [r17:INF] var1 =
           case var1 of
             nil => nil
           | :: v94 =>
             let val v95 = #0 v94; val v96 = #1 v94
             in  :: (v95 + 1, f[sat r17] v96)attop r17
             end;
       val n =
         let region r31:INF
         in  length
             let region r33:INF
  (*1*)      in  f[atbot r31] [1,2,3] attop r33
             end
         end
   in  {|f: (_,r1), n: _|}
   end
\end{smlcode}
\caption{Storage modes inferred by the storage mode analysis for the program
  \kw{kitdemo/sma1.sml}. Use the flag \kw{-max\_inl\_sz 0} to avoid inlining of
  the small function \kw{length}.}
\label{sma1.fig}
\medskip
\hrule
\end{figure}

\section{Storage Mode Analysis}
\label{sma.sec}

For the purpose of the storage mode analysis, actual region parameters to
region-polymorphic functions are considered allocation points.  Passing a region
as an actual argument to a region-polymorphic function involves neither
resetting the region nor storing any value in it, but a storage mode has to be
determined at that point nonetheless, because it has to be passed into the
function together with the region. The storage mode expresses whether, at the
call site, there may be any live values in the region after the call. For
example, in Figure~\ref{sma1.fig}, the call to \kw{f} at \lstinline{(*1*)}
passes \kw{r31} with storage mode \fw{atbot} because the only value that exists
before the call of \kw{f} and is needed after the call of \kw{f} is
\kw{length}, which is declared in a different compilation unit and therefore
obviously does not reside in \kw{r31}.

Within every lambda abstraction, the MLKit performs a backwards flow analysis
that determines, for every allocation point, a set of
%
\index{variable!locally live}%
%
{\em locally live variables}, that is, a set of variables used by the remainder
of the computation in the function up to the syntactic end of the
function. (This includes variables that appear in function application
expressions.) Prior to the computation of locally live variables, a program
transformation, called
%
\index{K-normalisation}%
\label{K-normal-form}%
%
{\em K-normalisation}, has made sure that every intermediate result that arises
during computation becomes bound to a variable. (This happens by introducing
extra \lstinline{let} bindings, when necessary.)\footnote{K-normalisation is
transparent to users: although the storage mode analysis and all subsequent
phases up to code generation operate on K-normal forms, programs are always
simplified to eliminate the extra \boxml{let}-bindings before they are presented
to the user.}

The MLKit also computes a set of locally live variables for those allocation
points that do not occur inside functions.

We now give an informal explanation of the rules that assign storage modes to
allocation points.  Let an allocation point
\begin{equation}
\label{allocpoint}\fw{at}\,\rho
\end{equation}
be given.
\bigskip

\noindent{\bf CASE A:} $\rho$ is a global region. Then \fw{attop} is used.
There is a deficiency we have to admit here. The MLKit only puts
\lstinline{region} bindings around expressions, not around declarations. Thus,
if one writes
\begin{smlcode}
  local
    fun f [] = []
      | f (x::xs) = x+1 :: f xs
    val l1 = [1,2,3]
  in
    val n = length(if true then f l1 else l1)
  end
\end{smlcode}

\noindent
at top level, then \kw{l1} is put into a global region, although this decision
is really unnecessary. As a consequence, \kw{f} would be called with storage
mode \fw{attop} and thus \kw{l1} would not be overwritten.  \bigskip

\noindent{\bf CASE B:}
The region variable $\rho$ is not a global region and the allocation
point (\ref{allocpoint}) occurs inside a lambda abstraction, that is,
inside an expression of the form \lstinline!fn $\mathit{pat}$ => $e$!.  Here we
regard every expression of the form
\begin{center}
  \lstinline!let fun f x = $e$ in $e'$ end!
\end{center}
as an abbreviation for
\begin{center}
  \lstinline!let val rec f = fn x => $e$ in $e'$ end!
\end{center}
Then it makes sense to talk about {\em the smallest enclosing lambda abstraction
  (of the allocation point)}.

Now there are the following cases:
\begin{description}
\item[B1] {\it $\rho$ is bound outside the smallest enclosing lambda abstraction
  (and this lambda abstraction is not the right-hand side of a declaration of a
  region-polymorphic function that has $\rho$ as formal parameter):} Use
  \fw{attop}
  %
  \index{attop@\texttt{attop}}%
  %
  (see Figure~\ref{b1.fig}).
\item[B2] {\it $\rho$ is bound by a {\rm \fw{let region}} expression inside the
  smallest enclosing function:} Use \fw{atbot} if no locally live variable at
  the allocation point has $\rho$ free in its region-annotated type scheme with
  place (Section~\ref{regtych.sec}), and use \fw{attop} otherwise
  %
  \index{let region@\texttt{let region}}%
  %
  (see Figure~\ref{b2.fig}).
\item[B3 (first attempt)]{\it $\rho$ is a formal parameter of a
  region-polymorphic function whose right-hand side is the smallest enclosing
  lambda abstraction:} Use
  %
  \index{sat@\texttt{sat}}%
  %
  \fw{sat}, if no locally live variable at the allocation point has $\rho$ free
  in its region-annotated type scheme with place, and use \fw{attop} otherwise
  (see Figure~\ref{b3.fig}).
\end{description}

\begin{figure}[htb]
\hrule
\medskip
\begin{smlcode}
  let region $\rho$
  in $\ldots$ (fn $\mathit{pat}$ => $\ldots$ at $\rho$ $\ldots$)
  end

  fun f at $\rho_1$ [$\rho$] x =
    (fn y => $\ldots$ at $\rho$ $\ldots$)at $\rho_2$
\end{smlcode}
\caption{Two typical situations where $\fw{at}\,\rho$ is turned into
  $\fw{attop}\,\rho$ by
  %
  \index{function!Curried}%
  %
  rule~B1.} \medskip \hrule
\label{b1.fig}
\end{figure}

\begin{figure}[htb]
\hrule
\medskip
\begin{smlcode}
    (fn $\mathit{pat}$ => $\ldots$
        let region $\rho$
        in $\ldots$ at $\rho$ $\ldots$
        end)
\end{smlcode}
\caption{The situation considered in B2. If no locally live variable $l$ has
  $\rho$ occurring in its region-annotated type scheme with place, replace
  $\fw{at}\,\rho$ by $\fw{atbot}\,\rho$, otherwise by
  $\fw{attop}\,\rho$.}  \medskip \hrule
\label{b2.fig}
\end{figure}

\begin{figure}[htb]
\hrule
\medskip
\begin{smlcode}
    fun f at $\rho_0$ [$\rho$, $\ldots$] $\mathit{pat}$ =
      $\ldots$ at $\rho$ $\ldots$ l $\ldots$
\end{smlcode}
\caption{The situation considered in B3. If no locally live variable $l$ has in
  its region-annotated type scheme with place a region variable that may be
  aliased with $\rho$, replace $\fw{at}\,\rho$ by $\fw{sat}\,\rho$, otherwise by
  $\fw{attop}\,\rho$.}  \medskip \hrule
\label{b3.fig}
\end{figure}

The motivation for (B1) is that if $\rho$ is declared non-locally, then we do
not attempt to find out whether $\rho$ contains live data (this would require a
more sophisticated analysis.)

The intuition behind (B2) is as follows. Region inference makes sure that the
region-annotated type of a variable always contains free in it region variables
for all the regions that the value bound to the variable needs when used. The
lifetime of the region bound to $\rho$ is given by the \fw{let region}
expression, which is in the same function as the allocation point. Thus, if no
locally live variable at the allocation point has $\rho$ free in its
region-annotated type scheme with place, then $\rho$ really does not contain any
live value at that allocation point.

The intuition behind (B3) is the same as behind (B2), but in this case there is
a complication: $\rho$ is only a formal parameter so it may be instantiated to
different regions; in particular it may be instantiated to a region variable
that does occur free in the region-annotated type scheme with place of a locally
live variable at the allocation point. If that happens, rule (B3), as stated, is
not sound!

We refer to the phenomenon that two different region variables in the
program may denote the same region at runtime as
%
\index{region aliasing}%
%
{\em region aliasing}. To determine whether to use \fw{sat} or \fw{attop} in
case (B3), the MLKit builds a
%
\index{region flow graph}%
\label{region flow graph}%
%
{\em region flow graph\/} for the entire compilation unit. (This construction
happens in a phase prior to the storage mode analysis proper.)  The nodes of the
region flow graph are region variables and arrow effects that appear in the
region-annotated compilation unit.  Whenever $\rho_1$ is a formal region
parameter of some function declared in the unit and $\rho_2$ is a corresponding
actual region parameter in the same unit, a directed edge from $\rho_1$ to
$\rho_2$ is created. Similarly for arrow effects: if $\epsilon_1.\rea_1$ is a
bound arrow effect of a region-polymorphic function declared in the compilation
unit and $\epsilon_2.\rea_2$ is a corresponding actual arrow effect then an edge
from $\epsilon_1$ to $\epsilon_2$ is inserted into the graph.  Also, edges from
$\epsilon_2$ to every region and effect variable occurring in $\rea_2$ are
inserted.  Finally, for every region-polymorphic function $f$ declared in the
program and for every formal region parameter $\rho$ of $f$, if $f$ is exported
from the compilation unit, then an edge from $\rho$ to the global region of the
same runtime type as $\rho$ is inserted into the graph. (This is necessary, so
as to cater for applications of $f$ in subsequent compilation units.)

Let $G$ be the graph thus constructed.  For every node $\rho$ in the graph, we
write $\langle\rho\rangle$ to denote the set of region variables that can be
reached from $\rho$, including $\rho$ itself.  The rule that replaces (B3) is:
%
\index{region parameter!formal}%
%
\begin{description}
\item[B3]{\it $\rho$ is a formal parameter of a region-polymorphic function
  whose right-hand side is the smallest enclosing lambda abstraction:} Use
  \fw{sat}, if, for every variable $l$ that is locally live at the allocation
  point and for every region variable $\rho'$ that occurs free in the
  region-annotated type scheme with place of $l$, it is the case that
  $\langle\rho\rangle\cap\langle\rho'\rangle =\emptyset$; use \fw{attop}
  otherwise.
\end{description}
\medskip

\noindent{\bf CASE C:} $\rho$ is bound by a \fw{let region} expression and the
allocation point (\ref{allocpoint}) does not occur inside any function
abstraction.  As in (B2), use \fw{atbot} if no locally live variable at the
allocation point has $\rho$ free in its region-annotated type scheme with place,
and use \fw{attop} otherwise.


\section{Example: Computing the Length of Lists}
\label{length.sec}
We shall now illustrate the storage mode rules of Section~\ref{sma.sec} with
some small examples, which also allow us to discuss benefits and drawbacks
associated with region resetting.

Consider the functions declared in Figure~\ref{length.fig};\footnote{Program
\boxml{kitdemo/length.sml}.}  they implement five different ways of finding the
length of a list!  The first, \kw{nlength}, is the most straightforward one.  It
is not tail recursive. Textbooks in functional programming often recommend that
functions are written iteratively (i.e., using tail calls) whenever
possible. This we have done with \kw{tlength}.  Next, \kw{klength} is a version
that contains a local
%
\index{region endomorphism}%
%
region endomorphism \kw{loop} to perform the iteration; \kw{llength}
is similar to \kw{klength}, except that the region endomorphism is
declared outside \kw{llength}, using
%
\index{local@\texttt{local}}%
%
a \fw{local} declaration.
\begin{figure}
\hrule
\medskip
\begin{smlcode}
  fun upto n =
      let fun loop (n,acc) = if n=0 then acc
                             else loop(n-1, n::acc)
      in loop(n,[])
      end

  fun nlength [] = 0
    | nlength (_::xs) = 1 + nlength xs

  fun tlength l =
      let fun tlength' (nil, acc) = acc
            | tlength' (_::xs, acc) = tlength'(xs,acc+1)
      in tlength'(l,0)
      end

  fun klength l =
      let fun loop (p as ([], acc)) = p
            | loop (_::xs, acc) = loop(xs,acc+1)
      in #2(loop(l,0))
      end

  local
    fun llength' (p as ([], acc)) = p
      | llength' (_::xs, acc) = llength'(xs,acc+1)
  in
    fun llength l = #2(llength'(l, 0))
  end

  fun global (p as ([], acc)) = p
    | global (_::xs, acc) = global(xs, acc+1)

  fun glength l = #2(global(l, 0))

  val k = 5000000
  val run = nlength(upto k) + tlength(upto k) + klength(upto k)
             + llength(upto k) + glength(upto k)
\end{smlcode}
\caption{Five different ways of computing the length of lists.}
\bigskip
\label{length.fig}
\hrule
\end{figure}
A region profile resulting from running the program is shown in
Figure~\ref{length.region.fig}.  The diagram shows how much space is used in
regions (both finite and infinite regions) and on the stack.  The
%
\index{region descriptor}%
%
\kw{rDesc} band shows how much space is used on the stack for holding
region descriptors. The
%
\index{stack band@\texttt{stack} band}%
%
\kw{stack} band shows how much space is used on the stack, including neither
finite regions nor region descriptors; the \kw{stack} band mainly consists of
registers and return addresses that have been pushed onto the stack.

\begin{figure}
\includerp{length_region.pdf}
\caption{Region profiling of five different ways of computing the length of a
  list, namely, from left to right: \kw{nlength}, \kw{tlength}, \kw{klength},
  \kw{llength}, and \kw{glength}.}
\label{length.region.fig}
\end{figure}

In Figure~\ref{length.region.fig}, we clearly see the five phases.  In each
phase, first a list is built---seen as an almost linear growth in a region; then
follows a computation of the length of the list.  The space behavior of the five
ways of computing the length vary. We shall have more to say about the time
behavior in what follows.

As one would expect, \kw{nlength} leads to a peak in stack size; it does not use
regions. The peak in stack size is caused by the stacking of a return address.

Next, we see that \kw{tlength} is an improvement over \kw{nlength}, the main
reason being that the MLKit has figured out that the argument to \kw{tlength}
can be passed unboxed; thus no regions are used to hold the argument
pair. However, if we chose to disable the unboxing of arguments that the MLKit
performs,\footnote{Unboxing of function arguments can be disabled by passing the
option \inline{-no_unbox_funargs} to the MLKit compiler.} the function would
become region-polymorphic and the polymorphic recursion in regions would allow
the pair \kw{(xs, acc+1)} to be stored in a region different from the
argument pair to \kw{tlength'}. In this case, what appeared to be a tail call
would in fact not be a tail call, for it would automatically be enclosed in a
\fw{let region} construct, introducing a fresh region for each argument pair
\kw{(xs, acc+1)}.  This region would be finite, so it would be allocated on the
stack.  Thus, with unboxing of function arguments disabled, we would see a sharp
increase in stack size for \kw{tlength'}. Although unboxing of function
arguments saves us in this situation, we cannot always expect it to do so; if we
were to collect boxed data in accumulating parameters to the function and this
data is not to be returned by the function, there is a danger that the recursive
call would not become a tail call due to the introduction of a \fw{let region}
construct being wrapped around the recursive call.\footnote{The MLKit features
an option \inline{-preserve_tail_calls}, which ensures that no \fw{region}
binding is wrapped around a tail-call. This option is enabled by default when
garbage collection is enabled.}

The next function, \fw{klength}, deserves careful study, because it
is a prototype of a particular schema that can be used again and again
when programming with regions. Iteration is done by a
%
\index{region endomorphism}%
%
region endomorphism, \kw{loop}, which is declared as a local function to the
main function. The use of the same variable \kw{p} on both the left-hand side
and the right-hand side of the declaration of \kw{loop} forces \kw{loop} to be a
region endomorphism. Because the result of \kw{loop(xs,acc+1)} is also the
result of \kw{loop}, the result of \kw{loop(xs,acc+1)} therefore has to be in
the same region as \kw{p}; but because \kw{loop} is an endomorphism, \kw{(xs,
  acc+1)} is forced to be in the same region as \kw{p}.  Thus, what appears to
be a tail call (\kw{loop(xs,acc+1)}) really will be a tail call; in particular,
there will be no fresh region for the argument and no growth of the stack.

Better still, we have carefully arranged that memory consumption will be
constant throughout the computation of the length of the list.  First, the
argument to the initial call of \kw{loop} is a pair \kw{(l, 0)} constructed at
that point. Because \kw{loop} is a region endomorphism, the result of
\kw{loop(l, 0)} will be in the same region as \kw{(l, 0)}.  Moreover, because we
then immediately take the second projection of that pair, that region is clearly
local to the body of \kw{klength}.  Call the region $\rho$. Because there can be
an unbounded number of stores into this region, $\rho$ is classified as infinite
by multiplicity inference.

The storage mode passed along with $\rho$ in the initial call \kw{loop(l,0)} is
\fw{atbot}, by rule (B2) of Section~\ref{sma.sec}. Inside \kw{loop}, the storage
mode given to the allocation of \kw{(xs, acc+1)} is \fw{sat}, by rule (B3) of
Section~\ref{sma.sec}: the only locally live variable at the point where the
allocation takes place is \kw{loop}, which we must not destroy before calling!
The region that \kw{loop} lies in is clearly different from $\rho$.

Therefore, every iteration of \kw{loop} resets the infinite region $\rho$ so
that it will contain at most one pair.  This is seen very clearly in the third
hump of Figure~\ref{length.region.fig}.

Next consider \kw{llength}. The difference from \kw{klength} is that
\kw{llength'} is now declared outside \kw{llength}.  Although the use of
\fw{local} makes it clear that \kw{llength'} is not exported from the
compilation unit, \kw{llength'} must in fact reside in a global region, because
\kw{llength}, which is exported, calls \kw{llength'}.  Nonetheless, the storage
mode analysis still achieves constant memory usage. As before, we have arranged
that iteration is done by a region endomorphism that is initially applied to a
freshly constructed pair. This pair can reside in a region that is local to the
body of \kw{llength} (once again, the projection \kw{\#2(llength'(l, 0))} makes
sure that the pair does not escape the body of \kw{llength}).  The crucial bit
is now what storage mode \kw{llength'} uses when it stores \kw{(xs, acc+1)}.
The only locally live variable at that point is \kw{llength'} itself and, as we
noted earlier, \kw{length'} lives in a global region, which is clearly different
from the region inside \kw{llength} that contains all the pairs.  Thus, storage
mode \fw{sat} will be used, as desired.

Finally, consider \kw{glength}, which is similar to \kw{llength}, but with the
crucial difference that \kw{global} is exported from the compilation
unit. Because \kw{global} may be called from a different compilation unit, then,
for all we know, \kw{global} may be applied to a pair that resides in the same
(global) region as \kw{global} itself. Using \fw{sat} when storing \kw{(xs,
  acc+1)} would then be a big mistake: it would destroy the very function that
we are trying to call! Therefore, the storage mode analysis assigns \fw{attop}
to that storage operation.\footnote{To be precise, \boxml{attop} comes about by
using rule (B3) of Section~\ref{sma.sec}. This example illustrates why we put
edges from formal region parameters to global regions for exported functions
when constructing the region flow graph. Notice also that storage mode analysis
does not take region runtime types into account.}  Consequently, we get a memory
leak, as shown in the final hump of Figure~\ref{length.region.fig}.

To sum up, here is how one writes a loop without using space
proportional to the number of iterations:
\index{length of list}%
\begin{enumerate}
\item The iteration should be done by an auxiliary, uncurried function that is
  declared as local to the function that uses it; we refer (informally) to this
  auxiliary function as the
  %
  \index{iterator}%
  %
  {\em iterator}.
\item The iterator should be a
  %
  \index{region endomorphism}%
  %
  region endomorphism and should be tail recursive.
\item Iteration should start from a suitably fresh initial argument; the result
  of the iteration should be kept clearly separate from the region where the
  iterator function lies.
\end{enumerate}
Mutual recursion poses no additional complications. All functions in a block of
mutually recursive functions are put in the same region.

Finally, the reader may be concerned that the two recommended solutions,
\kw{klength} and \kw{llength}, are much slower than the other versions. This is
partly an artifact of the profiling software.\footnote{When profiling is turned
on, every resetting of a region involves resetting of values in the first region
page of the region.} To get a better picture of the actual cost of the different
versions, we ran the five programs separately (using lists of length 10 million
instead of 5 million) on a Mac Book Pro with 16Gb RAM and a 2,7 GHz Quad-Core
Intel Core i7 processor.\footnote{Program \boxml{kitdemo/length-cmd.sml}. For
larger lists, the \boxml{nlength} program may cause stack overflow.}  The
results are shown in Figure~\ref{length.timing.fig}. Because \kw{upto} alone
takes 0.12 seconds to build the list, the differences in times are clear: the
version of the length function that does not use the stack and that takes its
argument in registers (i.e., \kw{tlength}) is the fastest. The recommended
versions of the length function (i.e., \kw{klength} and \kw{llength}) run as
well as the versions that make use of the runtime stack (i.e., \kw{nlength} and
\kw{glength}), but are scalable and follow general useful approaches to writing
recursive functions.

\begin{figure}
\hrule
\medskip
\begin{center}
\def\arraystretch{1.4}
\begin{tabular}{l|cccccc}
Program      & {\tt upto} & {\tt nlength} & {\tt tlength} & {\tt klength} & {\tt llength} & {\tt glength} \\ \hline
Time (s) & 0.12 & 0.25 & 0.15 & 0.22 & 0.23 & 0.26
\end{tabular}
\end{center}
\caption{User time in seconds for building a list of 10 million elements and
  computing its length, using five different length functions. The function
  \kw{upto} builds the list, but does not compute a length. Times are average
  over three runs.}
\label{length.timing.fig}
\medskip
\hrule
\end{figure}

\section{Resetting Regions}

It is often the case that there are only a few places in the program where
resetting is really essential, for example in some main loop.  Therefore, the
MLKit provides two operations that the programmer can use to encourage (or
force) the MLKit to perform resetting at particular places in the program. The
two operations are
%
\index{resetRegions@\texttt{resetRegions}}%
%
$$\resetr\; {\it vid}$$
and
%
\index{forceResetting@$\resetf$}%
%
$$\resetf\; {\it vid}$$ In both cases, the argument has to be a value
identifier.  To port programs that contain \kw{resetRegions} and
\kw{forceResetting} to other ML systems, simply declare
\begin{smlcode}
  fun resetRegions _ = ()
  fun forceResetting _ = ()
\end{smlcode}
before compiling the program developed using the MLKit.

Let $\rho$ be a region variable that occurs free in the region-annotated type
scheme with place of {\it vid}.  Let $m$ be the storage mode determined for
$\rho$ at a program point according to the rules of the previous section.
Whether resetting of {\it vid\/} at that program point actually takes place at
runtime, depends on $m$ and on whether resetting is forced, see
Figure~\ref{smamodes.fig}.

\begin{figure}
\hrule
\medskip
\begin{center}
\def\arraystretch{1.4}
\setlength\tabcolsep{3mm}
\begin{tabular}{p{1.4in}|p{1.8in}|p{1.3in}}
Does resetting take place at runtime? & \resetr     & \resetf \\ \hline
$m=\atbot$ & yes      &  yes \\ \hline
$m=\sat$   & only if runtime storage mode is {\tt atbot}        &  yes$\ast$ \\ \hline
$m=\attop$ & no$\ast$  &  yes$\ast$
\end{tabular}
\smallskip

($\ast$): A compile-time warning is printed in this case.
\end{center}
\caption{The storage modes that will be used when resetting a region depending
  on $m$, the storage mode inferred by the storage mode analysis, and depending
  on whether the resetting is safe ($\resetr$) or potentially unsafe
  ($\resetf$).}
\label{smamodes.fig}
\medskip
\hrule
\end{figure}

\section{Example: Improved Mergesort}
\label{improvedmerge.sec}
We can now improve on the
%
\index{merge sort}%
\index{msort@\texttt{msort}}%
%
mergesort algorithm (Section~\ref{polyrec.sec}) by taking storage modes into
account. Splitting a list can be done by an iterative region endomorphism that
is made local to the sorting function.  Also, when the input list has been
split, it is no longer needed, so the region it resides in can be
reset. Similarly, when the two smaller lists have been sorted (into new regions)
the regions of the smaller lists can be reset. These three simple observations
lead to the variant of \kw{msort} listed in
Figure~\ref{msortreset1.fig}.\footnote{MLB-file:
\boxml{kitdemo/msortreset1.mlb}, file \boxml{kitdemo/msortreset1.sml}.}

\begin{figure}
\hrule
\medskip
\begin{smlcode}
  local
    fun cp [] = []
      | cp (x::xs) = x :: cp xs

    (* exomorphic merge *)
    fun merge (xs, []) : int list = cp xs
      | merge ([], ys) = cp ys
      | merge (l1 as x::xs, l2 as y::ys) =
          if x<y then x :: merge(xs, l2)
          else y :: merge(l1, ys)

    (* splitting a list *)
    fun split (x::y::zs, l, r) = split(zs, x::l, y::r)
      | split (x::xs, l, r) = (xs, x::l, r)
      | split (p as ([], l, r)) = p

    (* exomorphic merge sort *)
    fun msort []  = []
      | msort [x] = [x]
      | msort xs = let val (_, l, r) = split(xs, [], [])
                   in resetRegions xs;
                      merge(msort l before resetRegions l,
                            msort r before resetRegions r)
                   end
  in
    val runmsort = msort(upto 200000)
    val result = print "Really done\n"
  end
\end{smlcode}
\caption{Variant of \kw{msort} that uses \kw{resetRegions} to improve memory
  usage. The MLKit fails to infer that the region holding the argument list
  \kw{xs} can be reset after \kw{xs} is split.}
\label{msortreset1.fig}
\medskip \hrule
\end{figure}

Unfortunately, the storage mode analysis complains:
\begin{scriptcode}
 *** Warnings ***
resetRegions(xs):
   You have suggested resetting the regions that appear free
   in the type scheme with place of 'xs', i.e., in
   (int, [r147]) list
   (1)
        'r147': there is a conflict with the locally
        live variable
        v187 :(int, [r161]) list
        from which the following region variables can be reached
        in the region flow graph:
             {r161}
        Amongst these, 'r161' can also be reached from 'r147'.
        Thus I have given 'r147' storage mode "attop".
\end{scriptcode}
There is one complaint concerning the first $\resetr$, but none concerning the
two remaining ones.  By inspecting the region-annotated term, one sees that
\kw{r147} is a formal parameter of \kw{msort}.  Due to the recursive call
\kw{msort l}, the region graph contains an edge from \kw{r147} to
\kw{r161}. Thus the analysis decides on \fw{attop}, using rule (B3). This choice
shows a weakness in the analysis, for using \fw{sat} would really be sound. (The
problem is that, unlike polymorphic recursion, the region flow graph does not
distinguish between different calls of the same function.)  Seeing that this is
the problem, we decide to put $\resetf$ to work, see
Figure~\ref{force.fig}.\footnote{MLB-file: \boxml{kitdemo/msortreset2.mlb}, file
\boxml{kitdemo/msortreset2.sml}.}
\begin{figure}
\hrule\medskip
\begin{smlcode}
  local
    fun cp [] = []
      | cp (x::xs) = x :: cp xs

    (* exomorphic merge *)
    fun merge (xs, []) : int list = cp xs
      | merge ([], ys) = cp ys
      | merge (l1 as x::xs, l2 as y::ys) =
          if x<y then x :: merge(xs, l2)
          else y :: merge(l1, ys)

    (* splitting a list *)
    fun split (x::y::zs, l, r) = split(zs, x::l, y::r)
      | split (x::xs, l, r) = (xs, x::l, r)
      | split (p as ([], l, r)) = p

    (* exomorphic merge sort *)
    fun msort []  = []
      | msort [x] = [x]
      | msort xs = let val (_, l, r) = split(xs, [], [])
                   in forceResetting xs;
                      merge(msort l before resetRegions l,
                            msort r before resetRegions r)
                   end
  in
    val runmsort = msort(upto 200000)
    val result = print "Really done\n"
  end
\end{smlcode}
\caption{Using \kw{forceResetting} to reset regions.}
\medskip
\hrule
\label{force.fig}
\end{figure}
The region profile of the improved merge sort appears in
Figure~\ref{msortreset.fig}. As expected, we have now brought space consumption
down from four times to two times the size of the input.
Figure~\ref{msortreset.fig} may be compared to Figure~\ref{msortregion.fig} on
page~\pageref{msortregion.fig}.

\begin{figure}
\includerp{msortreset2.pdf}
\index{region.ps@\texttt{region.ps}}%
\index{sampleMax@\texttt{-sampleMax} option}%
\index{eps file@\texttt{-eps} option}%
\index{rp2ps@\texttt{rp2ps}}%
\caption{Region profiling of the improved mergesort.  The upper triangle
  contains unsorted elements, while the lower triangle contains sorted elements.
  The program was compiled with profiling enabled and then run with the command
  \inline{run -microsec 1000}.  The Postscript picture \inline{region.ps} was
  generated with the command \inline{rp2ps -region -sampleMax 200} and then
  converted into \inline{region.pdf} with \inline{ps2pdf}.}
\label{msortreset.fig}
\end{figure}

\section{Example: Scanning Text Files}

\label{scan.sec}%
%
In this section we present a program that can
%
\index{scan@\texttt{scan}}%
%
scan a sequence of Standard ML source files and compute what percentage of the
source files is made up by comments. Recall that an ML comment begins with the
two characters \kw{(*}, ends with \kw{*)}, and that comments may be nested but
must be balanced (within each file, we require).

The obvious solution to this problem is to implement an automaton with counters
to keep track of the level of nesting of parentheses, number of characters read,
and number of characters within comments. This solution provides an interesting
test for region inference: although designed with the lambda calculus in mind,
does the scheme cope with good old-fashioned state computations?

Let us be ambitious and write a program that only ever holds on to one character
at a time when it scans a file. In other words, the aim is to use constant space
(i.e., space consumption should be independent of the length of the input file).

To this end, let us arrange to use a region with infinite multiplicity to hold
the current input character and then reset that region before we proceed to the
next character. The iteration is done by tail recursion, using region
endomorphisms to ensure constant space usage.

The bulk of the program appears below.\footnote{MLB-file:
\boxml{kitdemo/scan.mlb}, file: \boxml{kitdemo/scan.sml}.} The scanning of a
single file is done by \kw{scan}, which contains three mutually recursive region
endomorphisms (\kw{count}, \kw{after\_lpar}, and \kw{after\_star}) written in
accordance with the guidelines in Section~\ref{length.sec}.

It turns out that the constraints we have put on ourselves with running in
constant space does work well with the combination of how \kw{TextIO} input
streams buffers input data. Instead, we shall make use of the lower-level
\kw{Posix} operations for opening and reading files.

The built-in function \kw{Posix.IO.readVec}, which reads a vector of bytes from
an open file descriptor, understands storage modes; if called with storage mode
\fw{atbot}, it will reset the region where the byte vector should be put before
reading the bytes from the file descriptor.  Consequently, at every call of
\kw{next}, the ``input buffer region'' will be reset.

The other important loop in the program is \kw{driver}, a function that
repeatedly reads a file name from a given file descriptor, opens the file with
that name, and calls \kw{scan} to process the file. Once again, we want to keep
at most one file name in memory at a time, so we would like the region
containing the file name to be reset upon each iteration.  As it turns out,
\kw{readWord} will always try to store the string it creates at the bottom of
the region in question.

In general however, when splitting a program unit into two, one may have to
insert explicit $\resetr$ into the second unit, when operations from the first
unit are called. This extra resetting may be necessary because formal region
parameters of exported functions are connected to global regions in the region
flow graph (cf., rule B3).

\bigskip
\hrule
\begin{smlcode}
local
  structure F = Posix.FileSys
  exception NotBalanced
  fun scan fd : int * int =
    let
      fun next () = Byte.bytesToString(Posix.IO.readVec(fd,1))
      fun up (lev,ins) = if lev > 0 then ins + 1
                         else ins

      (* n   : characters read from 'fd'
         ins : characters inside comments
         lev : current (level) number of unmatched (*
         s   : next input character or empty *) *)

      fun count (p as (n,ins,lev,s)) =
        case s of
          "" => (* end of stream: *) p
        | "(" => after_lpar(n+1,ins,lev,next())
        | "*" => after_star(n+1,up(lev,ins),lev,next())
        | _  => count(n+1,up(lev,ins), lev,next())
      and after_lpar (p as (n,ins,lev,s)) =
        case s of
          "" => p
        | "*" => count(n+1,ins+2, lev+1,next())
        | "(" => after_lpar(n+1,up(lev,ins),lev,next())
        | _ => count(n+1,up(lev,up(lev,ins)),lev,next())
      and after_star (p as (n,ins,lev,s)) =
        case s of
          "" => p
        | ")" => if lev > 0 then
                    count(n+1,ins+1,lev-1,next())
                 else raise NotBalanced
        | "*" => after_star(n+1,up(lev,ins),lev,next())
        | "(" => after_lpar(n+1,ins,lev,next())
        | _  => count(n+1,up(lev,ins),lev,next())

      val (n,ins,lev,_) = count(0,0,0,next())
    in if lev=0 then (n,ins) else raise NotBalanced
    end

  fun report_file (filename, n, ins) =
      writeln (filename ^ ": size = " ^ Int.toString n
               ^ " comments: " ^ Int.toString ins ^ " ("
               ^ (Int.toString(percent(ins, n))
                  handle _ => "") ^ "%)");

  (* scan_file(filename) scans through the file named filename
     returning either SOME(size_in_bytes, size_of_comments)
     or, in case of an error, NONE. In either case a line of
     information is printed. *)

  fun scan_file filename : (int*int) option =
      let val fd = F.openf (filename, F.O_RDONLY, F.O.flags[])
      in let val (n, ins) = scan fd
         in Posix.IO.close fd;
            report_file (filename, n, ins);
            SOME (n, ins)
         end handle NotBalanced =>
                    (writeln (filename ^ ": not balanced");
                     Posix.IO.close fd;
                     NONE)
      end handle IO.Io {name,...} =>
                 (writeln (name ^ " failed."); NONE)

  fun report_totals (n, ins) =
      writeln ("\nTotal sizes: " ^ Int.toString n
               ^ " comments: " ^ Int.toString ins
               ^ " (" ^ (Int.toString (percent (ins, n))
                         handle _ => "") ^ "%)")

  (* main(fd) reads a sequence of filenames from fd, one file
     name pr line (leading spaces are skipped; no spaces
     allowed in file names). Each file is scanned using
     scan_file after which a summary report is printed *)

  fun main fd : unit =
      let fun driver (p as (NONE, n, ins)) =
              (report_totals(n, ins); p)
            | driver (p as (SOME filename, n, ins)) =
              driver (case scan_file filename of
                          SOME(n', ins') =>
                          ( resetRegions p
                          ; (readWord fd, n+n', ins+ins')
                          )
                        | NONE => ( resetRegions p
                                  ; (readWord fd, n, ins)
                                  )
                     )
      in driver (readWord fd, 0, 0); ()
      end
in
  val result = main F.stdin
end
\end{smlcode}
\hrule
\bigskip

The program was compiled both with and without profiling turned on.  The output
from running the program on 14 of the source files for the MLKit is shown here:
\begin{scriptcode}
../src/Parsing/Infixing.sml: size = 32153 comments: 5294 (16%)
../src/Parsing/Parse.sml: size = 5498 comments: 673 (12%)
../src/Parsing/Topdec.grm.sml: size = 212870 comments: 4698 (2%)
../src/Parsing/GRAMMAR_UTILS.sml: size = 5534 comments: 787 (14%)
../src/Parsing/INFIX_STACK.sml: size = 487 comments: 321 (65%)
../src/Parsing/Topdec.lex.sml: size = 49968 comments: 1023 (2%)
../src/Parsing/LEX_BASICS.sml: size = 2048 comments: 1242 (60%)
../src/Parsing/LEX_UTILS.sml: size = 1444 comments: 291 (20%)
../src/Parsing/GrammarUtils.sml: size = 17262 comments: 1820 (10%)
../src/Parsing/LexBasics.sml: size = 12636 comments: 3079 (24%)
../src/Parsing/MyBase.sml: size = 33725 comments: 11104 (32%)
../src/Parsing/HOOKS.sml: size = 312 comments: 170 (54%)
../src/Parsing/InfixStack.sml: size = 7404 comments: 2972 (40%)
../src/Parsing/LexUtils.sml: size = 8708 comments: 487 (5%)

Total sizes: 390049 comments: 33961 (8%)
\end{scriptcode}
A region profile for that run is shown in Figure~\ref{scan.fig}.  The
almost-constant space usage is evident. The occasional disturbances are due to
the non-iterative functions that read a file name from input by first reading
one line and then extracting the name.

\begin{figure}
\includerp{scan.pdf}
\caption{Region profile of the comment scanner. The occasional increases in
  memory use is due to the functions that read a file name from a file
  descriptor.  The program was compiled with profiling enabled, then run with
  the command \inline{run -notimer 1000 < ../kitdemo/scanfiles}.  A Postscript
  file \inline{region.ps} can be generated with the command \inline{rp2ps
    -region -sampleMax 200} and converted to \inline{region.pdf} using
  \inline{ps2pdf region.ps region.pdf}. }
\label{scan.fig}
\end{figure}


%---------------------------------------------------------
\chapter{Higher-Order Functions}
\label{hof.sec}
%---------------------------------------------------------

\section{Lambda Abstractions}

A \emph{lambda abstraction}
%
\index{lambda abstraction}%
\index{function!higher-order}%
%
in Standard ML is an expression of the form
\begin{center}
  \lstinline!fn $\id{pat}$ => $\id{exp}$!
\end{center}
where \id{pat} is a pattern and \id{exp} an expression.  Lambda abstractions
denote functions.  We refer to the \id{exp} as the \emph{body} of the function;
variable occurrences in \id{pat} are binding occurrences; informally, the
variables that occur in \id{pat} are said to be
%
\index{variable!lambda-bound}
%
\emph{lambda-bound} with scope \id{exp}.

Lambda abstractions are represented by closures, both in the language definition
and in the MLKit. In the MLKit, a closure for a lambda abstraction consists of a
code pointer plus one word for each free variable of the lambda
abstraction. Closures are not tagged except when garbage collection is enabled,
in which case a closure contains one or more words to hold the tag.

At this stage, it will hardly come as a surprise to the reader that closures are
stored in regions.  Sometimes they reside in finite regions on the stack, other
times they live in infinite regions, just like all other boxed values.

Every occurrence of \lstinline{fn}
%
\index{fn@\texttt{fn}}
%
in the program is considered an allocation point; the region-annotated version
of the lambda abstraction is
\begin{center}
  \lstinline!fn at $\rho$ $\id{pat}$ => $\id{exp}$!
\end{center}
Standard ML allows functions to be declared using \lstinline{val} rather than
\lstinline{fun}, for example,
\begin{smlcode}
  val h = g o f
\end{smlcode}
declares the value identifier \lstinline{h} to be the composition of \lstinline{g}
and \lstinline{f}.  Whereas functions declared with
%
\index{fun@\texttt{fun}}
%
\lstinline{fun} automatically become region-polymorphic, functions
declared with
%
\index{val@\texttt{val}}
%
\lstinline{val} do not in general become
%
\index{region polymorphism}
%
region-polymorphic.\footnote{The reason for this is that the expression on the
right-hand side of the value declaration might have an effect (e.g, print
something) before returning the function.  It would not be correct to suspend
this effect by introducing formal region parameters.} However, in the special
case where the right-hand side of the value declaration is a
%
\index{lambda abstraction}
%
lambda abstraction, the MLKit automatically converts the declaration into a
\lstinline{fun} declaration, thereby making the function region-polymorphic
after all.

ML allows declarations of the form
%
\index{fun@\texttt{fun}}%
%
\begin{center}
  \lstinline!fun $f$ $\mathit{atpat}_1$ $\mathit{atpat}_2$ $\cdots$ $\mathit{atpat}_n$ = $\mathit{exp}$!
\end{center}
as a shorthand for
\begin{center}
  \lstinline!fun $f$ $\atpat_1$ = fn $\atpat_2$ => $\cdots$ fn $\atpat_n$ => $\exp$!
\end{center}
where $\atpat$ ranges over atomic patterns.  Functions declared using this
abbreviation are said to be
%
\index{function!Curried}%
%
{\em Curried}.

\section{Region-Annotated Function Types}
%
\label{functiontypes.sec}%
%
The general form of a region-annotated
%
\index{function type!region-annotated}%
\index{type!region-annotated}%
%
function type is
$$([\mu_1,\cdots,\mu_n] \ar{\epsilon.\rea} \mu', \rho)$$ where
$\mu_1,\cdots\mu_n$ are the type with places of the arguments, $\mu'$ is the
type with place of the result, and $\rho$ is the region containing the closure
for the function. When a function type has only one argument type, we shall
often write it on the form $(\mu \ar{\epsilon.\rea} \mu', \rho)$, and so shall
the MLKit.

As mentioned in Section~\ref{listtypes.sec}, the unusual looking object
$\epsilon.\rea$ is called an
%
\index{arrow effect}%
%
{\em arrow effect}. Its first component
is an
%
\index{effect variable}%
%
effect variable, whose purpose will be explained shortly.  The second component
is called the
%
\index{effect!latent}%
%
{\em latent effect}, and describes the effect of evaluating the body of the
function.

The following example illustrates why latent effects are crucial for knowing the
lifetimes of closures.\footnote{Program \boxml{kitdemo/lambda.sml}.} Consider
\begin{smlcode}
  val n = let val f = let val xs = [1,2]
                      in fn ys => length xs + length ys
                      end
          in f [7]
          end
\end{smlcode}
Notice that \kw{xs} has to be kept alive for as long as the function
%
\lstinline!(fn ys => $\cdots$)!%
%may be called, for this function will
access \kw{xs}, when called.  The region-annotated version of the example
appears in Figure~\ref{lambda1.fig}.\footnote{To see the output programs
discussed in this section, enable the flag
\boxml{-print\_drop\_regions\_expression}.}

\begin{figure}
\hrule \medskip
\begin{smlcode}
   let val n =
         let region r9:INF, r19:INF, r25:1;
             val f =
               let val xs = [1,2] at r9
               in  fn at r25 ys => length xs + length ys
               end
         in  f [7] at r19
         end
   in  {|n: _|}
   end
\end{smlcode}
\caption{Region-annotated program illustrating that the lifetime of a closure is
  at least as long as the lifetime of the values that evaluation of the function
  body will require.}  \medskip \hrule
\label{lambda1.fig}
\end{figure}

We see that \kw{xs} is put in \kw{r9}, that the function closure for
\lstinline!(fn ys => $\cdots$)! is put in \kw{r25} and indeed, \kw{r9} and
\kw{r25} have the same lifetime. To understand how the region inference system
figured that out, let us consider the effect and the region-annotated types of
particular sub-expressions. Looking at the lambda abstraction, it must have a
functional type of the form $(\tau\ar{\epsilon.\rea}\tau', \kw{r25})$ where
$\rea$ is the effect
$$\{\Get(\kw{r1}), \Get(\kw{r9}), \Get(\kw{r19})\}$$ Notice that \kw{r9}
occurs free in the type of the lambda abstraction.  But, as pointed out in
Section~\ref{effects.sec}, the criterion
%
\index{region!de-allocation}%
%
for putting a \fw{region} binding of $\rho$ around an expression $e$ is that
$\rho$ occurs free neither in the type with place of $e$ nor in the type scheme
with place of any variable in the domain of the type environment. The smallest
sub-expression of the program for which \kw{r9} does not occur free in the
type with place of the expression is the right-hand side of the \fw{val} binding
of \kw{n}, for that expression simply has type with place \kw{int}.  And at that
point, the only region variables that occur free in the type environment are
global region variables.  Hence the placement of the \fw{region} binding of
\kw{r9}.

\section{Arrow Effects}

In a first-order language, effect variables might not be particularly important.
But in a higher-order language like ML, effect variables are useful for tracking
dependencies between functions. The following example illustrates the
point:\footnote{Program \boxml{kitdemo/apply.sml}.}
\begin{smlcode}
  fun apply f x = f x
  val y = apply (fn n => n + 1.0) 5.0
  val z = apply (fn m => m) 6
\end{smlcode}
Here is the region-annotated type scheme of \kw{apply}:
\begin{tabbing}
\qquad$\forall\alpha_0\alpha_2\rho_{17}\rho_{15}\epsilon_{16}\epsilon_{20}\epsilon_{18}.$\=$(\alpha_0
        \ar{\epsilon_{16}.\emptyset}\alpha_2,\rho_{15})\ar{\epsilon_{20}.\{\Put(\rho_{17})\}}$\\
            \>$(\alpha_0\ar{\epsilon_{18}.\{\Get(\rho_{15}), \epsilon_{16}\}}\alpha_2,\rho_{17})$
\end{tabbing}
The latent effect associated with $\epsilon_{20}$ shows that when \kw{apply} is
applied to a function, it may create (in fact: will create) a function closure
in $\rho_{17}$.  The latent effect associated with $\epsilon_{16}$ is empty,
because the declaration of \kw{apply} does not tell us anything about what
effect its formal parameter \kw{f} must have. Crucially, however,
$\epsilon_{16}$ is included as an atomic effect in the latent effect associated
with $\epsilon_{18}$; whenever the body of \kw{apply f} is evaluated, the body
of \kw{f} may be (in fact: will be) evaluated.

The polymorphism in effects makes it possible to distinguish between the latent
effects of different actual arguments to \kw{apply}. For example, the functions
\lstinline!(fn n => n + 1.0)! and \lstinline!(fn m => m)!  have different latent
effects. Let us take the function \lstinline!(fn n => n + 1.0)! as an
example. It has region-annotated type with place
\begin{equation}
\label{suc.lab}
((\kw{real},\rho_{21})\ar{\epsilon_{26}.\{\Get(\rho_{21}),\Put(\rho_1)\}}(\kw{real}, \rho_1), \rho_{25})
\end{equation}
Here, the effect variable $\epsilon_{26}$ and the region variables $\rho_{25}$
and $\rho_1$ were chosen arbitrarily. (Actually, the region variable $\rho_1$
denotes the global region for reals.) The region inference algorithm discovers
that (\ref{suc.lab}) can be derived from the argument type
$$(\alpha_0\ar{\epsilon_{16}.\emptyset}\alpha_2,\rho_{15})$$
of the type scheme for \kw{apply} by the instantiating substitution
$$S =(\!\!\begin{array}[t]{l}\{\alpha_0\mapsto(\kw{real},\rho_{21}),\alpha_2\mapsto(\kw{real}, \rho_1)\}, \\\{
       \rho_{17}\mapsto\rho_{27},\rho_{15}\mapsto\rho_{25}\},\\
       \{\!\!\begin{array}[t]{l}\epsilon_{16}\mapsto\epsilon_{26}.\{\Get(\rho_{21}),\Put(\rho_1)\},\\
        \epsilon_{20}\mapsto\epsilon_{24}.\{\Put(\rho_{27})\}, \\
        \epsilon_{18}\mapsto\epsilon_{22}.\{\epsilon_{26},\Put(\rho_1),\Get(\rho_{25})\}
       \end{array}\\
       \}
       )
   \end{array}$$
Formally, a
%
\index{substitution}%
%
{\em substitution\/} is a triple $(\St,\Sr,\Se)$, where $\St$ is a finite map
from type variables to region-annotated types, $\Sr$ is a finite map from region
variables to region variables, and $\Se$ is a finite map from effect variables
to arrow effects.  Let us explain why substitutions map effect variables to
arrow effects.  One alternative, one might consider, is to let substitutions map
effect variables to effect variables. But then substitutions would not be able
to account for the idea that effects can grow, when instantiated. In the
\kw{apply} example, for instance, the empty effect associated with
$\epsilon_{16}$ has to grow to $\{\Get(\rho_{21}),\Put(\rho_1)\}$ at the
concrete application of \kw{apply}. Otherwise, as it is easy to demonstrate, the
region inference system would become unsound.

Another alternative would be to let substitutions map effect variables to
effects. But nor that would work well together with the idea of using
substitutions to express growth of effects. For example, when applying the map
$\{\epsilon\mapsto\{\Get(\rho_0),\Put(\rho_2)\}\}$ to the effect
$\{\Get(\rho_9),\epsilon\}$, say, we would presumably yield the effect
$\{\Get(\rho_9),\Get(\rho_0),\Put(\rho_2)\}$ in which the fact that the original
effect had to be at least as large as whatever $\epsilon$ stands for, is lost.
Instead, we define substitution so that applying the effect substitution
$\{\epsilon\mapsto\epsilon.\{\Get(\rho_2),\Put(\rho)\}\}$ to
$\{\Get(\rho_9),\epsilon\}$ yields
$\{\Get(\rho_9),\epsilon,\Get(\rho_2),\Put(\rho)\}$.

We can now give a complete definition of atomic effects.  An
%
\index{effect!atomic, definition}%
%
{\em atomic effect\/} is either an effect variable or a term of the form
$\Get(\rho)$ or $\Put(\rho)$, where $\rho$ as usual ranges over region
variables. An
%
\index{effect!definition}%
%
{\em effect\/} is a finite set of atomic effects.

One can get the MLKit to print region-annotated
%
\index{type!region-annotated}%
\index{region-annotated type scheme!printing of}%
%
type schemes with places of all binding occurrences of value variables.  Also,
one can choose to have arrow effects included in the printout by passing the
options \kw{print\_types} and \kw{print\_effects} to the MLKit
compiler. Although passing these options gives very verbose output, it is
instructive to look at such a term at least once, to see how arrow effects are
instantiated. We show the full output for the \kw{apply} example in
Figure~\ref{apply.fig}.

\begin{figure}
\hrule \medskip
\begin{smlcode}
  fun apply :all r17,r15,e16,e20,e18,'a0,'a2.
             ('a0-e16->'a2,r15) -e20(put(r17))->
             ('a0-e18(U(U,get(r15),e16))->'a2,r17)
      at r1 [r15:0|r17:1] f = fn at r17 x:'a0 => f x;
  val y:(real,r1) =
    let region r21:1, r25:1, r27:1, e26, e22
    in   let region e24
         in  apply [r27]
                   [(real,r21),(real,r1)]
                   [r27,r25]
                   [e26(get(r21),put(r1)),
                    e24(put(r27)),
                    e22(e26(get(r21),put(r1)),get(r25))
                   ]
             (fn at r25 n:(real,r21) =>
                R64.fromF64 [at r1] (F64.fromR64 n:f64 + 1.0f64)
                :(real,r1)
             )
         end
         5.0
    end;
  val z:int =
    let region r43:1, r45:1, e46, e42
    in   let region e44
         in  apply [r45]
                   [int,int]
                   [r45,r43]
                   [e46,e44(put(r45)),e42(e46,get(r43))]
             (fn at r43 m:int => m)
         end
         6
    end
\end{smlcode}
\caption{The instantiation of arrow effects keeps different applications of the
  same function (here \kw{apply}) apart. The output was obtained by compiling
  the program \kw{kitdemo/apply.sml} with options \kw{-print\_types},
  \kw{-print\_effects}, \kw{-no\_uncurry} and \kw{-max\_inl\_sz 0}.}  \medskip
\hrule
\label{apply.fig}
\end{figure}

In reading the output, it is useful to know that the MLKit represents effects
and arrow effects as graphs, the nodes of which are region variables, effect
variables, $\Put$, $\Get$, or \kw{U} (for ``union''; \kw{U} by itself means the
empty set).  Region variables are leaf nodes. A $\Put$ or $\Get$ node has
emanating from it precisely one edge; it leads to the region variable in
question.  An effect variable node (written \kw{e} followed by a sequence
number) is always the handle of an arrow effect; there are edges from the effect
variable to the atomic effects of that arrow effect, either directly, or via
union nodes or other effect variable nodes.  For instance,
\kw{e18(U(U,get(r15),e16))} in Figure~\ref{apply.fig} denotes an effect variable with an edge
to a union node that has edges to an empty union node, a $\Get$ node, and an
effect variable node.

When a term containing arrow effects is printed, shared nodes that have already
been printed are marked with a \kw{@}; their children are not printed again.
%For instance, in the figure, the second
%occurence of \texttt{r2} is printed as \boxml{@r2}.
In the figure, the binding occurrence of \kw{apply} has been printed with its
region-annotated type scheme. Each non-binding occurrence of \kw{apply} has been
printed with four square-bracketed lists. The first list is the actual region
arguments; the following three are instantiation lists that show the range of
the substitution by which the bound variables of the type scheme was
instantiated, in the same order as the bound variables occurred.  For example,
in the second use of \kw{apply}, \kw{r17} was instantiated to \kw{r45}.

\section{On the Lack of Region Polymorphism}

Unlike identifiers bound by \fw{fun}, lambda-bound function identifiers are
never region-polymorphic. So in an expression of the form
\begin{center}
  \lstinline!fn f => $\cdots$ f $\cdots$ f $\cdots$!
\end{center}
all the uses of $\kw{f}$ use the same regions. Indeed, because \kw{f} occurs
free in the type environment while region inference analyses the body of the
lambda abstraction, none of the regions that appear in the type of \kw{f} will
be de-allocated inside the body of the lambda abstraction. Also, such a region
must be bound outside the lambda abstraction, so any attempt to reset such a
region inside the body of the abstraction will cause the storage mode analysis
to complain (by Rule (B1) of Section~\ref{sma.sec}).

Therefore, when a function $f$ is passed as argument to another function $g$, as
in the expression \kw{$g$($f$)}, first regions are allocated for the use of $f$,
then $g$ is called, and finally, the regions are de-allocated (provided they are
not global regions).  Whether the \fw{let region} construct thus introduced
encloses the call site immediately, as in
\begin{center}
  \lstinline!let region $\rho_1,\ldots,\rho_n$ in $g$($f$) end!
\end{center}
or further out, as in
\begin{center}
  \lstinline!let region $\rho_1,\ldots,\rho_n$ in $\ldots$ $g$($f$) $\ldots$ end!
\end{center}
depends on the type and effect of the expression \kw{$g$($f$)} in the usual way:
regions can be de-allocated when they occur free neither in the type with place
of the expression nor in the type environment.

\section{Examples: \texttt{map} and \texttt{foldl}}
Consider the program\footnote{Program \boxml{kitdemo/map.sml}.}
\begin{smlcode}
  fun map f [] = []
    | map f (x::xs) = f x :: map f xs

  val x = map (fn x => x+1) [7,11]
\end{smlcode}
This formulation of \kw{map} is not the most efficient one in the MLKit if it
was not because the MLKit optimiser would uncurry the function and furthermore
specialise the function for each application point.\footnote{The output we
present in this section was obtained by passing to the MLKit compiler the
options \boxml{-maximum\_specialise\_size 0} and \boxml{-no\_uncurry}.} However
it serves to illustrate the point made in the previous section about allocating
regions in connection with higher-order functions. The region-annotated version
is listed in Figure~\ref{map.fig}.
\begin{figure}
\hrule \medskip
\begin{smlcode}
   let fun map at r1 [r39:1, r23:0] var1 =
           fn at r39 var2 =>
           case var2 of
             nil => nil
           | :: v102 =>
             let val v103 = #0 v102; val v104 = #1 v102
             in  ::
                 (var1 v103,
                  let region r35:1 in map[r35,r23] var1 v104 end
                 )at r23
             end;
       val x =
         let region r43:1, r45:INF, r49:1
         in  map[r49,r4] (fn at r43 x => x + 1) [7,11] at r45
         end
   in  {|map: (_,r1), x: _|}
   end
\end{smlcode}
\caption{Although this version of \kw{map} creates a closure for each list
  element, the region-polymorphic recursion (of \kw{map}) ensures that that
  closure is put in a region local to \kw{map}.  Thus, these closures do not
  pile up in \kw{r39}, the region of the initial argument.}
\medskip \hrule
\label{map.fig}
\end{figure}
We see that the region that appears free in the type with place of the successor
function (i.e., \kw{r43}) is allocated prior to the call of \kw{map} and that
it stays alive throughout the evaluation of the body of \kw{map}. Notice,
however, that the closures that are created when \kw{map} is applied do not pile
up in \kw{r43}, the region of the successor function. Instead, they are put in
local regions bound to \kw{r35}, one closure in each region.  Also, if we had
given some more complicated argument to \kw{map}, the body of that function
could include local \fw{region} declarations. For each list element, regions
would then be allocated, used, and then de-allocated before proceeding to the
next list element.

So it might appear that higher-order functions are nothing to worry about when
programming with regions. That is not so, however. The limitation that
lambda-bound functions are never region-polymorphic can lead to space
leaks. Here is an example:
\begin{smlcode}
  fun foldl f acc [] = acc
    | foldl f acc (x::xs)  = foldl f (f(x,acc)) xs

  val x = foldl (fn (x,acc) => 10*acc+x) 0 [7,2]
\end{smlcode}
Because \kw{f} is lambda-bound, all the pairs created by the expression
\kw{(x,acc)} will pile up in the same region. The storage mode analysis will
infer storage mode \fw{attop} for the allocation of the pair, by rule (B1) of
Section~\ref{sma.sec}; because \kw{foldl} is curried, there are several lambdas
between the formal region parameter of \kw{foldl} that indicates where the pair
should be put and the allocation point of the pair.

It does not help to uncurry \kw{foldl} and turn \kw{foldl} into a
region endomorphism:
\begin{smlcode}
  fun foldl(p as (f,[],_)) = p
    | foldl(f,x::xs,acc) = foldl(f,xs,f(x,acc))

  val x = #3(foldl(fn(x,acc) => 10*acc+x,[7,2],0))
\end{smlcode}
The storage mode analysis will still give \fw{attop} for the allocation of the
pair \kw{(x,acc)}, because the region of the pair is free in the
region-annotated type of \kw{f}, which is locally live at that point.

What if we require that \kw{f} be curried, so as to avoid the creation of the
pair altogether?\footnote{Program \boxml{kitdemo/fold2.sml}.}
\begin{smlcode}
  fun foldl f b xs =
    let fun loop(p as ([], b)) = p
          | loop(x::xs, b) = loop(xs,f x b)
    in #2(loop(xs,b))
    end
\end{smlcode}
The region-annotated version of this program appears in Figure~\ref{fold2.fig}
on page~\pageref{fold2.fig}. This saves the allocation of a pair inside loop,
although the saving is lost if the evaluation of \kw{f x} creates a closure.

In short, folding a function over a list may leak two words of memory for each
list element.

%---------------------------------------------------------
\chapter{The Function Call}
%---------------------------------------------------------

Standard ML allows function applications of the form
$$\exp_1 \exp_2$$ where $\exp_1$ is the operator and $\exp_2$ is the operand.
The syntax for function application is overloaded, in that it is used for three
different purposes in ML:
\begin{enumerate}
\item Applications of built-in operations such as \kw{+},
  \kw{=}, and \kw{:=}.
\item Applications of unary value constructors (including \kw{ref}) and unary
  exception constructors.
\item Applications of user-defined functions, that is, functions introduced by
  \fw{fn} or \fw{fun}.
\end{enumerate}
This chapter is about the last kind of function applications; in the following,
we use the term function application to stand for applications of user-defined
functions only.

Function applications are ubiquitous in Standard ML programs; in particular,
iteration is often achieved by function calls. Not surprisingly, careful
compilation of function calls is essential for obtaining good performance.

The MLKit partitions function calls into four kinds, which are implemented in
different ways.  At best, a function call is simply realised by a jump in the
target code.  The resource conscious programmer will want to know the special
cases; for example, when doing an iterative computation, it is important to know
whether the space usage is going to be independent of the number of iterations.

The MLKit performs a backwards flow analysis, called
%
\index{call conversion}%
%
{\em call conversion}, to determine what function calls are tail calls and, more
generally, what function calls fall into the four special cases. We say that
expressions produced by this analysis are
%
\index{function call!call-explicit}%
\label{call-explicit}%
%
{\em call-explicit}. One can inspect call-explicit programs by
passing the option
%
\index{print call-explicit expression@\texttt{-print\_call\_explicit\_expression}}%
%
$$\kw{-print\_call\_explicit\_expression}$$ to the MLKit compiler, and thus
check whether specific function calls in the code turn out as intended.
Call-explicit expressions are produced after regions have been dropped
(page~\pageref{bother-to-distinguish-get-n-put}) but before native code
generation.

We shall first give a brief description of the parameter passing mechanism in
general and then discuss the different kinds of function calls provided, working
our way from the most specialised (and most efficient) cases towards the default
cases.

\section{Parameter Passing}

Parameters to functions are passed either on the runtime
%
\index{stack}%
%
stack or, if possible, in
%
\index{register}%
%
registers. Also region parameters to region-polymorphic functions are passed on
the runtime stack or in registers.

\section{Tail Calls and Non-Tail Calls}
\label{tailcall.sec}

A call that is the last action of a function is referred to as a {\em tail
  call}. After region inference, the MLKit performs a tail call analysis (in one
backwards scan through the program). It is significant that the tail call
analysis happens after region inference; as we saw in Section~\ref{length.sec},
a function call that looks like a tail call in the source program may end up as
a non-tail call in the region-annotated program, because the function has to
return to free memory. The tail call analysis divides function calls into four
different kinds of calls:
\begin{quote}
\begin{description}
\item[\kw{jmp}:] Tail calls to known functions.
\item[\kw{funcall}:] Non-tail calls to known functions.
\item[\kw{fnjmp}:] Tail calls to unknown functions.
\item[\kw{fncall}:] Non-tail calls to unknown functions.
\end{description}
\end{quote}
In the sections to follow, we describe each of these kinds of calls in detail.

\section{Tail Call to Known Function (\texttt{jmp})}
\label{simplejump.sec}

A call to a
%
\index{region polymorphism}%
%
region-polymorphic function (i.e., a known function) takes the form
\begin{center}
  \lstinline!$f$ [$\rho_1$, $\ldots$, $\rho_n$] ($e_1,\ldots,e_m$)!
\end{center}
where $\rho_1$, $\ldots$, $\rho_n$ are actual region parameters to the function,
$f$ is the name of a region-polymorphic function, and $e_1 \cdots e_m$, $m \geq
1$ are value arguments to the function (we often omit the brackets $\kw{(}
\cdots \kw{)}$ when $m = 1$.) The MLKit turns such a function call into the form
\begin{center}
  \lstinline!jmp $f$ [$\rho_1$, $\ldots$, $\rho_n$] ($e_1,\ldots,e_m$)!
\end{center}
if the call appears in a tail-call position, that is, if the call is the last
thing the current function needs to do.  Because the start address of $f$ is
known during compilation (because $f$ is region-polymorphic), such a call is as
efficient as an assembly language jump to a constant label (not taking into
account the shuffling of arguments needed to match the calling convention for
$f$.

The way to avoid that a \fw{region} binding is wrapped around the function call
(and thus causes the call not to be recognised as a tail call) is to turn the
calling function into a region endomorphism, when possible.

The following is an example of how one obtains a tail call to a known
function:\footnote{Program \boxml{kitdemo/tail.sml}.}
\begin{smlcode}
  local
    fun f'(p as (0,b)) = p
      | f'(n,b) = f'(n-1,n*b)
  in
    fun f(a,b) = #2(f'(a,b))
  end
\end{smlcode}
The call-explicit version of \kw{f'} appears in Figure~\ref{tail.fig}.
\begin{figure}
\hrule \medskip
\begin{smlcode}
  fun f' [r15:inf] var2 =
      let val v96 = #0 var2
      in  case v96 of
            0 => var2
          | _ => let val v98 = #1 var2
                 in  jmp f'[sat r15] (v96 - 1, v96 * v98)sat r15
                 end
      end
\end{smlcode}
\caption{An example where a function call turns into a tail call to a known
  function.}
\medskip \hrule
\label{tail.fig}
\end{figure}

There is a more efficient version of the function \kw{f} that exploits the
MLKit's unboxing of function arguments, but in general, one can rely on unboxing
to ensure tail-calls only when the elements of the argument tuple themselves are
unboxed; otherwise there is a risk that, for each invocation, fresh regions are
introduced to hold the arguments to the call, and the call would need to return
to de-allocate these regions.

The MLKit can transform a call into a \kw{jmp} tail call even in the case that
the call appears in the body of a \fw{fn} expression.  Consider the following
two mutually recursive functions \kw{g} and \kw{h}:\footnote{Program
\boxml{kitdemo/tail2.sml} compiled with the flags \boxml{-no\_uncurry} and
\boxml{-no\_abbrev}.}
\begin{smlcode}
  fun g (n,b) = h (n-1) b
  and h 0 b = b
    | h n b = g(n,n*b)
\end{smlcode}
Here \kw{h} calls \kw{g} in a tail position. The call explicit version of the
program is listed in Figure~\ref{tail2.fig}, and indeed, the call to \kw{g} is
recognised as a tail call.
\begin{figure}
\hrule \medskip
\begin{smlcode}
   let fun g attop r1 (v134, v135) =
           let region r13:3
           in  fncall funcall h[atbot r13] (v134 - 1) v135
           end
       and h attop r1 [r17:3] var1 =
           fn attop r17 var2 =>
           case var1 of 0 => var2 | _ => jmp g[] (var1, var1 * var2)
   in  {|h: (_,r1), g: (_,r1)|}
   end
\end{smlcode}
\caption{A function call can turn into a tail call even
  in the case that the call appears in the body of a \fw{fn} expression.}
\medskip \hrule
\label{tail2.fig}
\end{figure}
Also notice that the MLKit does not try to in-line \kw{g} in \kw{h} (or
vice-versa), although such an optimisation would certainly improve on the
efficiency of the generated code. Another example of a \kw{jmp} tail call is
shown in Section~\ref{foldl.sec}.

The call-explicit program shown in Figure~\ref{tail2.fig} was compiled with the
flag \kw{-no\_abbrev}. Without this flag, the output is abbreviated in several
ways. First, \kw{fncall} and \kw{funcall} annotations are not shown and neither
are the \fw{attop} \kw{r1} annotations on top-level functions.

\section{Non-Tail Call to Known Function \index{funcall@\texttt{funcall}}(\texttt{funcall})}

In the case that a call to a known function cannot be turned into a
tail call, because the call needs to return to do more work, the call
is transformed into
\begin{center}
  \lstinline!funcall $f$ [$\rho_1, \ldots, \rho_n$] $\exp$!
\end{center}
where \kw{funcall} is the mnemonic used for non-tail calls to region-polymorphic
functions. One example is the call to \kw{h} in Figure~\ref{tail2.fig}. Here the
call to \kw{h} takes a region argument \kw{r13} and an ordinary argument
\kw{(v134 - 1)}; the call to \kw{h} returns a closure, which needs to be applied
to \kw{v135} before the function \kw{g} can de-allocate the region \kw{r13} and
return.

This case completes all possible cases of applications of region-polymorphic
functions. We now turn to function applications where the operator is not the
name of a region-polymorphic function.

\section{Tail Call to Unknown Function (\texttt{fnjmp})}

Consider the case
%
\index{fnjmp@\texttt{fnjmp}}%
%
$$\exp_1\,\exp_2$$ where (a) the call is a tail call and (b) $\exp_1$ is not the
name of a region-polymorphic function.

Here $\exp_1$ is evaluated to a closure in memory, pointed to by a
%
\index{standard closure register}%
\index{register!standard closure}%
%
{\em standard closure register}. Then $\exp_2$ is evaluated and the result put
in a
%
\index{standard argument register}%
\index{register!standard argument}%
%
{\em standard argument register}. The first word in the closure contains the
address of the code of the function. This address is fetched into a third
register and a jump to the address is made.  Because the call is a tail call, it
induces no allocation, neither on the stack nor in regions.  It is thus as
efficient as an indirect jump in assembly language.

%To avoid that $\exp_2$ puts values
%in fresh regions (which would make the call a non-tail call) one
%can ``disable'' region polymorphism of $f$ as explained in Section~\ref{tailcall.sec}.

The mnemonic used in call-explicit expressions for this special case is
\begin{center}
  \lstinline!fnjmp $\exp_1$ $\exp_2$!
\end{center}

\section{Non-Tail Call to Unknown Function (\texttt{fncall})}

Consider the case
$$\exp_1\,\exp_2$$ where (a) the call is not a tail call and (b) $\exp_1$ is not
the name of a region-polymorphic function.

Applications of this form are implemented as follows. First $\exp_1$ is
evaluated and the result, a pointer to a closure, is stored in the
%
\index{standard closure register}%
\index{register!standard closure}%
%
standard closure register. Then $\exp_2$ is evaluated and stored in the
%
\index{standard argument register}%
\index{register!standard argument}%
%
standard argument register.  Then live registers and a return address are pushed
onto the stack and a jump is made to the code address that is stored in the
first word of the closure pointed to by the standard closure register. Upon
return, registers are restored from the stack.

The mnemonic used in call-explicit expressions for this special case is
\begin{center}
  \lstinline!fncall $\exp_1$ $\exp_2$!
\end{center}

\section{Example: Function Composition}

The Standard ML Basis Library declares function composition as
follows\footnote{Program \boxml{kitdemo/compose.sml}.}
\begin{smlcode}
  fun (f o g) x = f(g x)
\end{smlcode}
The resulting call-explicit expression produced by the MLKit when compiled with
the flags \kw{-no\_uncurry} and \kw{-no\_abbrev} is
\begin{smlcode}
  fun o attop r1 [r21:3] (v120, v121) =
      fn attop r21 x => fnjmp v120 (fncall v121 x)
\end{smlcode}
Notice that
%
\index{o@\texttt{o}}%
%
\boxml{f o g} first creates a closure in \boxml{r21} and then returns.  The
closure is of size three words and contains a pointer to the code for the
function and pointers to the closures for \kw{f} and \kw{g}. When called, the
created function first performs a non-tail call of \kw{g} and then a tail call
to \kw{f}.

\section{Example: \texttt{foldl} Revisited}
\label{foldl.sec}

Consider the following declaration of folding over lists:\footnote{Program
\boxml{kitdemo/fold1.sml}.}
\begin{smlcode}
  fun foldl f b xs =
    case xs of
      [] => b
    | x::xs' => foldl f (f x b) xs'
\end{smlcode}
The recursive call of
%
\index{foldl@\texttt{foldl}}%
%
\kw{foldl} is a call of a known function, but not a tail call; \kw{foldl}
returns a closure, which is subsequently applied to the value of \kw{(f x
  b)}. This too returns a closure, which in turn is applied to \kw{xs'}.  The
resulting call-explicit expression is shown in Figure~\ref{fold1.fig}.
\begin{figure}
\hrule \medskip
\begin{smlcode}
  fun foldl attop r1 [r41:4, r39:4] f =
      fn attop r41 b =>
      fn attop r39 xs =>
      case xs of
        nil => b
      | :: v100 =>
        let val v101 = #0 v100; val v102 = #1 v100; region r35:4
        in  fncall
             let region r37:4
             in  fncall
                  funcall foldl[atbot r37,atbot r35] f
                  (fncall fncall f v101 b)
             end
             v102
        end
\end{smlcode}
\caption{The straightforward implementation of \kw{foldl} uses space linear in
  the length of the list. (Program \kw{kitdemo/fold1.sml} compiled with the
  flags \kw{-no\_uncurry} and \kw{-no\_abbrev}.)}
\medskip \hrule \label{fold1.fig}
\end{figure}
Notice that upon each iteration, fresh regions for holding two closures are
being allocated for the duration of the recursive call.  Thus, space usage is
linear in the length of the list (4 words for each list cell, to be precise).

An alternative version of \kw{foldl} assumes that \kw{f} is
curried:\footnote{Program \boxml{kitdemo/fold2.sml}.}
\begin{smlcode}
  fun foldl f b xs =
    let fun loop(p as ([], b)) = p
          | loop(x::xs, b) = loop(xs,f x b)
    in
        #2(loop(xs,b))
    end
\end{smlcode}
It is compiled into the call-explicit expression in
Figure~\ref{fold2.fig}.
\begin{figure}
\hrule \medskip
\begin{smlcode}
  fun foldl attop r1 [r63:3, r61:3] f =
      fn attop r63 b =>
      fn attop r61 xs =>
      let region r27:1;
          fun loop atbot r27 [r39:inf] var2 =
              let val v107 = #0 var2
              in  case v107 of
                    nil => var2
                  | :: v109 =>
                    let val v110 = #0 v109;
                        val v111 = #1 v109;
                        val v112 = #1 var2
                    in  jmp loop[sat r39]
                                (v111,
                                 fncall fncall f v110 v112
                                )sat r39
                    end
              end;
          region r57:inf
      in  #1 (funcall loop[atbot r57] (xs, b)atbot r57)
      end
\end{smlcode}
\caption{The result of compiling the efficient version of \kw{foldl}
  (\kw{kitdemo/fold2.sml}) is an iterative function that avoids argument pairs
  piling up in one region.}  \medskip \hrule
\label{fold2.fig}
\end{figure}
Here the loop is implemented as a jump and there is no new allocation in each
iteration, except, of course, for the allocation that \kw{f} might
make.\footnote{All the allocations made by the calls to \boxml{f} (one call for
each element of the list) are put in the same regions.  If the list is very long
or the values produced large, it may be a good idea to copy the final result to
separate regions.}

As an exercise, consider the following variant of \kw{foldl}, which assumes that
\kw{f} takes a pair as an argument:\footnote{Program \boxml{kitdemo/fold3.sml}.}
\begin{smlcode}
  fun foldl' f b xs =
    let fun loop(p as ([], b)) = p
          | loop(x::xs, b) = loop(xs,f(x,b)))
    in
        #2(loop(xs,b))
    end
\end{smlcode}
Interestingly, this program contains a potential space leak. Can you detect it?
If not, the MLKit will tell you when you compile the program if you pass the
compiler the option \kw{-warn\_on\_escaping\_puts}.

Finally, we consider the following version of \kw{foldl}, which resembles the
implementation of the \kw{List.foldl} function:\footnote{Program \boxml{kitdemo/fold4.sml}.}
\begin{smlcode}
  local
    fun foldl f e [] = e
      | foldl f e (x::xs) = foldl f (f(x,e)) xs
  in
    val a = foldl (op +) 0 [0,1,2]
  end
\end{smlcode}
Figure~\ref{fold4.fig} shows the call-explicit version of the program. We see
that the function \kw{foldl} is specialised to the supplied function. Notice
that MLKit will specialise small functions, such as \kw{List.foldl}, across
compilation unit boundaries, which means that MLKit in general generates very
efficient code for calls to such functions.

\begin{figure}
\hrule \medskip
\begin{smlcode}
   let val a =
         let region r9:0;
             fun foldl atbot r9 (var2, var3) =
                 case var3 of
                   nil => var2
                 | :: v109 =>
                   let val v110 = #0 v109; val v111 = #1 v109
                   in  jmp foldl (v110 + var2, v111)
                   end;
             region r21:inf
         in  foldl (0, [0,1,2] attop r21)
         end
   in  {|a: _|}
   end
\end{smlcode}
\caption{The result of applying and specialising the Basis Library version of
  \kw{List.foldl}.}  \medskip \hrule
\label{fold4.fig}
\end{figure}


%---------------------------------------------
\chapter{ML Basis Files and Modules}
\label{mlb_and_modules.chap}
%---------------------------------------------
In Section \ref{tryit.sec} we described how to compile and run single-file
programs. In this chapter, we describe how to program in the large with the
MLKit, using
%
\index{Standard ML!Modules}%
%
Standard ML Modules and the possibility of organising source files in ML Basis
Files. The MLKit fully supports Standard ML Modules and it has a sophisticated
system for avoiding unnecessary recompilation. In the following section, we
describe the notion of ML Basis Files. We then turn to show how to program with
structures, signatures, and functors.  To enable the programmer to write
efficient programs using the Modules language, we shall also explain how the
MLKit compiles Modules language constructs.

\section{ML Basis Files}
An ML Basis File, in short MLB-file,
%
\index{ML Basis File}%
\index{{MLB}-file}%
%
is a file that lists the SML source files that make up a project or a
library. An MLB-file can also
%
\index{referencing an MLB-file}%
%
\emph{reference} other MLB-files, so one can organise projects in a hierarchical
manner. MLB-files are enforced not to be cyclic.

MLB-files have file extension
%
\index{.mlb@\texttt{.mlb}}%
%
\kw{.mlb}.  The content of an MLB-file is a \emph{basis declaration}, for which
the
%
\index{MLB-file!grammar}%
%
grammar is given in Figure~\ref{mlb_grammar.fig}. We assume a denumerable
infinite set of \emph{basis identifiers} Bid, ranged over by \emph{bid}. We use
\emph{longbid} to range over \emph{long basis identifiers}, that is, non-empty
lists of basis identifiers separated by a punctuation letter (\kw{.}). Basis
identifiers can be used for giving a name to a group of compilation units and
allow for expressing source dependencies, exactly, as a directed acyclic graph,
within one MLB-file.

\begin{figure}
\hrule\medskip
\[
\begin{array}{rcll}
  \emph{bdec} & ::= & \emph{bdec}~ \emph{bdec} & \mbox{sequential~basis~declaration} \\
            & |   & \varepsilon & \mbox{empty~basis~declaration} \\
            & |   & \texttt{local}~ \emph{bdec}~\texttt{in}~\emph{bdec}~\texttt{end} & \mbox{local~declaration} \\
            & |   & \texttt{basis} ~\emph{bid}~\texttt{=}~\emph{bexp} & \mbox{basis~identifier~binding} \\
            & |   & \texttt{open} ~\emph{longbid}* & \mbox{opening~of~a~basis}\\
            & |   & \emph{atbdec} \\
            & |   & \emph{path}.\texttt{mlb} & \mbox{include} \\ \\
  \emph{atbdec} & ::= & \emph{path}.\texttt{sml} & \mbox{source~file} \\
              & |   & \emph{path}.\texttt{sig} & \mbox{source~file} \\ \\
  \emph{bexp} & ::= & \texttt{bas}~ \emph{bdec}~ \texttt{end} & \mbox{basis~declaration~grouping} \\
            & |   & \texttt{let}~\emph{bdec}~\texttt{in}~\emph{bexp}~\texttt{end} & \mbox{let~expression} \\
            & |   & \emph{longbid}
\end{array}
\]
\caption{Grammar for MLB-files, i.e., files with extension \kw{.mlb}.  For some
  file extension \kw{.}\emph{ext}, {\it path}\kw{.}\emph{ext} denotes either an
  absolute path or a relative path (relative to the directory in which the
  MLB-file is located) to a file on the underlying file system.}
\label{mlb_grammar.fig}
\medskip \hrule
\end{figure}
In an MLB-file, one can reference source files and other MLB-files using
absolute or relative
%
\index{path!absolute}%
\index{path!relative}%
%
paths.  Relative paths are relative to the location of the MLB-file.  Paths can
reference environment variables using the \kw{\$(ENVVAR)} notation, where
\kw{ENVVAR} is an environment variable.

Until now, we have seen a few examples of MLB-files that reference the Basis
Library, using the \kw{\$(SML\_LIB)} environment variable (see
Section~\ref{polyrec.sec} for such an example). In Section~\ref{functors.sec},
we present an example of an MLB-file that reference other MLB-files. In
Section~\ref{comp_and_link_with_C.sec}, we shall see an example of how an
MLB-file can be compiled and linked with external object files, produced with a
C compiler, for instance.  MLB-files may contain Standard ML style
%
\index{MLB-file!comments in}%
\index{comments!in MLB-file}%
%
comments. The declared identifiers of an MLB-file is the union of the
identifiers being declared by source files in the MLB-file, excluding source
files that are included using \kw{local}. As an example of the use of basis
identifiers and \kw{local} to limit what identifiers are declared by an
MLB-file, consult the MLB-file \kw{basis/basis.mlb}.

Every source file must contain a Standard ML top-level declaration; the scope of
the declaration is all the subsequent source files mentioned in the MLB-file and
all other MLB-files that reference this MLB-file. Thus, a source file may depend
on source files mentioned earlier in the MLB-file and on other referenced
MLB-files.  The meaning of an entire MLB-file is the meaning of the top-level
declaration that would arise by expanding all referenced MLB-files and then
concatenating all the source files listed in the MLB-file (with appropriate
renaming of declared identifiers of source files that are included using
\kw{local}), in the order they are listed, except that each MLB-file is executed
only the first time it is imported.

The MLKit has a system for managing compilation and recompilation of
%
\index{MLB-files}%
%
MLB-files.  The system guarantees that the result of first modifying one or more
source files and then using the separate compilation system to rebuild the
executable is the same as if all
%
\index{source file}%
%
source files were
%
\index{recompilation}%
%
recompiled.

Thus, the separate compilation system is a way of avoiding recompiling parts of
a (possibly) long sequence of declarations, while ensuring that the result is
always the same as if one had compiled the entire program from scratch.  As an
example, consider the MLB-file \kw{kitdemo/scan.mlb} for the text scanning
example of Section~\ref{scan.sec}. It contains the following three lines:
\begin{scriptcode}
  $(SML_LIB)/basis/basis.mlb
  lib.sml
  scan.sml
\end{scriptcode}

\noindent
The source files for the project are \kw{lib\_posix.sml} and \kw{scan.sml},
which are both located in the directory where \kw{scan.mlb} is located. Whereas
each of the source files \kw{lib.sml} and \kw{scan.sml} depends on the Basis
Library, the source file \kw{scan.sml} also depends on \kw{lib.sml}.

Compiling an MLB-file is easy; simply give it as an argument to the MLKit
executable. When the MLB-file is first compiled, the MLKit detects automatically
when a source file has been modified (by checking file modification
dates). After a project has been successfully compiled and linked, it can be
executed by running the command
%
\index{run@\texttt{run}}%
%
\begin{scriptcode}
  ./run
\end{scriptcode}
in the working directory.

The MLKit compiles each source file of an MLB-file one at a time, in the order
mentioned. A source file is compiled under a given set of assumptions, which
provides, for instance, region-annotated type schemes with places for free
variables of the source file. Also, compilation of a source file gives rise to
exported information about declared identifiers. Exported information may occur
in assumptions for source files mentioned later in the MLB-file.

There are two rules that govern when a source file is recompiled.  A source file
is recompiled if either (1) the user has modified the source file or (2) the
assumptions under which the source file was previously compiled have changed. To
avoid unnecessary recompilation, assumptions for a source file depend on only
its free identifiers.  Moreover, if a source file has been compiled earlier, the
MLKit seeks to
%
\index{matching}%
%
{\em match\/} the new exported information to the old exported information by
renaming generated names to names generated when the source file was first
compiled. Matching allows the compiler to use fresh names (stamps) for
implementing generative data types, for instance, and still achieve that a
source file is not necessarily
%
\index{recompilation!cut-off}%
%
recompiled even though source files, on which it depends, are modified.

Let us assume that we modify the source file \kw{lib.sml} of the text scanning
example, after having compiled the MLB-file \kw{kitdemo/scan.mlb} once. When
compiling the MLB-file again, the MLKit checks whether the assumptions under
which the source file \kw{scan.sml} was compiled have changed, and if so,
recompiles \kw{scan.sml}.  Modifying only comments or string constants inside
\kw{lib.sml} or extending its set of declared identifiers does not trigger
recompilation of \kw{scan.sml}.

Some of the information a source file depends on is the ML type schemes of its
free variables. It also depends on, for example, the region-annotated type
schemes with places of its free variables.  Thus it can happen that a source
file is recompiled even though the ML type assumptions for free variables are
unchanged. For instance, the region-annotated type scheme with place for a free
variable may have changed, even though the underlying ML type scheme has not.

As an example, consider what happens if we modify the function \kw{readWord} in
the source file \kw{lib.sml} so that it puts its result in a global region. This
modification will trigger recompilation of the source file \kw{scan.sml},
because the assumptions under which it was previously compiled have changed.
Besides changes in region-annotated type schemes with places, changes in
multiplicities and in physical sizes of formal region variables of functions may
also trigger recompilation.


\section{Structures}

The support for Modules together with the possibility of dividing top-level
declarations into different source files provide a mechanism for programming in
the large. In the MLKit, structures exist only at compile time.  Thus one need
not worry where
%
\index{structure declaration}%
%
structures live at runtime.

We illustrate the compile-time nature of structures with the following
example. Consider the MLB-file \kw{PolySet.mlb},\footnote{MLB-file:
\boxml{kitdemo/PolySet.mlb}.} which mentions the source files \kw{PolySet.sml},
\kw{INT\_SET.sml}, and \kw{IntSet.sml}. The source file \kw{PolySet.sml}
contains the following top-level declaration:
\begin{smlcode}
  structure PolySet =
    struct
      type 'a set = 'a list
      val empty = []
      fun singleton x = [x]
      fun mem(x,[]) = false
        | mem(x,y::ys) = x=y orelse mem(x,ys)
      fun union(s1,[]) = s1
        | union(s1,x::s2) = if mem(x,s1) then union(s1,s2)
                            else x::union(s1,s2)
    end
\end{smlcode}
The code generated by the MLKit for the \kw{PolySet} structure is exactly as if
the declarations were written outside of a structure.  As a consequence, when
you refer to a component of a structure using qualified identifiers (e.g.,
\kw{PolySet.mem}), no code is generated for fetching the component from the
structure. Moreover, when opening a structure, using the
%
\index{open declaration}%
%
\lstinline{open} declaration, no code is generated for rebinding the identifiers
that become visible.

\section{Signatures}

\index{signature declaration}%
%
In the MLKit, signature declarations exist only at compile time. That is, a
signature declaration does not result in any code being generated. The source
file \kw{INT\_SET.sml} in the MLB-file \kw{PolySet.mlb}, mentioned earlier,
contains the signature declaration
\begin{smlcode}
  signature INT_SET =
    sig
      type 'a set
      val empty : int set
      val singleton : int -> int set
      val mem : int * int set -> bool
      val union : int set * int set -> int set
    end
\end{smlcode}

Signatures are used in two contexts; for specifying arguments to functors and
for providing restricted views of structures using
%
\index{signature constraint!transparent}%
%
transparent and
%
\index{signature constraint!opaque}%
%
opaque signature constraints. We defer the discussion of the use of signatures
for specifying arguments to functors to Section~\ref{functors.sec}.

Transparent signature constraints may both restrict components from a structure
and make polymorphic components less polymorphic. Moreover, opaque signature
constraints may also make type components of structures abstract. Consider the
structure declarations located in the source file \kw{kitdemo/IntSet.sml}:
\begin{smlcode}
  structure IntSet1 : INT_SET = PolySet
  structure IntSet2 :> INT_SET = PolySet
\end{smlcode}

\noindent
No code is generated for the structure declarations. Instead, the compiler
memorises that if you refer to the long identifier \kw{IntSet1.mem}, for
instance, then it is actually \kw{PolySet.mem} that is applied with type
instance \kw{int}.

As for the second declaration, opaque signature constraints are eliminated at
compile time (after elaboration) and transformed into transparent signature
constraints.

\section{Functors \label{functors.sec}}

\index{functor}%
\index{specialisation!functor}%
%
Functors map structures to structures. The MLKit specialises a functor every
time it is applied.  Thus, types that are abstract for the programmer (inside a
functor body) become visible to the compiler.  Region-annotated type schemes and
other information about identifiers in the actual functor argument are available
when the MLKit compiles the functor body.

For practical reasons, it is important that not all functor applications are
expanded at once, since this could cause intermediate representations of
programs to become as large as (or even much larger than) the entire
program. Further, non-restricted in-lining could lead to unnecessary
recompilation upon modification of source files.  Instead, the largest structure
declarations not containing functor applications are compiled into separate
chunks of machine object code.  Assumptions for compiling these structure
declarations are memorised, so that the generated code can be reused upon
modification of source files if the assumptions do not change.

Consider the following MLB-file:\footnote{MLB-file: \boxml{kitdemo/Set.mlb}.}
\begin{scriptcode}
  $(SML_LIB)/basis/basis.mlb
  local utils/utils.mlb
  in SET.sml Set.sml SetApp.sml
  end
\end{scriptcode}
The MLB-file reference the MLB-file \kw{utils.mlb} from the \kw{utils}
directory.\footnote{MLB-file: \boxml{kitdemo/utils/utils.mlb}.} This MLB-file
provides a structure \kw{ListUtils} that contains the function \kw{pr\_list}
with type scheme
%
\lstinline!('a -> string) -> 'a list -> string!.
%
The content of the file \kw{Set.sml} is listed in Figure~\ref{Set.fig}. It
declares the functor \kw{Set}, which takes as arguments the element type for the
set, an ordering function on elements, and a function for providing a string
representation of elements.
\begin{figure}[ht]
\hrule \medskip
\begin{smlcode}
  functor Set (eqtype elem (*total order*)
               val lt : elem * elem -> bool
               val pr : elem -> string)
       : SET where type elem = elem =
    struct
      type elem = elem
      type set = elem list
      val empty : set = []
      fun singleton e = [e]
      fun mem x l =
        let fun mem' [] = false
              | mem' (y::ys) = if lt(y,x) then mem' ys
                               else not(lt(x,y))
        in mem' l
        end
      fun union(s1,s2) =
        let fun U (t as ([], [], acc)) = t
              | U ([], y::ys, acc) = U([], ys, y::acc)
              | U (x::xs, [], acc) = U(xs, [], x::acc)
              | U (s1 as x::xs, s2 as y::ys, acc) =
                  U(if lt(x,y) then (xs, s2, x::acc)
                    else if lt(y,x) then (s1, ys, y::acc)
                    else (xs, ys, y::acc))
        in rev(#3(U(s1, s2, [])))
        end
      val pr = fn s => ListUtils.pr_list pr s
    end
\end{smlcode}
\caption{The source file \kw{kitdemo/Set.sml}.}
\medskip \hrule \label{Set.fig}
\end{figure}

The source file \kw{SetApp.sml} is listed in Figure~\ref{SetApp.fig}. It
constructs a structure \kw{IntSet} by applying the functor \kw{Set} to
appropriate arguments including an ordering operation on integers and an
operation for giving the string representation of an integer. The \kw{IntSet}
structure is used for constructing a set \kw{{2,5}}, which the program prints
using the built-in \kw{print} function.
\begin{figure}[ht]
\hrule \medskip
\begin{smlcode}
  structure IntSet = Set(type elem = int
                         val lt = op <
                         fun pr a = Int.toString a)
  open IntSet
  val _ = print (pr (union(singleton 2, singleton 5)))
\end{smlcode}
\caption{The source file \kw{kitdemo/SetApp.sml}.}
\medskip \hrule \label{SetApp.fig}
\end{figure}

The body of the \kw{Set} functor is instantiated to form the code for the
\kw{IntSet} structure. The result of instantiating the \kw{Set} functor is first
translated into a $\Lam$ program and then translated into a $\MulExp$
program. The $\MulExp$ call-explicit code for the \kw{mem} function is shown in
Figure~\ref{set_inst_mulexp.fig}.
\begin{figure}[ht]
\hrule \medskip
\begin{smlcode}
  fun mem (x, l) =
      let region r55:1;
          fun mem' atbot r55 var2 =
              case var2 of
                nil => false
              | :: v191 =>
                let val v192 = #0 v191; val v193 = #1 v191
                in  case v192 < x of
                      true => jmp mem' v193
                    | _ =>
                      case x < v192 of true => false | _ => true
                end
      in  mem' l
      end
\end{smlcode}
\caption{The $\MulExp$ call-explicit code for the \kw{mem} function resulting
  from instantiating the \kw{Set} functor.}
\medskip \hrule
\label{set_inst_mulexp.fig}
\end{figure}

Notice that the code for the \kw{mem}~function holds inlined code for the
\kw{lt}~function; because the function is sufficiently small, the MLKit
propagates its intermediate representation across module boundaries.

%---------------------------------------------------------
\chapter{Garbage Collection}
\label{gc.chap}
%---------------------------------------------------------
The MLKit supports reference tracing garbage collection in combination with the
region memory model \cite{hallenberg99,het02}.  Garbage collection is also
possible with region profiling enabled.

The reference-tracing garbage collector is enabled by default and, as we have
seen earlier, garbage collection can be disabled by passing the \kw{-no\_gc}
option to the MLKit compiler at compile time. As we shall see, it is also
possible to disable garbage collection at runtime for a program that has been
compiled with garbage collection enabled.

The MLKit also features generational reference-tracing garbage collection
(option \kw{-gengc}), which in some cases is superior to ordinary
reference-tracing garbage collection, but which may also cause additional
fragmentation \cite{elshaljfp21}.

\section{Dangling Pointers}
The region type system supports deallocation of memory that is not accessed in
the remainder of the execution of the program. Because of this principle, the
execution model may lead to {\em dangling pointers}, that is, pointers that
point into memory that has been discharged. When garbage collection is enabled,
the region type system is modified slightly so as to guarantee that no dangling
pointers occur during execution \cite{elsman:tldi03,10.1145/3591229}. The
following example illustrates how the enabling of garbage collection changes the
way programs are compiled:
\begin{smlcode}
  val f = let val x = ref (2, [1])
          in fn y => (#1 (!x), y)
          end
  val r = f 5
\end{smlcode}
When garbage collection is disabled, the program is compiled into the following
MulExp program:\footnote{Compiled with \boxml{mlkit -no\_gc
  -maximum\_inline\_size 0 -Ppse -w 40 dangling.sml} from within the
\boxml{kitdemo} directory.}
\begin{smlcode}
  val f =
    let region r9:inf;
        val x = ref attop r6 (2, [1] attop r9)attop r4
    in  fn attop r1 y => (#0 (!x), y)attop r4
    end
  val r = fncall f 5
\end{smlcode}
Notice here that region \kw{r9}, which contains the list \kw{[1]}, is
de-allocated before the function \kw{f} is applied to the value \kw{5}. If we
chose to run this program together with a reference tracing garbage collector, a
fatal error could occur: The memory that contains the list \kw{[1]} could be
reused for other purposes at the time the garbage collector tries to trace the
dangling pointer.

Figure~\ref{dangling_gc.fig} shows the MulExp program produced when garbage
collection is enabled.\footnote{Compiled with \boxml{mlkit -gc
  -maximum\_inline\_size 0 -Ppse -w 50 dangling.sml} from within the
\boxml{kitdemo} directory.}
\begin{figure}[ht]
\hrule \medskip
\begin{smlcode}
  val f =
    let val x = ref attop r6 (2, [1] attop r4)attop r4
    in  fn attop r1 y => (#0 (!x), y)attop r4
    end
  val r = fncall f 5
\end{smlcode}
\caption{The $\MulExp$ program produced when compiling the program
  \kw{kitdemo/dangling.sml} with garbage collection enabled. To avoid dangling
  pointers when garbage collection is enabled, all values in the closure for
  \kw{f} are kept alive as long as the closure itself.}  \medskip \hrule
\label{dangling_gc.fig}
\end{figure}
When garbage collection is enabled, the MLKit makes sure that all values stored
in a closure are kept live as long as the closure is live.  Assume that the type
with place $\mu$ of the function associated with the closure is on the form
$(\mu_1 \ar{\epsilon.\varphi} \mu_2, \rho_0)$.  The MLKit enforces the
restriction by requiring that for each region variable $\rho$ that occur free in
the type of free variables of the function (those variables for which values are
stored in the closure at runtime), $\rho$ occur free in $\mu$. In the
implementation, the requirement may lead to extra $\Get$ effects being added to
$\epsilon.\varphi$ when garbage collection is enabled. In the example, an
imposed $\Get$ effect on the arrow effect in the type for \kw{f} makes it
impossible to wrap a {\tt region} binding around the binding for \kw{f}. (See
\cite[page 50]{total93}, \cite{elsman:tldi03}, and
\cite{gcsafety-revisited-tr-2022,10.1145/3591229} for more information about
this requirement.)

\section{Scanning Text Files with Stream IO and Garbage Collection}

In Section~\ref{scan.sec}, we saw how we could use basic non-buffered \kw{Posix}
IO operations for scanning text files in constant space. The Standard ML Basis
library, however, also features a stream-based \kw{TextIO} structure that
supports arbitrary look-ahead, buffering, stream-redirection, and many other
features \cite{basislib2004}. Unfortunately, as mentioned in
Section~\ref{scan.sec}, this functionality does not work well together with
MLKit's region based memory management, unless combined with a mechanism for
dynamically garbage collecting regions. We now consider a modified version of
the the text scanning program listed in Section~\ref{scan.sec} that uses the
\kw{TextIO.inputN} function for file reading, instead of using \kw{Posix}
buffered IO.

Figure~\ref{scan-stream.fig} shows two region profiles for the modified text
scanning program.\footnote{MLB-file: \boxml{scan\_stream.mlb}.} We see that the
reference-tracing garbage collector periodically cleans up the global regions
\kw{r1} and \kw{r4}, which tends to grow steadily without garbage collection.

\begin{figure}
\includerp{scan_stream_nogc.pdf}

\includerp{scan_stream.pdf}

\caption{Two region profiles of text scanning using buffered stream-based IO
  operations. The top region profile is with reference-tracing garbage
  collection disabled and the bottom region profile is with reference-tracing
  garbage collection enabled.}
\label{scan-stream.fig}
\end{figure}


\section{Instrumenting the Executable}
Executables produced by the MLKit with garbage collection enabled can be
instrumented by use of command-line options. For instance, if the MLKit has
produced a file \kw{run}, one can pass the option \kw{-verbose\_gc} to \kw{run}
to enable the printing of garbage collection information at runtime. An overview
of available command-line options is shown by passing the option \kw{-help} to
the generated executable: {\small
\begin{scriptcode}
  Usage: ./run
        [-help, -h]
        [-disable_gc | -verbose_gc] [-heap_to_live_ratio d]
    where
        -help, -h                Print this help screen and exit.

        -disable_gc              Disable garbage collector.
        -verbose_gc              Show info after each collection.
        -heap_to_live_ratio d    Use heap to live ratio d, ex. 3.0.
\end{scriptcode}
}

\part{System Reference}

%---------------------------------------------------------
\chapter{Region Profiling}
\label{useOfProf.sec}
%---------------------------------------------------------
We have already seen several examples of the use of the profiler. We shall now
explain in more detail how to profile programs. For example, we shall see how
one can find out precisely what allocation points in the program contribute to
allocation in a particular region.

The profiler consists of several tools that can be used to analyse the dynamic
memory behavior of a program. First of all, the profiler lets you create graphs
of the dynamic memory usage of the program. Three different kinds of graphs may
be created:
\begin{itemize}
\item A
  \index{region profile}%
  \index{profile!region}%
  %
  {\em region profile\/} is a graph that gives a global view of the memory usage
  by showing the total number of bytes allocated in regions and on the stack as
  a function of time. In the graph, regions that arise from the same
  \begin{center}
    \lstinline{region} $\rho$
  \end{center}
  construct are collected into one colored band, labeled $\rho$. The region
  variables that label bands are always global or \lstinline{region}-bound, never
  formal region parameters.
\item An
  \index{object profile}%
  \index{profile!object}%
  %
  {\em object profile\/} is a graph that, for a particular region, shows the
  objects allocated in the region, with one colored band for each allocation
  point in the region-annotated program\footnote{Every occurrence of an
  \lstinline{at} in the region-annotated program is an allocation point.}. Each
  allocation point is annotated with a
  %
  \index{program point}%
  %
  {\em program point}, which is a unique number that identifies the
  allocation.\footnote{Program points are unique. In particular, for a project
  with two program units, the program points in the region-annotated programs
  for the two units will be distinct.}  To inspect region-annotated programs
  with program points, pass the MLKit compiler the option
  \kw{-print\_program\_points} in addition to the option
  \kw{-print\_call\_explicit\_expression}, say.\footnote{Program points are
  annotated during physical size inference.}

  If you have an object profile showing that program point \kw{pp42}, say,
  contributes with allocation, you can search for \kw{pp42} in the
  region-annotated program and thus find the construct that caused the
  allocation.
\item A
  \index{stack profile}%
  \index{profile!stack}%
  %
  {\em stack profile\/} is a graph that shows the stack memory usage, as a
  function of time.
\end{itemize}

In addition to the possibility of generating programs with program
points, it is also possible, during compilation, to generate a
%
\index{region flow graph}%
%
{\em region flow graph}, which shows how regions may be passed around at runtime
when region-polymorphic functions are applied. The region flow graph comes in
handy when profiling large programs and when one wants to find out why a formal
region variable is instantiated to a certain \lstinline{region}-bound region
variable.

The following example clarifies the use of a region flow graph.  Suppose the
region profile shows that \kw{r5} is responsible for most of the memory usage.
Further, suppose an object profile of \kw{r5} shows that program point
\kw{pp345} is responsible for most of the allocation.  Searching for \kw{pp345}
in the region-annotated program, you may find that the allocation at \kw{pp345}
is into some other region variable, \kw{r34}, say.  Here \kw{r34} will be a
formal region parameter of a region-polymorphic function that at runtime has
been instantiated to \kw{r5} by one or more calls of region-polymorphic
functions.  You can now use the region flow graph to find the cascade of region
polymorphic applications that ends up instantiating \kw{r34} to \kw{r5}.

The profiling process is sketched in Figure~\ref{profStrategy.fig}.
\setlength{\unitlength}{6mm}
\newcommand{\picbox}[1]{\framebox(7,4){\parbox{38mm}{\begin{center}
        #1 \end{center}}}}
\begin{figure}
\hrule \medskip
\begin{center}
\begin{picture}(18,17)
\put(2,0){\picbox{Generate profile \\ with {\tt rp2ps}}}
\put(2,6){\picbox{Choose runtime \\ profiling strategy \\ and execute}}
\put(2,12){\picbox{Choose compile-time \\ profiling strategy \\ and compile}}
\put(11,0){\dashbox{.5}(7,4){\parbox{38mm}{\begin{center}
        Region profile, object profile, or stack profile \end{center}}}}
\put(11,6){\dashbox{.5}(5,3){\parbox{20mm}{\begin{center} data file {\tt profile.rp} \end{center}}}}
\put(11,11){\dashbox{.5}(7,2){\parbox{38mm}{\begin{center}
        Region flow graph \end{center}}}}
\put(11,15){\dashbox{.5}(7,2){\parbox{38mm}{\begin{center}
        Program annotated with program points \end{center}}}}
\put(9,15){\vector(2,1){2}}
\put(9,13){\vector(2,-1){2}}
\put(9,8){\vector(2,0){2}}
\put(9,2){\vector(2,0){2}}
\put(9,8){\vector(2,0){2}}
\put(5.4,12){\vector(0,-1){2}}
\put(5.6,12){\vector(0,-1){2}}
\put(3.9,4){\vector(0,1){2}}
\put(4.1,4){\vector(0,1){2}}
\put(6.9,6){\vector(0,-1){2}}
\put(7.1,6){\vector(0,-1){2}}
\put(11,7){\vector(-2,-3){2}}
\put(0.9,1.9){\line(0,1){12.2}}
\put(1.1,2.1){\line(0,1){11.8}}
\put(1.1,2.1){\line(1,0){0.9}}
\put(0.9,1.9){\line(1,0){1.1}}
\put(0.9,14.1){\vector(1,0){1.1}}
\put(1.1,13.9){\vector(1,0){0.9}}
\end{picture}
\caption{Overview of the profile process. The process sometimes requires the
  programmer to refine the runtime profiling strategy, or even the compile-time
  profiling strategy. Dotted boxes represent output from the compiler, from
  executing the program, and from using the tool \kw{rp2ps}, which generates
  Postscript graphs from the exported data file.}
\label{profStrategy.fig}
\end{center}
\medskip
\hrule
\end{figure}

%\renewcommand{\picbox}[1]{\framebox(5,3){\scriptsize{\parbox{22mm}{\begin{center}
%        #1 \end{center}}}}}
%\newcommand{\vectorr}[1]{\vector(1,0){1}
%  \makebox(-1,1)[t]{\scriptsize{#1}}}
%\setlength{\unitlength}{0.5cm}
%\begin{figure}[ht]
%\hrule
%\begin{center}
%\begin{picture}(29,8)
%\put(0,4){\picbox{Choose \\ Compile-Time \\ Profiling \\ Strategy}}
%\put(6,4){\picbox{Compile ML Source Program with MLKit compiler}}
%\put(12,4){\picbox{Choose Target \\ Profiling Strategy}}
%\put(18,4){\picbox{Execute Target Program \\ (\texttt{run} $\ldots$)}}
%\put(24,4){\picbox{Generate \\ Profiles \\ with the graph \\ generator \texttt{rp2ps}}}
%\put(8,4){\vector(-1,-1){2}}
%\put(2.5,0){\dashbox{0.3}(6.0,2){\scriptsize{\parbox{40mm}{\begin{center}Region-
%        Annotated \\ Lambda Program\end{center}}}}}
%\put(9,4){\vector(1,-1){2}}
%\put(9,0){\dashbox{0.3}(4,2){\scriptsize{\parbox{22mm}{\begin{center}Region
%      \\ Flow \\ Graph\end{center}}}}}
%\put(20.5,4){\vector(0,-1){2}}
%\put(18.5,0){\dashbox{0.3}(4,2){\scriptsize{\parbox{22mm}{\begin{center}Profile
%      \\ Datafile\end{center}}}}}
%\put(26.5,4){\vector(0,-1){2}}
%\put(22,2){\vector(1,1){2}}
%\put(24.5,0){\dashbox{0.3}(4,2){\scriptsize{\parbox{22mm}{\begin{center}Profile
%      \\ Graphs\end{center}}}}}
%\put(1,1.5){\scriptsize \texttt{.log}\index{log@\texttt{.log}}}
%\put(13,1.5){\scriptsize \texttt{.log}\index{log@\texttt{.log}}}
%\put(13,1){\scriptsize \texttt{.vcg}\index{vcg@\texttt{.vcg}}}
%\put(17.3,1.5){\scriptsize \texttt{.rp}\index{rp@\texttt{.rp}}}
%\put(23.3,1.5){\scriptsize \texttt{.ps}\index{ps@\texttt{.ps}}}
%\end{picture}
%\caption{Overview of the MLKit profiler. Dotted boxes
%        represent output from the profiler. The file containing the output
%        is also shown, e.g. a profile goes into a \texttt{.ps} file.}
%\label{profStrategy.fig}
%\end{center}
%\hrule
%\end{figure}

We will now show an example on how to profile a concrete program that contains a
space leak and then show how the profiler can be used to improve the program. We
then explain in more detail how to specify the profiling strategies and how the
profiles are generated.

%-------------------------------------------------
\section{Example: Scanning Text Files Again}
%-------------------------------------------------

In this section, we concentrate on the general principles of profiling. As an
example, we investigate a revised version of the project \kw{kitdemo/scan.mlb}
(see Section~\ref{scan.sec}). Instead of asking for a list of input files to
scan (as project \kw{scan.mlb} does), the revised version of the scan project
asks for only one input file, which it then scans
%
\index{scan_rev1.mlb@\texttt{scan\_rev1.mlb}}%
%
50~times.\footnote{Project \boxml{kitdemo/scan\_rev1.mlb}.}

The first thing to do is to get an overview of the memory usage of the
program. A region profile of the program gives you just that. See
Figure~\ref{scan_rev1_1.fig}.
\begin{figure}
  \includerp{scan_rev1_1.pdf}
\caption{Memory is accumulated in the top two bands. The global regions \kw{r1}
  and \kw{r333643} hold the largest amount of memory. The graph was generated by
  first compiling the \kw{kitdemo/scan\_rev1.mlb} project with profiling enabled
  (option \kw{-prof}). We also add the compiler options \kw{-log\_to\_file},
  \kw{-Ppp}, \kw{-Prfg}, and \kw{-Pcee} for enabling printing of region flow
  graphs, program points, and call-explicit expressions (redirected to log
  files). Then by executing \kw{echo life.sml | run -notimer 723} and finally by
  typing \kw{rp2ps -region -name 'Scanning life.sml 50 times' -sampleMax 200}.}
\label{scan_rev1_1.fig}
\medskip\hrule
\end{figure}

The graph shows that region \kw{r333643} accumulates more memory for each time
it scans the file \kw{life.sml}.

To see what happens in region \kw{r333643}, we make an object profile of that
region, see Figure \ref{scan_rev1_2.fig}.
\begin{figure}
  \includerp{scan_rev1_2.pdf}
\caption{There seems to be a space leak at program point \kw{pp894}. The graph
  was generated by typing \kw{rp2ps -object r333643}.}
\label{scan_rev1_2.fig}
\medskip\hrule
\end{figure}
The object profile shows that program point \kw{pp894} continually allocates
memory that is first freed when the program terminates. We now search for
\kw{pp894} in the generated log files and in the log file located in the basis
library folder \kw{\$(SML\_LIB)/basis}).\footnote{Unfortunately, the MLKit
compiler happily resets the program point counter for each compilation of a
program unit, thus, there are multiple instances of the program point
\boxml{pp894}.} Among other places, we find that the program point \boxml{pp894}
appears in the following fragment in the file \boxml{basis/Int.sml.log}:
\begin{smlcode}
  fun toString attop r1T pp859 [r61517s:inf] i =
   case ... of
      ...
    | _ =>
      let ...
      in  String.implode [sat r61517s pp894] (...)
      end
\end{smlcode}
So the space leak is caused by the \kw{String.implode} primitive function being
called with region \kw{r333643} instantiated for the formal region variable
\kw{r61517}.

We now search for \kw{r333643} in file \kw{scan\_rev1.sml.log} and find the
following fragment of the region flow graph:
\begin{small}
\begin{scriptcode}
  LETREGION[r333643:inf]
  readWord[r333197:inf]   --r333197 atbot-->   [*r333643*] ;
  toString[r61517:inf]   --r61517 attop-->   [*r333643*] ;
\end{scriptcode}
\end{small}
The fragment is read as follows. The formal region variable \kw{r61517} is
instantiated to the \lstinline{region}-bound region variable \kw{r333643} in a
call to \kw{toString}. Moreover, also the formal region variable \kw{r333197}
(of function \kw{readWord}) is instantiated to \kw{r333643}. (The asterisks
(\kw{*}) denote that the node has been displayed before.)

Region flow graphs are local to each program fragment in a program. A call to a
non-local region-polymorphic function introduces an edge in the region flow
graph, but the graph says nothing about in which module the called function is
located. Thus, it may be necessary to look in several log files to find the path
from a formal region variable to an actual region variable. By inspecting the
call-explicit programs found in \kw{basis/Int.sml.log} and
\kw{kitdemo/lib.sml.log} one finds that both \kw{toString} and \kw{readWord}
eventually call \kw{implode}. However, \kw{readWord} is called only initially,
thus, we conclude that the space leak is caused by function \kw{Int.toString}
being called with region \kw{r333643} instantiated for the formal region
variable \kw{r61517}. Indeed, by inspecting the calls to \kw{toString} in the
call-explicit program found in \kw{scan\_rev1.sml.log}, we see that
\kw{toString} is called with actual region \kw{r333643}.

The \kw{concat} function from the initial basis catenates a list of strings. But
all the strings in the argument list to \kw{concat} are required to be in the
same region. Thus, whenever a file is reported (see
Figure~\ref{report_file.fig}), strings created by the \kw{Int.toString} function
are put in the region that also holds the file name for the report (which is
read using the function \kw{readWord}); and this region is non-local to the
\kw{do\_it} function, which implements the main loop of the program.
\begin{figure}
\hrule \medskip
\begin{smlcode}
  fun report_file (filename, n, ins) =
      writeln(concat[filename, ": size = ", Int.toString n,
                     " comments: ", Int.toString ins, " (",
                     (Int.toString(percent(ins, n))
                      handle _ => "-"), "%)"])

  fun scan_file filename : (int*int) option =
      let val fd = F.openf (filename, F.O_RDONLY, F.O.flags[])
      in let val (n, ins) = scan fd
         in Posix.IO.close fd;
            report_file (filename, n, ins);
            SOME (n, ins)
         end handle NotBalanced =>
                    (writeln (filename ^ ": not balanced");
                     Posix.IO.close fd;
                     NONE)
      end handle IO.Io {name,...} =>
                 (writeln (name ^ " failed."); NONE)

  fun main () : unit =
      case readWord F.stdin of
          SOME filename =>
          let fun do_it 0 = ()
                | do_it n = (scan_file filename; do_it (n-1))
          in do_it 50
          end
        | NONE => ()
\end{smlcode}
\caption{Fragments of \kw{scan\_rev1.sml}. All the strings in the argument list
  to \kw{concat} are put in the same region.}
\label{report_file.fig}
\medskip \hrule
\end{figure}

One way of solving the space leak is to make a copy of \kw{filename} at the call
to \kw{report\_file} in function \kw{scan\_file}:
\begin{smlcode}
  fun scan_file filename : (int*int) option =
      let val fd = F.openf (filename, F.O_RDONLY, F.O.flags[])
      in let val (n, ins) = scan fd
         in Posix.IO.close fd;
            report_file (filename^"", n, ins);
            SOME (n, ins)
         end handle NotBalanced =>
                    (writeln (filename ^ ": not balanced");
                     Posix.IO.close fd;
                     NONE)
      end handle IO.Io {name,...} =>
                 (writeln (name ^ " failed."); NONE)
\end{smlcode}
Project
%
\index{scan_rev2@\texttt{scan\_rev2.mlb}}%
%
\kw{kitdemo/scan\_rev2.mlb} implements the modification.
Figure~\ref{scan_rev2_1.fig} shows a region profile of the \kw{scan\_rev2.mlb}
project.
\begin{figure}
\includerp{scan_rev2_1.pdf}
\caption{There is no space leak: no matter how many times we scan the file, the
  project will use the same number of words. The graph was generated by
  executing \kw{echo life.sml | run -notimer 723} and \kw{rp2ps name scan\_rev2
    -region}.}
\label{scan_rev2_1.fig}
\medskip\hrule
\end{figure}

%----------------------------------------
\section{Compile-Time Profiling Strategy}
%----------------------------------------

Before compiling a program for the purpose of profiling, one must decide on a
%
\index{profile strategy!compile-time}%
%
{\em compile-time profiling strategy}; see Figure~\ref{profStrategy.fig}.  The
compile-time profiling strategy directs the embedding of profiling instructions
in the generated code and instructs the compiler whether to report a region flow
graph.

Region profiling is enabled by passing the option
%
\index{region profiling@\texttt{-region\_profiling}}%
%
\kw{-region\_profiling} (or simply \kw{-prof}) to the MLKit
compiler. If you want the MLKit to report region-annotated programs
with program points, you should pass the option
%
\index{print all program points@\texttt{-print\_all\_program\_points}}%
%
\kw{-print\_all\_program\_points} (or \kw{-Ppp}) to the MLKit compiler together
with one or more of the options
%
\index{print physical size inference expression@\texttt{-Ppse}}%
%
\kw{-print\_physical\_size\_inference\_expression} (or \kw{-Ppse}) and
%
\index{print call-explicit expression@\texttt{-print\_call\_explicit\_expression}}%
%
\kw{-print\_call\_explicit\_expression} (or \kw{-Pcee}).

To make the compiler report a region flow graph, pass the option
%
\index{print region flow graph@\texttt{-print\_region\_flow\_graph}}%
%
$$\kw{-print\_region\_flow\_graph}$$ (or \kw{-Prfg}) to the MLKit compiler at
compile time. The region flow graph is reported in text format.

As a running example, we use the
%
\index{life@\texttt{life}}%
%
\kw{life} program.\footnote{Program: \boxml{kitdemo/life.sml}.}  We assume that
the options \kw{-prof}, \kw{-Ppp}, \kw{-Prfg}, and \kw{-Pcee} are passed to the
MLKit compiler.

By also passing the option \kw{-log\_to\_file} to the MLKit compiler, the MLKit
generates several files, of which we have \kw{life.sml.log} (containing, among
other things, the call-explicit region-annotated program with program points and
the region flow graph in text layout) and the executable file \kw{run}.

%-------------------------------------------------
\section{The Log File}
%-------------------------------------------------
In the file \kw{life.sml.log} you find the call-explicit region-annotated
program with program points and the region flow graph in text layout for the
\kw{life.sml} source file.  The region flow graph is found by searching for the
string \kw{REGION FLOW GRAPH FOR PROFILING}. The graph contains the following
fragment (modified slightly to fit here):\label{reg_flow_graph.ex}
{\small
\begin{verbatim}
  cp_list[r330702:inf]
    --r330702 sat--> nthgen[r332514:inf]
                       --r332514 atbot--> LETREGION[r332640:inf] ;
                       --r332514 sat--> [*r332514*] ;
    --r330702 atbot--> LETREGION[r332002:inf] ;
    --r330702 sat--> [*r330754*] ;
    --r330702 sat--> [*r330702*] ;
\end{verbatim}
}
The region flow graph is almost equivalent to the graph used by the storage mode
analysis (see page~\pageref{region flow graph}). In the graph, region variables
are nodes and there is an edge between two nodes $\rho$ and $\rho'$ if $\rho$ is
a formal region parameter of a function that is applied to actual region
parameter $\rho'$. It follows that \fw{region}-bound region variables are always
leaf nodes.

Nodes in the graph are written in square brackets, which are labeled with the
token \kw{LETREGION} or the name of the function for which the region variable
is a formal parameter. For example, the notation \kw{cp\_list[r330702:inf]}
identifies the node \kw{r330702}, which is a formal region parameter of the
function \kw{cp\_list}.  An asterisk inside a square bracket means that the node
has been written earlier.  Only the node identifier (i.e., the region variable)
will then be printed. The size of the region is printed after the region
variable; we use \kw{inf} for infinite regions and {\em size\/} for finite
regions of size {\em size\/} words.

Edges are written with the {\em from node\/} identifier annotated on them. The
edge points to the \emph{to node}. The fragment
{\small
\begin{verbatim}
  cp_list[r330702:inf]
     --r330702 sat-->    [*r330754*] ;
\end{verbatim}
}
is read: there is an edge from node \kw{r330702} to node \kw{r330754} and node
\kw{r330754} has been written earlier. From the cycle in the graph, one can
conclude that \kw{cp\_list} calls itself recursively; if you look in file
\kw{life.sml}, you will find something like
\begin{smlcode}
  fun cp_list [] = []
    | cp_list ((x,y)::rest) =
          let val l = cp_list rest
          in (x,y):: l
          end
\end{smlcode}

The region flow graph can get very complicated to read due to mutually recursive
functions, which give many edges and cycles.  If the graphs get too complicated,
you may find help in the
%
\index{strongly connected component}%
%
{\em strongly connected component\/} (scc) version of the graph.  The scc graph
is found by searching for \kw{[sccNo} in the log file.  Each scc is identified
  by a unique {\em scc number}. The region variables contained in each scc is
  annotated on the scc node.

Consider, for example, the following fragment of the scc version of
the region flow graph for the \kw{life} program:
{\small
\begin{verbatim}
  [sccNo 94: r2768,]   --sccNo 94-->   [sccNo 33: r331990,];
\end{verbatim}
}
Here, we have a scc node (id 94) containing region variable \kw{r2768} and an
edge to scc node (id 33) containing region variable \kw{r331990}.

%----------------------------------
\section{Runtime Profiling Strategy}
%----------------------------------
When the source program has been compiled and linked, you have an executable
file, \kw{run}. Typing \kw{./run} at the command prompt will execute the program
with a predefined
%
\index{profile strategy!runtime}%
%
runtime profiling strategy, which is displayed when the program is run with the
\kw{-verbose} option:
\begin{scriptcode}
  ---------------------Profiling-Enabled---------------------
   The profile timer (unix virtual timer) is turned on.
   A profile tick occurs every 1th second.
   Profiling data is exported to file profile.rp.
  -----------------------------------------------------------
\end{scriptcode}
You can change the
%
\index{profile strategy!options}
%
profiling strategy by passing command line arguments directly to the executable.
The second line says that a virtual timer is used. There are three possible
timers, each of which can be enabled using one of the following
options:\footnote{A complete description can be found in the manual page for
\boxml{getitimer}.}

\vspace{2mm}
{\def\arraystretch{1.4}
\begin{tabular}{lp{8cm}}
{\tt -realtime} & Real time.
  \index{realtime@\texttt{-realtime} option}%
  \index{timer!real} \\
{\tt -virtualtime} & The execution time for the process. %
  \index{virtualtime@\texttt{-virtualtime} option}%
  \index{timer!virtual} \\
{\tt -profiletime} & The execution time for the process together with the time used in
the operating system on behalf of the process. %
\index{profiletime@\texttt{-profiletime} option}%
  \index{timer!prof}
\end{tabular}}
\vspace{2mm}

The third line says that a
%
\index{profile tick}%
%
{\em profile tick\/} occurs every 1 second.  A profile tick is when the program
stops normal execution, and memory is traversed to collect profile data. The
more often a profile tick occurs the more detailed you profile (and the slower
the program will run). The
%
\index{profiling!time slot}%
%
{\em time slot\/} (i.e., the time between to succeeding profile ticks) to use
is specified by the
%
\index{sec@\texttt{-sec} option}%
%
\kw{-sec n} and
%
\index{microsec@\texttt{-microsec} option}%
%
\kw{-microsec n} options. A time slot of half a second is specified by
\kw{-microsec 500000} and not by \kw{-sec 0.5}.\footnote{The lowest possible
time slot to use is system dependent.  }

The fourth line says that the collected profile data is exported to the file
\kw{profile.rp}. The default file name setting can be changed with the
%
\index{file@\texttt{-file} option}%
%
\kw{-file name} option.

There are several other possible command-line options; use the \kw{-h} option or
the
%
\index{help@\texttt{-help} option}%
%
\kw{-help} option for details. When garbage collection is enabled, options for
controlling garbage collection are also available as command-line options (see
Section~\ref{gc.chap}).

%----------------------------------
\section{Regions Statistics}
%----------------------------------
If the executable file \kw{run} is executed with the option \kw{-showStat} then
%
\index{region statistics}%
%
{\em region statistics\/} is printed just before the program terminates. Region
statistics includes information about the use of regions and does not depend on
the specifics of the runtime profiling strategy; in fact, region statistics
includes only exact, non-sampled values for the program. Assuming that \kw{run}
is the executable file generated by compiling the program \kw{life} with
profiling enabled, executing \kw{./run -showStat} yields---just before the
program terminates---the region statistics shown in
Figure~\ref{region_statistics.fig}.
\begin{figure}
\hrule \medskip
\begin{scriptcode}
MALLOC
  Number of calls to malloc for regions: 1
  Alloc. in each malloc call: 819200 bytes
  Total allocation by malloc: 819200 bytes (0.8Mb)

REGION PAGES
  Size of one page: 8176 bytes
  Max number of allocated pages: 44
  Number of allocated pages now: 6
  Max space for region pages: 359744 bytes (0.3Mb)

INFINITE REGIONS
  Size of infinite region descriptor: 32 bytes
  Number of calls to allocateRegionInf: 81050
  Number of calls to deallocateRegionInf: 81044
  Number of calls to alloc: 1060622
  Number of calls to resetRegion: 85882
  Number of calls to deallocateRegionsUntil: 0

ALLOCATION
  Max alloc. space in pages: 121936 bytes (0.1Mb)
    incl. prof. info: 243888 bytes (0.2Mb)
  Infinite regions utilisation (243888/359744): 68%
  Number of allocated large objects: 0

STACK
  Number of calls to allocateRegionFin: 358935
  Number of calls to deallocateRegionFin: 358935
  Max space for finite regions: 144 bytes (0.0Mb)
  Max space for region descs: 1280 bytes (0.0Mb)
  Max size of stack: 19792 bytes (0.0Mb)
    incl. prof. info (stackBot - maxStack): 20232 bytes (0.0Mb)
    prof. info: 440 bytes (0.0Mb)
    in profile tick: 0 bytes (0.0Mb)
\end{scriptcode}
\caption{Region statistics for the {\tt life} program.}
\label{region_statistics.fig}
\medskip\hrule
\end{figure}

The \kw{MALLOC} part of Figure~\ref{region_statistics.fig} shows how memory is
allocated from the operating system.

Each infinite region form a linked list of one or more
%
\index{region pages}%
%
{\em region pages\/} whose size is found in the \kw{REGION PAGES} part. The
value
\begin{scriptcode}
  Max number of allocated pages: 44
\end{scriptcode}
multiplied by
\begin{scriptcode}
  Size of one page: 8176 bytes
\end{scriptcode}
gives
\begin{scriptcode}
  Max space for region pages: 359744 bytes (0.3Mb)
\end{scriptcode}

In the \kw{INFINITE REGIONS} part, we see the number of calls to infinite region
operations such as \kw{allocateRegionInf} and \kw{alloc}. The program allocates
81050 infinite regions and de-allocates 81044; the six global regions are not
de-allocated before the region statistics is printed and the program terminates.
The program allocates 1060622 objects in infinite regions. Infinite regions have
been reset 85882 times. The \kw{deallocateRegionsUntil} operation is called
whenever an exception is raised, thus, we see that no exceptions were raised by
the program.

Because objects allocated in infinite regions are not split across different
region pages, it is not always possible to fill out a region page entirely. In
the \kw{ALLOCATION} part, the value
\begin{scriptcode}
  Infinite regions utilisation (243888/359744): 68%
\end{scriptcode}
shows memory utilisation for infinite regions at the moment where the program
has allocated the largest amount of memory in infinite regions. We also see that
the maximum allocated space in region pages is 121936 bytes.

In the \kw{STACK} part, we see that the program allocates and de-allocates the
same number of finite regions. We also see that the space used for finite
regions is 144 bytes and that the total use of stack space is 19792 bytes
(excluding space used to hold profiling information). The stack size values
\begin{scriptcode}
    prof. info: 440 bytes (0.0Mb)
    in profile tick: 0 bytes (0.0Mb)
\end{scriptcode}
can be used to see if it is necessary to profile with a smaller time slot, which
will often lower the difference between the two values.


%--------------------------------------------
\section{Processing the Profile Data File}
%--------------------------------------------
The profile data-file \kw{profile.rp} can be processed by the
%
\index{rp2ps@\texttt{rp2ps} options|(}%
%
graph generator \kw{rp2ps} (read: RegionProfile2Postscript) found in the
\kw{bin} directory.\footnote{The \boxml{rp2ps} program is based on a Haskell
profiler written by Colin Runciman, David Wakeling and Niklas R\"{o}jemo.} The
graph generator is controlled by command line options.

A
%
\index{region profile}%
\index{region@\texttt{-region} option}%
%
region profile is produced by typing
\begin{scriptcode}
  $ rp2ps -region
\end{scriptcode}
at the command prompt. The program produces a Postscript file \kw{region.ps} by
reading profile information from the
%
\index{profile data file}%
%
profile data file \kw{profile.rp}, see Figure~\ref{profStrategy.fig}.  A region
profile for the \kw{life} program is shown in Figure~\ref{lifeprof50.fig} on
page~\pageref{lifeprof50.fig}. The region that occupies the largest area is at
the top. If there are more regions than can be shown in different colors, then
the smallest regions are collected in an OTHER band at the bottom.

Each region is identified with a number that matches a \fw{region}-bound region
variable in the region-annotated program.  Infinite regions end with \kw{inf}
and finite regions end with \kw{fin}. There are also a band named \kw{rDesc} and
a band named \kw{stack}. The \kw{rDesc} band shows the memory used on region
descriptors of infinite regions on the stack. The stack band shows stack usage
excluding finite regions and region descriptors for infinite regions.

The vertical line marked ``Maximum allocated bytes...'' in
Figure~\ref{lifeprof50.fig} is called the {\em maximum allocation line}; it
shows the maximum number of bytes allocated in regions and on the stack when the
program was executed. Notice that this maximum is often lower than the sum of
the maximum allocated bytes in regions and the maximum allocated bytes on the
stack. The space between the maximum allocation line and the top band shows the
inaccuracy of the profiling strategy. To decrease the gap, it often helps to use
a smaller time slot.

The largest region shown in Figure~\ref{lifeprof50.fig} is \kw{r332640}. An
%
\index{object profile}%
\index{object@\texttt{-object} option}%
%
object profile of region \kw{r332640} is produced by typing
\begin{scriptcode}
  $ rp2ps -object 332640
\end{scriptcode}
at the command prompt. We obtain the object profile shown in
Figure~\ref{prof_eks2.fig}.
\begin{figure}
\includerp{life_ex2.pdf}
\caption{The object profile shows all allocation points allocating into region
  \kw{r332640}.}
\label{prof_eks2.fig}
\medskip\hrule
\end{figure}

We see that allocation point \kw{pp11} is responsible for the largest amount of
allocations in the program. The allocation point may be found in the
region-annotated program resulting from compiling the \kw{life} program
(remember to enable printing of program points). In general, program points may
also stem from the Basis Library (search the \kw{.log} files in the directory
\kw{basis}).

The stack profile shown in Figure~\ref{prof_eks3.fig} shows memory usage on the
stack, excluding space used by finite regions. A
%
\index{stack profile}%
\index{stack@\texttt{-stack} option}%
%
stack profile is generated by typing
\begin{scriptcode}
  $ rp2ps -stack
\end{scriptcode}
at the command prompt.

\begin{figure}
\includerp{life_ex3.pdf}
\caption{Memory usage on the stack excluding space for finite regions.}
\label{prof_eks3.fig}
\medskip\hrule
\end{figure}

%-------------------------------------------------------
\section{Advanced Graphs with \texttt{rp2ps}}
%-------------------------------------------------------
This section gives a quick overview of the more advanced options that can be
passed to \kw{rp2ps}. First of all, it is possible to name the profiles with the
%
\index{name@\texttt{-name} option}%
%
\kw{-name} option. Comments are inserted on the x-axis with the
%
\index{comment@\texttt{-comment} option}%
%
\kw{-comment} option.

The profile data file may contain a large number of \emph{samples} (the data
collected by a profile tick is called a sample). By default, \kw{rp2ps} uses
only 64 samples. You can alter the setting with the
%
\index{sampleMax@\texttt{-sampleMax} option}%
%
\kw{-sampleMax} option. The following two possibilities are used to sort out
samples:

\vspace{2mm}
{
\def\arraystretch{1.4}
\begin{tabular}{lp{8cm}}
\kw{-sortBySize} & The $n$ (specified by \kw{-sampleMax}) largest samples are
shown. %
\index{sortBySize@\texttt{-sortBySize} option} \\
\kw{-sortByTime} & The $n$ samples shown are equally distributed over time (default). %
\index{sortByTime@\texttt{-sortByTime} option}
\end{tabular}
}
\vspace{2mm}

The \kw{-sortBySize} option is useful if your profiles have a large gap between
the top band and the maximum allocation line.  If there is a large gap when
using option \kw{-sortBySize}, then it may help to profile with a smaller time
slot. You can use the
%
\index{stat@\texttt{-stat} option}%
%
\kw{-stat} option to see the number of samples in the profile data file. It is
printed as \kw{Number of ticks:}.

Figure~\ref{prof_eks4.fig} shows the profile for the following command line:
\begin{scriptcode}
  $ rp2ps -region -sampleMax 100 -name life \
          -comment 0.03 "A comment at time 0.03" -sortBySize
\end{scriptcode}

\begin{figure}
  \includerp{life_ex4.pdf}
\caption{It is possible to insert comments in profile graphs.}
\label{prof_eks4.fig}
\medskip\hrule
\end{figure}

The graph generator recognises several options that are not mentioned
here. Help on these options is obtained by typing \kw{rp2ps -h} or
%
\index{help@\texttt{-help} option}%
%
\kw{rp2ps -help} at the command prompt.
%
\index{rp2ps@\texttt{rp2ps} options|)}%

%---------------------------------------------------------
\chapter{Controlling MLKit Compilation}
\label{controlkit.sec}
\label{startup.sec}
%---------------------------------------------------------

We have already described how to compile and run single source files
(Section~\ref{tryit.sec}) and MLB-files (Chapter~\ref{mlb_and_modules.chap}).
In the following sections, we give an overview of MLKit options for controlling
printing and layout of intermediate forms. One useful command-line option is the
%
\index{help@\texttt{-help} option to \texttt{mlkit}}%
%
\kw{-help} option; Appendix~\ref{mlkithelp.app} shows the output of executing
\kw{mlkit -help}.


%------------------------------------------------
\section{Printing of Intermediate Forms}
\label{printing_intermediate_forms.sec}
%------------------------------------------------
A series of options may be used to control
%
\index{Printing of intermediate forms}%
%
printing of intermediate forms during compilation.  A summary of the major
phases that produce printable intermediate forms is shown in
Figure~\ref{phases.fig}. The phases are listed in the order they take place in
the MLKit.
\begin{figure}
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
 {\bf Phase} & {\bf Result} & {\bf Flag(s) that Print Result} \\
\hline
 Elaboration            & $\Lam$    & \hfill \boxml{$(\ast)$}\\
 Elim. of Poly. Eq.     & $\Lam$    & \hfill \boxml{$(\ast)$}\\
 Lambda Optimiser       & $\Lam$    & \boxml{-Pole} \hfill $(\ast)$\\
 Spreading              & $\RegExp$ & \hfill \boxml{$(\ast)$}\\
 Region Inference       & $\RegExp$ & \hfill \boxml{$(\ast)$}\\
 Multiplicity Inference & $\MulExp$ & \hfill \boxml{$(\ast)$}\\
 K-normalisation        & $\MulExp$ & \\
 Storage Mode Analysis  & $\MulExp$ & \boxml{-Psme} \hfill $(\ast)$\\
 Dropping of Regions    & $\MulExp$ & \boxml{-Pdre} \hfill $(\ast)$\\
                        &           & \boxml{-Pdresm} \\
 Physical Size Inference& $\MulExp$ & \boxml{-Ppse} \hfill $(\ast)$\\
 Call Conversion        & $\MulExp$ & \boxml{-Pcee} \hfill $(\ast)$\\
\hline
\end{tabular}
\end{center}
\caption{The table shows how different options correspond to printing different
  intermediate program representations.  The option \kw{-debug} causes all
  intermediate forms marked $(\ast)$ to be printed.  Thus, one can select phases
  individually or ask to have all intermediate forms printed.  The phases that
  follow K-normalisation all work on K-normal forms, but, for readability, terms
  are printed as if they had not been normalised.}
\label{phases.fig}
\end{figure}

The optimiser, which rewrites a $\Lam$\index{Lambda@$\Lam$} program, collects
statistics about the optimisation. This statistics is printed if the
option $$\kw{-statistics\_after\_optimisation}$$ %
%
\index{statistics after optimisation@\texttt{-statistics\_after\_optimisation}}%
\index{optimisation!statistics}%
%
is provided.

Storage mode analysis (see Chapter~\ref{storagemodes.sec}) results in
a $\MulExp$\index{MulExp@$\MulExp$} expression, which is printed if the option
%
\index{print storage mode expression@\texttt{-Psme}}%
%
\kw{-print\_storage\_mode\_expression} is provided.  After that, region parameters
for which there are only $\Get$ effects on in the type scheme for a
region polymorphic function are removed from the $\MulExp$ expression
(see page~\pageref{bother-to-distinguish-get-n-put}).  To see the
resulting expression, turn on
%
\index{print drop regions expression@\texttt{-Pdre}}%
%
\kw{-print\_drop\_regions\_expression} or
$$\kw{-print\_drop\_regions\_expression\_with\_storage\_modes}$$
The latter flag also prints storage modes.

\index{physical size inference}%
\index{region size}%
%
Physical size inference then determines the size in words of finite region
variables.  For instance, a finite region that will contain a pair will have
physical size two words.  To see the expression after physical size inference,
provide the option
%
\index{print physical size inference expression@\texttt{-Ppse}}%
%
\kw{-print\_physical\_size\_inference\_expression}.  After that,
%
\index{call conversion}%
%
call conversion converts the $\MulExp$ expression to a
%
\index{expression!call-explicit}%
%
call-explicit expression (see page~\pageref{call-explicit}).  To see the result,
provide the option
$$\kw{-print\_call\_explicit\_expression}$$

After that, you can inspect the code at different steps of the transformation
into machine code by providing different options (use the \kw{-help} option to
see which.

\section{Layout of Intermediate Forms}
\label{layout_intermediate_forms.sec}

While the switches described in the previous section concern which intermediate
forms to print, the switches described in this section
%
\index{layout control}%
%
control how the different forms are printed.

The options
%
\index{print types@\texttt{-print\_types}}%
%
\kw{-print\_types},
%
\index{print effects@\texttt{-print\_effects}}%
%
\kw{-print\_effects}, and
%
\index{print regions@\texttt{-print\_regions}}%
%
\kw{-print\_regions} control the printing of region-annotated types, effects,
and region allocation points (e.g., $\fw{at}\,\rho$).  All eight combinations of
these three flags are possible, but if
%
\index{print effects@\texttt{-print\_effects}}%
%
\kw{-print\_effects} is turned on, it is best also to turn the two others on so
that one can see where the effect variables and region variables that appear in
arrow effects are bound.

%---------------------------------------------------------
\chapter{Calling C Functions}
\label{ccall.sec}
%---------------------------------------------------------

In this chapter, we describe how the MLKit programmer can call
%
\index{C!calling}%
%
C functions from within Standard ML programs.  The MLKit allows ML values to be
passed to C functions, which again may return ML values.  Not all ML values are
represented as if they were C values. For instance, C strings are
null-terminated arrays of characters, whereas ML strings in the MLKit are
represented as a linked list of bounded sized character arrays. To allow the
programmer to conveniently convert between C values and ML values, the MLKit
provides conversion functions and macros for commonly used data structures.

When the MLKit calls a C function, data structures returned by the function are
stored in regions that are allocated by the MLKit. For dynamically sized objects
of the resulting value, such as strings and lists, regions are allocated by the
MLKit and passed to the C function as additional arguments; the C function must
then itself allocate space in these regions for the dynamically sized data
structures. Moreover, for those parts of the resulting value for which the size
can be determined statically, pointers to already allocated space are passed to
the C function as additional arguments.

In both cases, the MLKit uses region inference to infer the lifetime of
regions that are passed to the C function.  The region inference
algorithm does not analyse C functions. Instead, the MLKit inspects the
ML type provided by the programmer. The MLKit assumes that functions
with monomorphic types are
%
\index{region exomorphism}%
%
region exomorphisms;
%
\index{region endomorphism}%
%
region endomorphic functions may be described using ML polymorphism, see
Section~\ref{C_polymorphism.sec}.

For every C function that is called from an ML program, the order of the
additional region arguments is uniquely determined by the ML result type of the
function.  This type must be constructed from lists, records, booleans, reals,
strings, integers, and type variables.

When profiling is enabled, yet another additional argument, a program point, is
passed to the C function. This argument provides allocation primitives with
information about what points in the program contributes with allocation; see
Section~\ref{prof.sec}.

Examples of existing libraries that can be accessed from within ML programs
include database client drivers (e.g., for Postgresql) and standard UNIX
libraries providing functions such as \kw{time}, \kw{cp}, and \kw{fork}. There
are limitations to the scheme, however. First, because C and the MLKit do not
share value representations, transmitting large data structures between C and ML
will often involve significant copying. Second, some C libraries require the
user to set up
%
\index{call-back function}%
%
call-back functions to be executed when specific events occur. The MLKit only
has very limited functionality for letting a C function call ML code.

%========================================================
\section{Declaring Primitives and C Functions}
\label{parPassing.sec}
%========================================================
The MLKit conforms in large parts to the Standard ML Basis Library. Part
of the functionality found in the basis library is programmed in C and
linked to the MLKit runtime system.  The declarations in system
dependent parts of the library use a special built-in identifier
called
%
\index{prim@\texttt{prim}}%
%
\kw{prim}, which is declared to have type scheme $\forall \alpha \beta .
\kw{string} \ast \alpha \rightarrow \beta$ in the initial basis.  A primitive
function is then declared by passing its name to \kw{prim}.  For example, the
declaration
\begin{smlcode}
  fun (s : string) ^ (s' : string) : string =
    prim ("concatStringML", (s, s'))
\end{smlcode}
declares string catenation.  The argument and result types are explicitly stated
so as to give the primitive the correct type scheme.  The string constant
\lstinline{"concatStringML"} denotes a C function identifier.\footnote{Some
primitives (e.g., \boxml{"="} and \boxml{":="}) are recognised and
implemented in assembler by the compiler.} For the example declaration, the
MLKit generates a call to the C function \kw{concatStringML} with arguments
\kw{s} and \kw{s'}. The C function must then of course be present at link-time;
if not, the MLKit complains.\footnote{When profiling is enabled, the MLKit
automatically appends the extension \boxml{Prof} for those functions that take
regions (and thus a program point) as argument; see Section~\ref{prof.sec}.}

A convenient way to declare a C function is to use the following scheme:
\begin{center}
  \lstinline!fun $\mathit{vid}$ ($x_1$:$\tau_1$, $\ldots$, $x_n$:$\tau_n$) : $\tau$ = prim($\mathit{c\_func}$, ($x_1$, $\ldots$, $x_n$))!
\end{center}

\noindent
The result type $\tau$ must be of the form
\begin{quote}
\begin{tabbing}
$\tau$ ::\== ~\= $\alpha$ $~|~$ \kw{int} $~|~$ \kw{bool} $~|~$ \kw{unit} \\
  \> $|$ \> $\tau_1 \ast \ldots \ast \tau_n$ $~|~$ $\tau$ \kw{list} $~|~$ \kw{real} $~|~$ \kw{string}
\end{tabbing}
\end{quote}
\noindent
If the result type is one of $\alpha$, \kw{int}, \kw{bool}, or \kw{unit} then
the result value can be returned in a single register. Contrary, if the result
type represents an allocated value, the C function must be told where to store
the value. For any type that is either \kw{real} or a non-empty tuple type, and
does not occur in a list type of the result type $\tau$, the MLKit allocates
space for the value and passes a pointer to the allocated space as an additional
argument to the C function. For any type representing an allocated value that is
either \kw{string} or occurs in a list type of the result type $\tau$, the MLKit
cannot statically determine the amount of space needed to store the
value. Instead, regions are passed to the C function as additional arguments and
the C function must then explicitly allocate space in these regions as needed,
using a C function provided by the runtime system. The order in which these
additional arguments are passed to the C function is determined by a pre-order
traversal of the result type $\tau$.  For a list type, regions are given in the
order:
\begin{enumerate}
\item Region for auxiliary pairs.
\item Regions for elements (if necessary).
\end{enumerate}

We now give an example to show what extra arguments are passed to a
C function, given the result type. In the example, we use the following
(optional) naming convention:
names of arguments holding addresses of
pre-allocated space in regions
start with \kw{vAddr}, while names of arguments
holding addresses of region descriptors (to be used for allocation in a
region) start with \kw{rAddr}.
\begin{example}
  Given the result type $(\kw{int} \ast \kw{string}) ~\kw{list} \ast \kw{real}$,
  the following extra ar\-gu\-ments are passed to the C function (in order):
  \kw{vAddrPair}, \kw{rAddrLPairs}, \kw{rAddrEPairs}, \kw{rAddrEStrings} and
  \kw{vAddrReal}, see Figure \ref{args_ex1.fig}.

  Here \kw{vAddrPair} holds an address pointing to pre-allocated storage in
  which the tuple of the list and the (pointer to the) real should reside. The
  argument \kw{rAddrLPairs} holds the region address for the auxiliary pairs of
  the list. Similarly, the arguments \kw{rAddrEPairs} and \kw{rAddrEStrings}
  hold region addresses for element pairs and strings, respectively. The
  argument \kw{vAddrReal} holds the address for pre-allocated storage for the
  real.
\end{example}

\setlength{\unitlength}{1pt}
\begin{figure}
\hrule
\begin{center}
\begin{picture}(400,155)
\put(125,140){\framebox{$\ast$}}
\put(155,100){\framebox{\kw{real}}}
\put(75,100){\framebox{\kw{list}}}
\put(85,60){\framebox{$\ast$}}
\put(40,20){\framebox{\kw{int}}}
\put(115,20){\framebox{\kw{string}}}
\put(125,140){\line(-1,-1){29}}
\put(138,140){\line(1,-1){29}}
\put(90,97){\line(0,-1){28}}
\put(85,60){\line(-1,-1){29}}
\put(98,60){\line(1,-1){29}}

\put(115,145){\circle{10}}\put(115,145){\makebox(0,0){1}}
\put(65,105){\circle{10}}\put(65,105){\makebox(0,0){2}}
\put(75,65){\circle{10}}\put(75,65){\makebox(0,0){3}}
\put(30,25){\circle{10}}\put(30,25){\makebox(0,0){4}}
\put(105,25){\circle{10}}\put(105,25){\makebox(0,0){5}}
\put(145,105){\circle{10}}\put(145,105){\makebox(0,0){6}}

\put(200,145){\circle{10}}\put(200,145){\makebox(0,0){1}}
\put(210,142){\kw{vAddrPair}}

\put(200,125){\circle{10}}\put(200,125){\makebox(0,0){2}}
\put(210,122){\kw{rAddrLPairs}}

\put(200,105){\circle{10}}\put(200,105){\makebox(0,0){3}}
\put(210,102){\kw{rAddrEPairs}}

\put(200,85){\circle{10}}\put(200,85){\makebox(0,0){4}}
\put(210,82){Integers are unboxed}

\put(200,65){\circle{10}}\put(200,65){\makebox(0,0){5}}
\put(210,62){\kw{rAddrEStrings}}

\put(200,45){\circle{10}}\put(200,45){\makebox(0,0){6}}
\put(210,42){\kw{vAddrReal}}

\end{picture}
\caption{The order of pointers to allocated space and infinite regions is
  determined from a pre-order traversal of the result type $(\kw{int} \ast
  \kw{string}) ~\kw{list} \ast \kw{real}$.}
\label{args_ex1.fig}
\end{center}
\hrule
\end{figure}

Additional arguments holding pointers to pre-allocated space and
infinite regions are passed to the C function prior to the ML
arguments. Consider again the ML declaration
\begin{center}
  \lstinline!fun $\mathit{vid}$ ($x_1$:$\tau_1$, $\ldots$, $x_n$:$\tau_n$) : $\tau$ = prim($\mathit{c\_func}$, ($x_1$, $\ldots$, $x_n$))!
\end{center}

\noindent
The C function $\mathit{c\_func}$ must then be declared as
\begin{eqnarray}
  \texttt{int} \ \emph{c\_func} \ \texttt{(}\texttt{int}\ \emph{addr}_1,
    \ldots, \texttt{int}\ \emph{addr}_m,\ \texttt{int}\ x_1, \ldots, \texttt{int}\ x_n\texttt{)} \nonumber
\end{eqnarray}
\noindent
where $\mathit{addr}_1$, $\ldots$, $\mathit{addr}_m$ are pointers to
pre-allocated space and infinite regions as described above.


%========================================
\section{Conversion Macros and Functions}
%========================================
The runtime system provides a small set of conversion macros and functions for
use by C functions that need to convert between ML values and C values. Using
these conversion macros and functions for converting between representations
protects you against future changes in the representation of ML values. The
conversion macros and functions are declared in the header files:
%
\index{Tagging.h@\texttt{Tagging.h}}%
\index{String.h@\texttt{String.h}}%
%
\begin{scriptcode}
  src/Runtime/Tagging.h
  src/Runtime/String.h
  src/Runtime/List.h
\end{scriptcode}

%--------------------
\subsection{Integers}
%--------------------
There are two macros for converting between the ML representation of integers
and the C representation of integers:\footnote{These macros are the identity
maps when garbage collection is disabled.}
%
\index{convertIntToC@\texttt{convertIntToC}}%
\index{convertIntToML@\texttt{convertIntToML}}%
%
\begin{scriptcode}
  #define convertIntToC(i)
  #define convertIntToML(i)
\end{scriptcode}
To convert an ML integer \kw{i\_ml} to a C integer (type \kw{long int})
\kw{i\_c}, write
\begin{scriptcode}
  i_c = convertIntToC(i_ml);
\end{scriptcode}
To convert a C integer (type \kw{long int}) \kw{i\_c} to an ML integer
\kw{i\_ml}, write
\begin{scriptcode}
  i_ml = convertIntToML(i_c);
\end{scriptcode}
The macros demonstrated here are used in the examples~\ref{power.ex},
\ref{power_real.ex}, and~\ref{power_exn.ex} in Section~\ref{Cexamples.sec}.

%-----------------
\subsection{Units}
%-----------------
The following constant in the conversion library denotes the ML representation
of \kw{()}:
%
\index{mlUNIT@\texttt{mlUNIT}}%
%
\begin{scriptcode}
  #define mlUNIT
\end{scriptcode}

%-----------------
\subsection{Reals}
%-----------------
An ML real is represented as a pointer into a region containing the real. To
convert an ML real to a C real, we dereference the pointer. To convert a C real
to an ML real, we update the memory to contain the C real. The following two
macros are provided:
%
\index{convertRealToC@\texttt{convertRealToC}}%
\index{convertRealToML@\texttt{convertRealToML}}%
%
\begin{scriptcode}
  #define convertRealToC(mlReal)
  #define convertRealToML(cReal, mlReal)
\end{scriptcode}

Converting an ML real \kw{r\_ml} to a C real \kw{r\_c} can be done with the
first macro:
\begin{scriptcode}
  r_c = convertRealToC(r_ml);
\end{scriptcode}

Converting from a C real to an ML real (being part of the result value of the C
function) is done in one or two steps depending on whether the real is part of a
list or not. If the real is not in a list the memory containing the real has
been allocated before the C call, see Section~\ref{parPassing.sec}:
\begin{scriptcode}
  convertRealToML(r_c, r_ml);
\end{scriptcode}
If the ML real is part of a list element, then space must be allocated for the
real before converting it. If \kw{rAddr} identifies a region for the real, you
write:
%
\index{allocReal@\texttt{allocReal}}%
%
\begin{scriptcode}
  allocReal(rAddr, r_ml);
  convertRealToML(r_c, r_ml);
\end{scriptcode}

\noindent
These macros are used in the examples~\ref{power_real.ex}, \ref{power_exn.ex}
and~\ref{real_list.ex} in Section~\ref{Cexamples.sec}.

%--------------------
\subsection{Booleans}
%--------------------
Four constants provide the values of true and false in ML and in C.  These
constants are defined by the following macros:\footnote{For historical reasons,
booleans in the MLKit are tagged even when garbage collection is disabled.}
%
\index{mlTRUE@\texttt{mlTRUE}}%
\index{mlFALSE@\texttt{mlFALSE}}%
\index{cTRUE@\texttt{cTRUE}}%
\index{cFALSE@\texttt{cFALSE}}%
%
\begin{scriptcode}
  #define mlTRUE  3
  #define mlFALSE 1
  #define cTRUE   1
  #define cFALSE  0
\end{scriptcode}

Two macros are provided for converting booleans:
%
\index{convertBoolToC@\texttt{convertBoolToC}}%
\index{convertBoolToML@\texttt{convertBoolToML}}%
%
\begin{scriptcode}
  #define convertBoolToC(i)
  #define convertBoolToML(i)
\end{scriptcode}
Converting booleans is similar to converting integers:
\begin{scriptcode}
  b_c = convertBoolToC(b_ml);
  b_ml = convertBoolToML(b_c);
\end{scriptcode}

%-------------------
\subsection{Records}
%-------------------
Records are boxed. One macro is provided for storing and retrieving elements:
%
\index{elemRecordML@\texttt{elemRecordML}}%
%
\begin{scriptcode}
  #define elemRecordML(recAddr, offset)
\end{scriptcode}
An element can be retrieved from a record \kw{rec\_ml} by writing
\begin{scriptcode}
  e_ml = elemRecordML(rec_ml, offset);
\end{scriptcode}
where the first element has \kw{offset} 0. An element \kw{e\_ml} is stored in an
ML record \kw{rec\_ml} by writing
\begin{scriptcode}
  elemRecordML(rec_ml, offset) = e_ml;
\end{scriptcode}
Two specialised versions of the \kw{elemRecordML} macro are provided for
%
\index{first@\texttt{first}}%
\index{second@\texttt{second}}%
%
pairs:
\begin{scriptcode}
  #define first(x)
  #define second(x)
\end{scriptcode}

If the record is to be part of a list element then it is necessary to allocate
the record before storing into it. This allocation is done with the macro
%
\index{allocRecordML@\texttt{allocRecordML}}%
%
\begin{scriptcode}
  #define allocRecordML(rAddr, size, vAddr)
\end{scriptcode}
where \kw{rAddr} denotes a region (i.e., a pointer to a region descriptor),
\kw{size} is the size of the record (i.e., the number of components), and
\kw{vAddr} is a variable in which \kw{allocRecordML} returns a pointer to
storage for the record. The record is then stored, component by component, by
repeatedly calling \kw{elemRecordML} with the pointer \kw{vAddr} as argument.

The above macros are used in examples~\ref{real_list.ex}, \ref{change_elem.ex}
and~\ref{dir.ex} in Section~\ref{Cexamples.sec}.

%-------------------
\subsection{Strings}
%-------------------
Strings are boxed and always allocated in infinite regions. It is possible to
print an ML string by using the C function
%
\index{printStringML@\texttt{printStringML}}%
%
\begin{scriptcode}
  void printStringML(String str);
\end{scriptcode}

Strings are converted from ML to C and vice versa using the two C functions
%
\index{convertStringToC@\texttt{convertStringToC}}%
\index{convertStringToML@\texttt{convertStringToML}}%
%
\begin{scriptcode}
  void convertStringToC(String mlStr, char *cStr,
                        size_t cStrLen, int exn);
  String convertStringToML(Region rAddr, char *cStr);
\end{scriptcode}
An ML string \kw{str\_ml} is converted to a C string \kw{str\_c} in already
allocated storage of size \kw{size} bytes by writing
\begin{scriptcode}
  convertStringToC(ctx, str_ml, str_c, size, exn);
\end{scriptcode}
where \kw{exn} is some ML exception value (see Section~\ref{C_exceptions.sec})
to be raised if the ML string has size greater than \kw{size} and \kw{ctx} is an
evaluation context obtained using the \kw{\_\_get\_ctx} primitive.

A C string is converted to an ML string in the region denoted by \kw{rAddr} by
writing
\begin{scriptcode}
  str_ml = convertStringToML(rAddr, str_c);
\end{scriptcode}

The following macro returns the size of an ML string:
%
\index{sizeStringDefine@\texttt{sizeStringDefine}}%
%
\begin{scriptcode}
  size_t sizeStringDefine(String str);
\end{scriptcode}

These macros are used in the examples~\ref{dir.ex} and
\ref{print_string_list.ex} in Section~\ref{Cexamples.sec}.

%-----------------
\subsection{Lists}
%-----------------

Lists are always allocated in infinite regions. A list uses, as a minimum, one
region for the auxiliary pairs of the list, see Figure~\ref{listregions.fig} on
page~\pageref{listregions.fig}.

We shall now show three examples of manipulating lists. The first example
traverses a list. Consider the following C function template:
%
\index{traverse_list@\texttt{traverse\_list}}%
%
\begin{scriptcode}
  void traverse_list(uintptr_t* ls) {
    uintptr_t elemML;
    for ( ; isCONS(ls); ls=tl(ls)) {
      elemML = hd(ls);
      /*do something with the element*/
    }
    return;
  }
\end{scriptcode}

The ML list is passed to the C function in parameter \kw{ls}.  The example uses
a simple loop to traverse the list. The parameter \kw{ls} points at the first
constructor in the list. Each time we have a \kw{CONS} constructor we also have
an element, see Figure~\ref{listregions.fig}. The element can be retrieved with
the \kw{hd} macro.  One retrieves the tail of the list by using the \kw{tl}
macro.

The following four macros are provided in the \kw{src/Runtime/List.h} header
file:
%
\index{isNIL@\texttt{isNIL}}%
\index{isCONS@\texttt{isCONS}}%
\index{hd@\texttt{hd}}%
\index{tl@\texttt{tl}}%
%
\begin{scriptcode}
  #define isNIL(x)
  #define isCONS(x)
  #define hd(x)
  #define tl(x)
\end{scriptcode}

The next example explains how to construct a list backwards. Consider the
following C function template:
%
\index{mk_list_backwards@\texttt{mk\_list\_backwards}}%
%
\begin{scriptcode}
  uintptr_t mk_list_backwards(Region pairRho) {
    uintptr_t *resList, *pair;
    makeNIL(resList);
    while (/*more elements*/) {
      ml_elem = ...;
      allocRecordML(pairRho, 2, pair);
      first(pair) = (uintptr_t) ml_elem;
      second(pair) = (uintptr_t) resList;
      makeCONS(pair, resList);
    }
    return (uintptr_t)resList;
  }
\end{scriptcode}
First, we create the \kw{NIL} constructor, which marks the end of the
list. Then, each time we have an element, we allocate a pair. We store the
element in the first cell of the pair. A pointer to the list constructed so far
is put in the second cell of the pair. (In this release of the MLKit, the
\kw{makeCONS} macro simply assigns its second argument the value of its first
argument.) In the example, we have assumed that the elements are unboxed, thus,
no regions are necessary for the elements.

The last example shows how a list can be constructed forwards. It is more clumsy
to construct the list forwards because we have to return a pointer to the first
element. Consider the following C function template.
%
\index{mk_list_forwards@\texttt{mk\_list\_forwards}}%
%
\begin{scriptcode}
  uintptr_t mk_list_forwards(Region pairRho) {
    uintptr_t *pair, *cons, *temp_pair, res;

    /* The first element is special because we have to    */
    /* return a pointer to it.                            */
    ml_elem = ...
    allocRecordML(pairRho, 2, pair);
    first(pair) = (uintptr_t) ml_elem;
    makeCONS(pair, cons);
    res = (uintptr_t) cons;

    while (/*more elements*/) {
      ml_elem = ...
      allocRecordML(pairRho, 2, temp_pair);
      first(temp_pair) = (uintptr_t) ml_elem;
      makeCONS(temp_pair, cons);
      second(pair) = (uintptr_t) cons;
      pair = temp_pair;
    }
    makeNIL(cons);
    second(pair) = (uintptr_t)cons;
    return res;
  }
\end{scriptcode}

We create the \kw{CONS} constructor and pair for the first element and return a
pointer to the \kw{CONS} constructor (the pair) as the result. We then construct
the rest of the list by constructing a \kw{CONS} constructor and a pair for each
element. It is necessary to use a temporary variable for the pair
(\kw{temp\_pair}) because we have to update the pair for the previous
element. The second component of the last pair contains the \kw{NIL} constructor
and thus denotes the end of the list.

The two macros \kw{makeCONS} and \kw{makeNIL} are provided in the \kw{List.h}
header file:
%
\index{makeNIL@\texttt{makeNIL}}%
\index{makeCONS@\texttt{makeCONS}}%
%
\begin{scriptcode}
  #define makeNIL(rAddr, ptr)
  #define makeCONS(rAddr, pair, ptr)
\end{scriptcode}

%=======================================================
\section{Exceptions}
\label{C_exceptions.sec}
%=======================================================
C functions are allowed to raise exceptions and it is possible for the ML code
to handle these exceptions. A C function cannot declare exceptions locally,
however. For technical reasons, we must first acquire an
%
\index{evaluation context}%
%
evaluation context, which can be obtained using the special built-in primitive
\kw{\_\_get\_ctx}:
\begin{smlcode}
  fun getCtx () : foreignptr =
    prim("__get_ctx", ())
\end{smlcode}

\noindent
Now, as an example, consider the following ML declaration:
\begin{smlcode}
  exception Exn
  fun raiseif0 (arg : int) : unit =
    prim("raiseif0", (getCtx(), arg, Exn))
\end{smlcode}
If we want the function \kw{raiseif0} to raise the exception value \kw{Exn} if
the argument (\kw{arg}) is 0 then we use the function \kw{raise\_exn} provided
by the runtime system, by including the header file
\kw{src/Runtime/Exception.h}. The C function \kw{raiseif0} may be defined thus:
\begin{scriptcode}
  void raiseif0(Context ctx, long i_ml, uintptr_t exn) {
    long i_c;
    i_c = convertIntToC(i_ml);
    if (i_c == 0) raise_exn(ctx, exn);
    return;
  }
\end{scriptcode}
Notice that the supplied context is passed to the \kw{raise\_exn} function,
which uses the context to gain access to the region stack and to the current
exception handler.

Notice also that there is no need to make the function \kw{raiseif0} return the
value \kw{mlUNIT}; in case the type of the return value is \kw{unit} then the
MLKit automatically inserts code for returning the ML value \kw{()} after the
call to the C function.

Exceptions are used in examples~\ref{power_exn.ex} and~\ref{dir.ex} in
Section~\ref{Cexamples.sec}.

%=======================================================
\section{Program Points for Profiling}
\label{prof.sec}
%=======================================================
To support profiling, the programmer must provide special profiling versions of
those C functions that allocate space in regions (i.e., that take regions as
additional arguments). If profiling is enabled and at least one pointer to a
region is passed to the C function then also a program point that represents the
call to the C function is passed.  The program point is used by the C function
when allocating space in regions, as explained in Section~\ref{prof.sec}. The
program point is passed as the last argument:
\begin{tabbing}
\indent\=  $\kw{uintptr\_t} \ \emph{c\_funcProf} \ ($\=$\kw{Region}\ \emph{addr}_1,
    \ldots, \kw{Region}\ \emph{addr}_m,$\\
  \>\>$ \kw{uintptr\_t}\ x_1, \ldots,
    \kw{uintptr\_t}\ x_n, \kw{long}\ \emph{pPoint}) $
\end{tabbing}
\noindent
No special version of the C function is needed if it does not allocate into
infinite regions; in this case, the same C function can be used both when
profiling is enabled and disabled.

A program point passed to a C function is an integer; it identifies the
allocation point that represents the C call in the program, see
Chapter~\ref{useOfProf.sec}.

The runtime system provides special versions of various allocation macros and
functions presented earlier in this chapter:
%
\index{allocRealProf@\texttt{allocRealProf}}%
\index{allocRecordMLProf@\texttt{allocRecordMLProf}}%
\index{convertStringToMLProf@\texttt{convertStringToMLProf}}%
%
\begin{scriptcode}
  #define allocRealProf(realRho, realPtr, pPoint)
  #define allocRecordMLProf(rhoRec, ssize, recAddr, pPoint)
  String convertStringToMLProf(Region rhoString,
                               char *cStr,
                               long pPoint);
\end{scriptcode}

Here is the profiling version of the C function \kw{mk\_list\_backwards}:
\begin{scriptcode}
  uintptr_t
  mk_list_backwardsProf(Region pairRho, long pPoint) {
    uintptr_t *resList, *pair;
    makeNIL(resList);
    while (/*more elements*/) {
      ml_elem = ...;
      allocRecordMLProf(pairRho, 2, pair, pPoint);
      first(pair) = (uintptr_t) ml_elem;
      second(pair) = (uintptr_t) resList;
      makeCONS(pair, resList);
    }
    return (uintptr_t) resList;
  }
\end{scriptcode}
The example shows that it is not difficult to make the profiling version of a C
function; use the \kw{Prof} versions of the macros and use the extra argument
\kw{pPoint}, appropriately. The same program point is used for all allocations
in the C function, perceiving the C function as one entity.

%=======================================================
\section{Storage Modes}
%=======================================================
As described in Chapter~\ref{storagemodes.sec} on page~\pageref{atbit.lab},
actual region parameters contain a storage mode at runtime, if the region is
infinite.  A C function may check the storage mode of an infinite region to see
whether it is possible to reset the region before allocating space in it. The
header file \kw{src/Runtime/Region.h} of the runtime system provides a macro
%
\index{is_inf_and_atbot@\texttt{is\_inf\_and\_atbot}}%
%
\kw{is\_inf\_and\_atbot}, which can be used to test whether resetting is safe,
assuming that the arguments to the C function are dead.

The C function \kw{resetRegion}, which is also provided by the runtime system in
the header file \kw{src/Runtime/Region.h}, can be used to reset a
region. Consider again the \kw{mk\_list\_backwards} example. If the $\atbot$ bit
of the region for the list is set, then this region can be reset prior to
constructing the list:
%
\index{resetRegion@\texttt{resetRegion}}%
\begin{scriptcode}
  uintptr_t mk_list_backwards(Region pairRho) {
    uintptr_t *resList, *pair;
    if (is_inf_and_atbot(pairRho)) resetRegion(pairRho);
    makeNIL(resList);
    ...
  }
\end{scriptcode}
The C programmer should be careful not to reset regions that potentially contain
live values. In particular, the C programmer must be conservative and take into
account possible region aliasing between regions holding arguments and regions
holding the result.  Clearly, if a region that the C function is supposed to
return a result in contains part of the value argument(s) of the function, then
the function should not first reset the region and then try to access the
argument(s).

%=======================================================
\section{Endomorphisms by Polymorphism}
\label{C_polymorphism.sec}
%=======================================================
Until now, we have seen examples only of C functions that are region exomorphic,
that is, functions that, in general, write their result into regions that are
different from those in which the arguments reside.

A region endomorphic function has the property that the result of calling the
function is stored in the same regions that hold the arguments to the
function. Region endomorphic functions are useful when the result of the
function shares with parts of the arguments.  Consider the C function
\begin{scriptcode}
  uintptr_t select_second(uintptr_t pair) {
   return second(pair);
  }
\end{scriptcode}
which selects the second component of \kw{pair} (cast to an integer); the
identifier {\tt second} is defined in the header file \kw{Tagging.h} by the
macro definition
\begin{scriptcode}
  #define second(x)  (*((uintptr_t *)(x)+1))
\end{scriptcode}

Now, for the MLKit to make correct, that is safe, decisions about when to
de-allocate regions, the endomorphic properties of a C function must be
expressed in the region-annotated type scheme for value identifiers to which the
C function is bound. The programmer can tell the MLKit about region endomorphic
behavior of a C function by using type variables.  For example, here is an ML
declaration that binds a value identifier \kw{second} to the C function
\kw{select\_second}:\footnote{MLB-file: \boxml{kitdemo/select\_second.mlb}. The
C file \boxml{select\_second.c} must be compiled (using \boxml{gcc}) to form the
object file (archive) \kw{libselect\_second.a} before the project can be
compiled:
%
\kw{mlkit -no\_gc -dirlibs "." -libs "m,dl,c,select\_second" select\_second.mlb}.}%
%
\begin{smlcode}
  fun second(pair : 'a * 'b) : 'b =
    prim("select_second", pair)
\end{smlcode}
The MLKit associates the following region-annotated type scheme to the value
identifier \kw{second}:
$$\forall \alpha_1\alpha_2\rho\epsilon.(\alpha_1 * \alpha_2, \rho)
\ar{\epsilon.\{\Get(\rho_3)\}} \alpha_2$$ Notice that the region-annotated type
scheme expresses the region endomorphic behavior of the C function. That is, for
any substitution $S$, mapping $\alpha_1$ and $\alpha_2$ to region types and
places, the type $S((\alpha_1 * \alpha_2, \rho) \ar{\epsilon.\{\Get(\rho_3)\}}
\alpha_2)$ will express that the result is located in the same regions as (the
second projection) of the argument.


%=======================================================
\section{Compiling and Linking}
\label{comp_and_link_with_C.sec}
%=======================================================
To use a set of C functions in the ML code, one must first compile the C
functions into an object file. (Remember to include appropriate header files.)

As an example, the file \kw{kitdemo/libmylib.c} holds a set of example C
functions. This file is compiled into an archive (in the form of a single object
file) by typing (from the shell)
\begin{scriptcode}
  $ gcc -o libmylib.a -c libmylib.c
\end{scriptcode}
in the \kw{kitdemo} directory. Now, to compile the file to work with profiling,
type
\begin{scriptcode}
  $ gcc -DPROFILING -o libmylib-p.a -c libmylib.c
\end{scriptcode}

The MLB-file \kw{mylib.mlb}, which is listed in Figure~\ref{mylib.mlb.fig},
mentions the file \kw{mylib.sml}, which declares a series of ML functions to be
used in the file \kw{test\_mylib.sml}.
\begin{figure}
\hrule \medskip
\begin{scriptcode}
  $(SML_LIB)/basis/basis.mlb
  mylib.sml
  test_mylib.sml
\end{scriptcode}
\caption{Linking with external object files is done by use of the \kw{prim}
  primitive, which in this case is used in the file \kw{mylib.sml} for declaring
  a series of ML functions.}
\label{mylib.mlb.fig}
\medskip \hrule
\end{figure}

Once the archives have been generated, the appropriate archive can be passed to
the \kw{mlkit} compiler, using the options \kw{-libs} and \kw{-libdirs}, as
follows:
\begin{scriptcode}
  $ mlkit -no_gc -o mylibtest -libdirs "." \
          -libs "m,c,dl,mylib" mylib.mlb
  ...
  $ mlkit -no_gc -prof -o mylibtest-p -libdirs "." \
          -libs "m,c,dl,mylib-p" mylib.mlb
  ...
\end{scriptcode}

\noindent
To learn more about the options \kw{-libs} and \kw{-libdirs}, type
\begin{scriptcode}
  $ mlkit --help
\end{scriptcode}
on the command line.

You may consult the file \kw{kitdemo/Makefile} to see how one can further
automate an appropriate build process.

\section{Dynamic Linking}
\label{link_at_runtime.sec}

The MLKit supports
%
\index{dynamic linking}%
%
dynamic linking at runtime.  This is done using the
%
\index{dlopen!\texttt{dlopen}}%
\index{dlsym!\texttt{dlsym}}%
%
\kw{dlopen} and \kw{dlsym} functions from the MLKit library
\kw{basis/dynlink.mlb}. The function \kw{dlopen} opens a given library and the
function \kw{dlsym} associates a name with a given function in the library. If
the name is already linked, the exception \kw{Fail} is raised.

Using the functions \kw{dlopen} and \kw{dlsym}, as shown in
Figure~\ref{dynlib.fig}, you can call a dynamically linked library function
using a primitive call to '\kw{:}'.

If '\kw{:}' is called with a name that has no association, the exception
\kw{Match} is raised.
\begin{figure}
\hrule \medskip
\begin{smlcode}
  fun isNullFP(s : foreignptr) : bool = prim("__is_null", s)
  val b = Dynlib.dlopen (SOME "libcrack.so", Dynlib.NOW, false)
  val _ = Dynlib.dlsym ("testdyn","FascistCheck",b)
  fun fascistCheck a : string option =
    let val b : foreignptr =
      prim("@:", ("testdyn", a : string,
                  "/usr/lib/cracklib_dict"))
    in if isNullFP b
       then NONE
       else SOME(prim ("fromCtoMLstring", b))
    end
\end{smlcode}
\caption{Dynamic linking of the function \kw{FascistCheck} from the library
  \kw{libcrack.so}.  The ML function \kw{fascistCheck} calls \kw{FascistCheck}
  with the argument \kw{(a,/usr/lib/cracklib\_dict)} and converts the resulting
  C string into an ML string.  This example uses the auto conversion feature as
  described in the next section.}
\label{dynlib.fig}
\medskip \hrule
\end{figure}

%=============================================
\section{Auto Conversion}
\label{auto_conversion.sec}
%=============================================

\index{auto conversion}%
%
For C functions that are simple, in a sense that we shall soon define, the MLKit
can generate code that automatically converts representations of arguments from
ML to C and representations of results from C back to ML.

Auto conversion is enabled by prefixing a \kw{@}-character to the name of the C
function, as in the following example:
\begin{smlcode}
  fun power_auto(base : int, n : int) : int =
    prim ("@power_auto", (base, n))
\end{smlcode}

\noindent
The power function may then be implemented in C as follows:
\begin{scriptcode}
  long power_auto(long base, long n) {
    long p;
    for (p = 1; n > 0; --n) p = p * base;
    return p;
  }
\end{scriptcode}

\noindent
No explicit conversion is needed in the C code. The example shown here is
example~\ref{power_auto.ex} of Section~\ref{Cexamples.sec}; it is part of the
\kw{mylib.mlb} project.

We define the notion of \emph{base type} as one of \kw{int}, \kw{Int8.int},
\kw{Int16.int}, \kw{Int31.int}, \kw{Int32.int}, \kw{Int63.int}, \kw{Int64.int},
\kw{word}, \kw{Word8.word}, \kw{Word16.word}, \kw{Word31.word},
\kw{Word32.word}, \kw{Word63.word}, \kw{Word64.word}, \kw{char}, or \kw{bool}.

Auto conversion works when each of the argument types of the ML function is a
base type or one of \kw{string}, \kw{CharArray.array}, \kw{Word8Vector.vector},
or \kw{Word8Array.array}. The return type of the ML function must be a base type
or the type \kw{unit}.

For the vector and array types, the data pointer is passed as argument to the C
function. The C function may then access and mutate the content of the data but
should not hold on to the data or store the pointer for later use.

Auto conversion works also when profiling is enabled.


%--------------------------------------
\section{Examples\label{Cexamples.sec}}
%--------------------------------------

\index{C examples}%
\index{libmylib.c@\texttt{libmylib.c}}%
\index{mylib.sml@\texttt{mylib.sml}}%
%
Several example C functions are located in the file \kw{kitdemo/libmylib.c}. The
MLB-file \kw{kitdemo/mylib.mlb}, which is listed in Figure~\ref{mylib.mlb.fig},
makes use of these functions.

The source file \kw{mylib.sml}, which is part of the \kw{mylib.mlb} project,
contains the following ML declarations:
\begin{smlcode}
  fun power(base: int, n: int) : int =
    prim ("power", (base, n))

  fun power_auto(base: int, n: int) : int =
    prim ("@power_auto", (base, n))

  fun power_real (base: real, n: int) : real =
    prim ("power_real", (base, n))

  fun print_string_list (ss: string list) : unit =
    prim ("print_string_list", ss)

  exception Power
  fun power_exn (base: real, n: int) : real =
    prim ("power_exn", (getCtx(), base, n, Power))

  exception DIR
  fun dir (directory: string) : string list =
    prim ("dir", (getCtx(), directory, DIR))

  fun real_list () : real list =
    prim ("real_list", ())

  fun change_elem (p : int*string) : string*int =
    prim ("change_elem", p)

  fun strrev (s:string) : unit =
    prim("@strrev_auto", (size s,s))
\end{smlcode}

The C function implementations are summarised below (see the files
\kw{libmylib.c} and \kw{mylib.sml} in the \kw{kitdemo} directory for detailed
comments.)

\begin{example}\label{power.ex}
  The \index{power@\texttt{power}}\kw{power} function shows how to convert
  integers with the macros \kw{convertIntToC} and \kw{convertIntToML}.
\end{example}

\begin{example}\label{power_real.ex}
  The \index{power_real@\texttt{power\_real}}\kw{power\_real} function shows how
  to convert reals with the macros \kw{convertRealToC} and \kw{convertRealToML}.
\end{example}

\begin{example}\label{power_auto.ex}
  The \index{power_auto@\texttt{power\_auto}}\kw{power\_auto} function shows the
  use of auto conversion, which allows for easy linking to certain C functions.
\end{example}

\begin{example}\label{print_string_list.ex}
  The
  \index{print_string_list@\texttt{print\_string\_list}}\kw{print\_string\_list}
  example shows how to traverse a list of strings. The technique can easily be
  adopted to other data structures (e.g., to lists of lists of strings).
\end{example}

\begin{example}\label{power_exn.ex}
  The \index{power_exn@\texttt{power\_exn}}\kw{power\_exn} function shows how an
  exception can be raised from a C function, as explained in
  Section~\ref{C_exceptions.sec}.
\end{example}

\begin{example}\label{dir.ex}
  The \index{dir@\texttt{dir}}\kw{dir} function shows how a list can be
  constructed backwards.  We use the UNIX system calls \kw{opendir} and
  \kw{readdir} to read the contents of the specified directory.

  Notice also that we check the infinite regions for resetting at the
  start of the C function. The checks should be placed at the start of
  the function, orelse not inserted at all.

  If you compare the C functions \kw{dir} and \kw{dirProf} you may see how the
  function \kw{dirProf} is modified to work with profiling.
\end{example}

\begin{example}\label{real_list.ex}
  Function \index{real_list@\texttt{real\_list}}\kw{real\_list} constructs a
  list of reals forwards. The reals are allocated in an infinite region. It may
  be more convenient to construct the list backwards in the C function and then
  apply a list reverse function on the result list in the ML program.
\end{example}

\begin{example}\label{change_elem.ex}
  Function \index{change_elem@\texttt{change\_elem}}\kw{change\_elem} shows the
  use of the macro \kw{elemRecordML}. The result type is \kw{string*int}. The
  function swaps the two elements in the pair. The MLKit passes an address to
  pre-allocated space for the result pair, and an infinite region for the result
  string.

  At first thought it should be enough to just swap the two arguments, and not
  copy the string into the string region, that is, one could write the following
  function:
\begin{scriptcode}
?  uintptr_t
?  change_elem(uintptr_t newPair, Region stringRho, uintptr_t pair) {
?    uintptr_t firstElem_ml, secondElem_ml;
?    firstElem_ml = elemRecordML(pair, 0);
?    secondElem_ml = elemRecordML(pair, 1);
?    elemRecordML(newPair, 0) = secondElem_ml;
?    elemRecordML(newPair, 1) = firstElem_ml;
?    return newPair;
?  }
\end{scriptcode}
  This function may work sometimes but it is not safe! Region inference expects
  the result string to be allocated in \kw{stringRho}, and may therefore
  de-allocate the region containing the argument string, \kw{secondElem\_ml},
  while the string in the returned pair is still live. The safe version of
  \verb|change_elem| is found in \kw{libmylib.c}. See
  Section~\ref{C_polymorphism.sec} for inspiration to how a safe non-copying
  swap function can be implemented.
\end{example}

\begin{example}\label{strrev.ex}
  This example demonstrates the use of auto conversion with strings.  Here is
  the C code for the function \kw{strrev\_auto}, which is referred to by the ML
  function
  %
  \index{strrev@\texttt{strrev}}%
  %
  \kw{strrev}:
\begin{scriptcode}
  void
  strrev_auto(long len, char* data) {
    long n = len / 2;
    for (long i = 0; i < n; i++) {
      char c = data[i];
      data[i] = data[len-i-1];
      data[len-i-1] = c;
    }
    return;
  }
\end{scriptcode}
The function reverses the string characters in-place, which is safe even when
garbage-collection is enabled. Notice that the size of the string is passed
explicitly to the C function as a separate argument. Auto conversion works both
with and without profiling and with and without reference-tracing garbage
collection.
\end{example}

%---------------------------------------------------------
\chapter{Summary of Changes}
%---------------------------------------------------------

\section{Changes Since Version 4.7.2}
\index{changes!since version 4.7.2}%

Here is an overview of the main changes to the MLKit since version 4.7.2.

\subsubsection{Double-Ended Bit-Stealing for Uboxing}

MLKit now uses an advanced unboxing scheme that allows many algebraic data types
to be implemented unboxed using the, otherwise non-used, 16 most-significant
bits of a pointer or the high unused bits of 8-bit word values)
\cite{10.1145/3674628}. The scheme is described in details in
Section~\ref{unboxing.sec}.

\subsubsection{Deep-Argument Flattening}

The MLKit optimiser now attempts to flatten arguments to functions using a
scheme that allows for deep flattening and uncurrying of arguments to functions
(also across compilation unit boundaries) \cite{deep-elsman25}. With this
scheme, if a function takes a tuple of reals and a curried argument of type real
as arguments, those arguments that are not used in their boxed form will be
passed unboxed.

\subsubsection{Support for Threads and Parallelism}

MLKit now supports threads and parallelism through a fork-join thread interface
\cite{10.1145/3591256}. The parallelism features are not described in details in
this report, however.

\subsubsection{Improved Abbreviated Pretty Printing}

Intermediate forms in the MLKit (e.g., $\MulExp$ programs) now benefit from
prettier printing. For example, primitives are now printed using qualified
syntax (e.g., \kw{String.concat}).

\subsubsection{Explicit Programming with Regions and Effects}

The MLKit now supports explicit programming with regions and effects. The
resulting language and compiler is called ReML and it features techniques for
expressing and verifying constraints on regions and effects
\cite{10.1145/3632921}. ReML is not described in this report.

\subsubsection{Improved C FFI Auto Conversion}

The MLKit now has improved support for interaction with C through an enriched
set of supported types, as documented in Section~\ref{auto_conversion.sec}.

\section{Changes Since Version 4.6.1}
\index{changes!since version 4.6.1}%

This section provides an overview of the main changes to the MLKit since version
4.6.1.

\subsubsection*{Simplification of the Region Type System}

To simplify the region type system, region variables are no longer associated
with type variables and the concept of word regions has been eliminated
entirely. Instead of associating type variables with region variables, type
substitutions now map type variables to region type and places.

\subsubsection*{GC Safety Fixed}

A problem with garbage-collection safety was fixed and it is now properly
ensured that no dangling pointers appear during evaluation, which is a necessary
requirement for combining region inference and reference-tracing garbage
collection. Details are described in a conference paper \cite{10.1145/3591229}
and a technical report \cite{gcsafety-revisited-tr-2022}.

\section{Changes Since Version 4.3.0}
\index{changes!since version 4.3.0}%
%
This section provides an overview of the main changes to the MLKit since version
4.3.0.

\subsubsection*{X64 Backend}
The
%
\index{backend!x86}%
%
x86 native backend has been replaced with an
%
\index{backend!x64}%
%
x64 native backend, which uses the GNU assembler to create native machine code
on x86 machines. The new backend also features intra-procedural register
allocation for floating-point values. The MLKit now also features \kw{Int64.int}
as the default integer and \kw{Word64.word} as the default word type
(\kw{Int63.int} and \kw{Word63.word} when garbage collection is enabled).

\subsubsection*{Hosted at Github}
%
\index{Github!repository}%
\index{Repository!Github}%
%
The MLKit is now hosted at Github. The repository is
\begin{quote}
  \url{https://github.com/melsman/mlkit}
\end{quote}
%
\index{bug report}%
\index{Github!issue}%
%
Bug reports should be filed by submitting a Github issue. Features and bug fixes
can be submitted via Github pull requests. Comprehensive tests are executed
using Github actions.

\subsubsection*{JavaScript Backend (SMLtoJs)}
\index{JavaScript!SMLtoJs}%

SMLtoJs is a stand-alone version of the MLKit that compiles to JavaScript and
makes use of MLKit's front-end and compilation infrastructure (e.g.,
recompilation management). It supports large parts of the Standard ML Basis
Library. SMLtoJs does not make use of region-based memory management. SMLtoJs
has been used for hosting a Standard ML compiler in a web browser
\cite{10.1145/2093328.2093336}. To try Standard ML in a browser, visit the site

\begin{quote}
\url{https://diku-dk.github.io/sml-ide/}
\end{quote}

\subsubsection*{Generational Garbage Collection}
\index{garbage collection!generational}%

The non-generational pointer-tracing garbage collection technique has been
augmented with a generational version (option \kw{-gengc}), which in some cases
is superior to ordinary reference-tracing garbage collection, but which may also
cause additional fragmentation \cite{elshaljfp21}.

\subsubsection*{Improved Basis Library Coverage}

The Standard ML Basis library coverage has been extended to support also the
\kw{Unix} structure, socket programming through the
%
\index{socket!programming}%
%
\kw{Socket} structure, the \kw{NetHostDb} structure, and the \kw{INetSock}
structure. With the move to the x64 architecture, the MLKit now also supports
the structures \kw{Word63}, \kw{Word64}, \kw{Int63}, and \kw{Int64}.


\section{Changes Since Version 4}
\index{changes!since version 4}%
%
This section provides an overview of the main changes to the MLKit since version
4, but before version 4.3.0.

\subsubsection*{Support for Compiling ML Basis Files}
\index{ML Basis Files}%
%
ML Basis Files allows for expressing source dependencies, exactly (as a directed
acyclic graph). ML Basis Files thus provides a mechanism for programming ``in
the very large''.

\subsubsection*{File-based Separate Compilation}
\index{separate compilation}%
%
The MLKit now supports file-based separate compilation, based on dependencies
established from ML Basis Files. The compiler serialises symbol table
information to disk for each compilation unit, so that this information can be
deserialised and used when compiling other compilation units.

\subsubsection*{Updated Standard ML Basis Library}
\index{Standard ML!{Basis Library}}%
\index{Basis Library}%
%
The MLKit implementation of the Standard ML Basis Library now conforms to the
specification published in \cite{basislib2004}.

\subsubsection*{Untagged Pairs, Triples and References}
\index{untagging}%
\index{tagging}%
\index{garbage collection}%
\index{value representation}%
%
The MLKit now support untagged representations of heap-allocated pairs, triples,
and Standard ML references, even when garbage collection is enabled.

\section{Changes Since Version 3}
\index{changes!since version 3}%
%
This section provides an overview of the main changes to the MLKit since version
3, but before version 4.

\subsubsection*{Garbage Collection}
\index{garbage collection}%
%
The MLKit supports reference tracing garbage collection in combination with the
region memory model. Garbage collection is supported only in the native backend
version of the MLKit. To enable garbage collection, pass the option \kw{-gc} to
the MLKit compiler. Garbage collection is also possible with region profiling
enabled. See Chapter~\ref{gc.chap} for more information about garbage collection
with the MLKit.

\subsubsection*{X86 Backend}
The
%
\index{backend!hppa}%
%
HPPA backend of the MLKit version 3.0 and earlier has been replaced with an
%
\index{backend!x86}%
%
x86 native backend, which uses the GNU assembler to create native machine code
on x86 machines.

\subsubsection*{Bytecode Backend}
\index{backend!bytecode}%
%
For portability, the MLKit now provides a bytecode backend and a bytecode
interpreter. Which backend is used by the MLKit compiler is determined when the
MLKit itself is compiled, but it is possible to have both a native version and a
bytecode version of the MLKit compiler installed on the same system.

\subsubsection*{Unboxing of Function Arguments}
\index{arguments!multiple}%
\index{multiple function arguments}%
\index{function arguments!multiple}%
%
By default, the MLKit performs a simple local unboxing analysis to figure out if
a function taking a tuple as argument can be transformed into a function taking
multiple arguments. Only functions that use only the individual elements of the
argument tuple undergo transformation. The optimisation can be disabled by
passing the option \kw{-no\_unbox\_function\_arguments} to the MLKit compiler.

\subsubsection*{Removal of Region Vectors}
\index{region vector!removed}%
%
In the MLKit version 3.0 and earlier, actual region parameters were passed to a
region polymorphic function in a {\em region vector}, which itself was allocated
in a region. In version 4.0, actual region parameters to
%
\index{function!region polymorphic}%
%
region polymorphic functions are passed in registers and on the stack.  This
simplification improves pretty printing of region annotated terms and on what
function calls turn into tail calls (see Section~\ref{simplejump.sec}).

\section{Changes Since Version 2}
\index{changes!since version 2}%
%
This section provides an overview of the main changes to the MLKit since version
2.0 but before version 3.0 of the MLKit.

\subsubsection*{Modules and Separate Compilation}
The most important development since Version 2 is the ability to compile Modules
and the discipline of separate compilation. A distinguished feature of the way
modules are compiled is that module constructs do not give rise to any code, so
there is no runtime overhead in using modules
\cite{ElsmanICFP99,ElsmanThesis}. See Chapter~\ref{mlb_and_modules.chap}.

\subsubsection*{Standard ML Basis Library}
The MLKit support a large portion of the
%
\index{Standard ML Basis Library}%
%
Standard ML Basis Library, based on the Moscow ML version of the library. To see
exactly what parts of the Standard ML Basis Library are supported, consult the
MLB-file \kw{basis.mlb} located in the directory \kw{basis}.

\subsubsection*{Scalability}
The MLKit now compiles fairly large programs, including Hafnium's AnnoDomini
(58.000 lines of SML) and the MLKit itself (around 80.000 lines).

\subsubsection*{New Match Compiler}
The pattern compiler has been rewritten, based on Sestoft's
method~\cite{sestoft96}, which is also the basis of the Moscow ML match
compiler.

\subsubsection*{New StatObject Module}
The MLKit contains a module,
%
\index{StatObject}%
%
\kw{StatObject}, which implements the semantic objects of the static semantics
of the Core.  Originally, this was a very clean and very inefficient
implementation of the Definition. In version 2 of the MLKit, \kw{StatObject} was
replaced by an imperative and efficient, but complicated module.  In version 3,
\kw{StatObject} uses a clean, efficient and imperative implementation of
\kw{StatObject}. This is particularly useful for those who want to reuse the
front-end of the MLKit for other purposes.

\subsubsection*{Unboxed Representation of Lists}
\index{list} List constructors are now represented unboxed, that is, the least
significant bits of a list value is used to distinguish between \kw{nil} and a
pointer to a pair (\kw{::}) holding the head and the tail of the list. Thus, a
list takes up only one region (for the auxiliary pairs) plus any regions for the
elements of the list. Consult Chapter~\ref{lists.sec} for details.

\nocite{total97,total94,btv96,elshal95,KochHojfeld96,H96,hallenberg99,brtt93,hosc-regions2004}

\bibliographystyle{alpha}
\bibliography{mlkit}

\appendix

%---------------------------------------------------------
\chapter{Command-Line Options}
\label{mlkithelp.app}
%---------------------------------------------------------
This appendix shows the output of executing
%
\index{help@\texttt{-help} option to \texttt{mlkit}}%
%
\kw{mlkit -help}, where \kw{mlkit} is the version of the MLKit compiler that
uses the
%
\index{backend!x64}%
%
x64 native backend.

\begin{scriptcode}
MLKit v4.7.16 ( - ) [X64 Backend]

Usage: mlkit [OPTION]... [file.sml | file.sig | file.mlb]

Options:

--version, -v, -V
     Print version information and exit.

--help
     Print extended help information and exit.

--help S
     Print help information about an option and exit.

--man
     Print man-page and exit.

--SML_LIB S              (You_did_not_set_path_to_install_dir)
     Installation directory for the MLKit standard library.
     For normal execution you should not modify this value.
     However, if you wish to use the MLKit with an altered
     runtime system you can update this setting and the
     system will try to link to a runtime system found in
     the specified install directory.

--aggressive_opt, -aopt                                   (on)
     Enable aggressive optimisations, including aggressive
     inlining. These optimisations are not guaranteed to be
     region safe. Turning off garbage collection automatically
     turns off this option.

--alloc_protect_always                                   (off)
     Always protect allocation when parallelism is enabled. That
     is, disregard the result of protection inference.

--argobots, -argo                                        (off)
     When enabled, executables link with the Argobots
     lightweight thread library.

--assembler S, -as S                                   (as -q)
     This option specifies the assembler used.
     On Linux the default is 'as --64'. On macOS,
     the default is 'as -q'.

--chat, -verbose                                         (off)
     Print a message for each compilation step in the compiler.

--comments_in_asmcode                                    (off)
     Insert comments in assembler code.

--compile_only, -c                                       (off)
     Compile only. Suppresses generation of executable

--compiler_timings, -timings                             (off)
     Show compiler timings for each compilation phase.

--constant_folding, -cfold                                (on)
     Enable constant folding optimisations.

--contract                                                (on)
     Contract is responsible for inlining, specialization,
     elimination of dead code, and much else (Lambda
     Expression Optimiser).

--contract_regions, -cr                                  (off)
     When this option is enabled, identically typed
     regions bound by the same letregion construct
     are unified. Moreover, region parameters to
     non-exported functions are trimmed whenever
     possible.

--cross_module_opt, -cross_opt                            (on)
     Enable cross-module optimisation including inlining
     of small functions and specialisation of small
     recursive functions. Which optimisations are performed
     across modules is controlled by individual optimisation
     flags.

--dangling_pointers, -dangle                             (off)
     When this option is disabled, dangling pointers
     are avoided by forcing values captured in
     closures to live at-least as long as the closure
     itself. So as to make garbage collection sound,
     this option is disabled by default when garbage
     collection is enabled.

--dangling_pointers_statistics                           (off)
     When enabled, the compiler prints statistics about
     the number of times strengthening of the region typing
     rules (to avoid dangling pointers during evaluation)
     effects the target program. This flag is useful only
     when the flag -gc or -no_dangle is enabled.

--debug_compiler, -debug                                 (off)
     Print intermediate forms of a program during compilation.

--debug_constraint_solving, -dcs                         (off)
     Debug ReML constraint solving.

--debug_linking                                          (off)
     Debug linking of target code by showing which object
     files are linked together.

--debug_man_enrich                                       (off)
     Show information about why a program unit need be
     recompiled. A program unit (or a functor body)
     is recompiled if either (a) the program unit is
     modified, or (b) information about an identifier
     for which the program unit depends upon has changed.

--debug_parallelism, -Dpar                               (off)
     Debug parallelism, including protection inference.

--debug_which_at                                         (off)
     Debug storage mode analysis.

--delete_target_files                                     (on)
     Delete assembler files produced by the compiler. If you
     disable this flag, you can inspect the assembler code
     produced by the compiler.

--disable_atbot_analysis                                 (off)
     Disable storage mode analysis. That is, turn all
     allocation directives into attop.

--disable_flow_var                                       (off)
     Disable optimised compilation of control-flow
     code, such as conditional expressions.

--disable_spurious_type_variables                        (off)
     Disable inference of spurious type variables. This option
     may crash the reference tracing garbage collector as it may
     result in dangling pointers. This flag is relevant only when
     garbage collection is enabled.

--eliminate_explicit_records                              (on)
     Eliminate bindings of explicit records only used for
     selections. Transform
           let r = (e1,...,en) in ... #i r .. #j r ...
     into
           let x1=e1 in ... let xn=en in ... xi .. xj ...
     (Lambda Expression Optimiser).

--extra_gc_checks                                        (off)
     Insert check for GC even in functions that do not
     allocate.

--fix_floating                                            (on)
     Float fix-bindings into immediate let-bindings when
     possible to help tail-calls not be captured in let-
     region bindings.

--garbage_collection, -gc                                 (on)
     Enable garbage collection. When enabled, regions are
     garbage collected during execution of the program. When
     garbage collection is enabled, all values are tagged. Due
     to region inference, for most programs, the garbage
     collector is invoked less often than for systems based
     only on garbage collection. When garbage collection is
     enabled, introduction of dangling pointers are avoided by
     forcing values captured in closures to live at-least as
     long as the closure. Moreover, enabling garbage
     collection implicitly enables the preservation of tail
     calls (see the option ``preserve_tail_calls''.)

--gdb_support, -g                                        (off)
     When enabled, the compiler passes the option --g
     to `as' (The GNU Assembler) and preserves the generated
     assembler files (.s files). Passing the --g
     option to `as' makes it possible to step through
     the generated program using gdb (The GNU Debugger).

--generational_garbage_collection, -gengc                (off)
     Enable generational garbage collection. Same as option
     garbage collection except that two generations are used
     for each region.

--high_pointer_tagging                                    (on)
     When enabled, the 16 most-significant bits in pointers
     may be used for tagging.

--import_basislib, -basislib                              (on)
     Import Basis Library automatically in your projects. If
     you wish to make use of the Standard ML Basis Library
     in your projects, this option should be turned on, unless
     you wish to import the Basis Library manually in your
     projects.

--inline_functors                                        (off)
     Inline functors during static interpretation instead of
     generating separate target code blocks for functor bodies
     and arguments. With the flag enabled, performance may
     increase with the cost of larger (re)compilation times.
     The flag may be controlled in mlb-files using mlb-
     annotations.

--inline_names S
     Names of functions that should always be inlined
     if possible, no matter the setting of the flag
     --maximum_inline_size.

--libdirs S
     This option controls where ld looks for
     archives. The format is a comma-separated list
     of directories; see the -libs entry. The default
     is the empty list; thus 'ld' will look for
     libraries in only the system specific default
     directores. The directories are passed to 'ld'
     using the -L option.

--libs S                                              (m,c,dl)
     For accessing a foreign function residing in
     an archive named libNAME.a from Standard ML code
     (using prim), you need to add 'NAME' to this
     comma-separated list. Notice that an object file
     (with extension '.o') is an archive if it is
     renamed to have extension '.a'. You may need to
     use the -libdirs option for specifying
     directories for which ld should look for library
     archives. The libraries are passed to 'ld' using
     the -l option.

--link_code S
     Link-files to be linked together to form an
     executable.

--link_exe S, -ldexe S (gcc -Wl,-ld_classic,-stack_size,0x10000000)
     This option specifies the command used for linking
     an executable. The standard is to use 'gcc' for
     linking. When linking with c++ libraries, 'g++' is
     the linker you want. On Linux the default is 'gcc',
     whereas on newer macOS systems (Darwin > 23.1), the default
     is 'gcc -Wl,-ld_classic,-stack_size,0x10000000' and on
     older macOS systems, the default is
     'gcc -Wl,-stack_size,0x10000000'.

--link_shared S, -ldshared S                             (gcc)
     This option specifies the command used for linking
     a shared object file. The standard is to use 'gcc' for
     linking.

--link_time_dead_code_elimination, -ltdce                 (on)
     Link time dead code elimination.

--load_basis_files S, -load S
     Basis files to be loaded before compilation
     proper.

--log_to_file                                            (off)
     Log to files instead of stdout.

--maximum_inline_size N, -max_inl_sz N                   (200)
     Functions smaller than this size (counted in abstract
     syntax tree nodes) are inlined, even if they are used
     more than once. Functions that are used only once are
     always inlined. A function declared in one program unit
     may be inlined when applied in another program unit
     provided the function is sufficiently closed (refers only
     to exported identifiers) and provided the option
     --cross_opt is enabled.

--maximum_specialise_size N, -max_spec_sz N              (200)
     Function-parameterised functions smaller than this size
     (counted in abstract syntax tree nodes) are specialised if
     all applications of the function within its own body are
     applied to its formal function argument, even if they are used
     more than once. Functions that are used only once are
     specialised no matter their size. A function declared in
     one program unit may be specialised when applied in
     another program unit provided the function is sufficiently
     closed (refers only to exported identifiers) and provided
     the option --cross_opt is enabled. See also the option
     --specialize_recursive_functions.

--messages                                                (on)
     Print messages about reading source files and generating
     target files.

--minimize_fixs                                           (on)
     Minimize fix constructs (Lambda Expression Optimiser).

--mlb-subdir S
     For ensuring that the smart recompilation scheme
     is not reusing target-code compiled with different
     settings, a string provided with the mlb-subdir
     option can ensure the use of consistently generated
     code. This option is Useful, in particular, when
     performing benchmarking.

--mlb_path_maps S, -mlb-path-map S
     ML Basis path map files to be used.

--namebase S                                       (dummyBase)
     Name base to enforce unique names when compiling
     mlb-files.

--no_aggressive_opt, -no_aopt
     Opposite of --aggressive_opt, -aopt.

--no_constant_folding, -no_cfold
     Opposite of --constant_folding, -cfold.

--no_contract
     Opposite of --contract.

--no_cross_module_opt, -no_cross_opt
     Opposite of --cross_module_opt, -cross_opt.

--no_dangling_pointers, -no_dangle
     Opposite of --dangling_pointers, -dangle.

--no_delete_target_files
     Opposite of --delete_target_files.

--no_eliminate_explicit_records
     Opposite of --eliminate_explicit_records.

--no_fix_floating
     Opposite of --fix_floating.

--no_garbage_collection, -no_gc
     Opposite of --garbage_collection, -gc.

--no_generational_garbage_collection, -no_gengc
     Opposite of --generational_garbage_collection, -gengc.

--no_high_pointer_tagging
     Opposite of --high_pointer_tagging.

--no_import_basislib, -no_basislib
     Opposite of --import_basislib, -basislib.

--no_link_time_dead_code_elimination, -no_ltdce
     Opposite of --link_time_dead_code_elimination, -ltdce.

--no_messages
     Opposite of --messages.

--no_minimize_fixs
     Opposite of --minimize_fixs.

--no_optimiser, -no_opt
     Opposite of --optimiser, -opt.

--no_preserve_tail_calls, -no_ptc
     Opposite of --preserve_tail_calls, -ptc.

--no_print_control_abbrev_layout, -no_abbrev
     Opposite of --print_control_abbrev_layout, -abbrev.

--no_print_regions, -no_Pregions
     Opposite of --print_regions, -Pregions.

--no_raggedRight
     Opposite of --raggedRight.

--no_region_inference, -no_ri
     Opposite of --region_inference, -ri.

--no_register_allocation
     Opposite of --register_allocation.

--no_repository, -no_rep
     Opposite of --repository, -rep.

--no_specialize_recursive_functions
     Opposite of --specialize_recursive_functions.

--no_type_check_lambda
     Opposite of --type_check_lambda.

--no_unbox_funargs
     Opposite of --unbox_funargs.

--no_unbox_real_funargs
     Opposite of --unbox_real_funargs.

--no_unbox_reals
     Opposite of --unbox_reals.

--no_uncurrying, -no_uncurry
     Opposite of --uncurrying, -uncurry.

--objs                                                   (off)
     If enabled, MLKit writes object-file paths to the file
     run or the file specified by -output. The path
     to the runtime system (archive file) is included. The
     option is best used together with the option
     -no_delete_target_files.

--optimiser, -opt                                         (on)
     Enable optimisation of intermediate language code
     (Lambda Expressions). Which optimisations are performed
     is controlled by individual flags. The optimisations
     include function inlining, function specialisation,
     fix-minimization, unboxing of function arguments, and
     elimination of unnecessary record constructions.

--output S, -o S                                         (run)
     The name of the executable file generated by
     the Kit.

--parallel_compilation N, -j N                             (1)
     The maximum number of parallel processes used
     for compilation.

--parallelism, -par                                      (off)
     When enabled, the runtime system supports
     parallel threads.

--parallelism_alloc_unprotected, -par0                   (off)
     When enabled, allocation into a region is not
     guaranteed to be atomic.

--preserve_tail_calls, -ptc                               (on)
     Avoid the wrapping of letregion constructs around
     tail calls. Turning on garbage collection
     automatically turns on this option.

--pretty_depth N                                           (5)
     This flag controls the pretty-printing depth of
     values printed in the REPL. The value must be an
     integer larger than zero.

--pretty_string_size N                                    (80)
     This flag controls the pretty-printing size of
     strings printed in the REPL. The value must be an
     integer larger than zero.

--print_K_normal_forms                                   (off)
     Print Region Expressions in K-Normal Form. Applicable,
     only after storage mode analysis has been applied.

--print_all_program_points, -Ppp                         (off)
     Print all program points when printing physical size
     inference expressions.

--print_bit_vectors                                      (off)

--print_calc_offset_program                              (off)

--print_call_explicit_expression, -Pcee                  (off)
     Print Region Expression with call annotations.

--print_clos_conv_program, -Pccp                         (off)
     Print Region Expression after closure conversion.

--print_closed_export_bases, -Pceb                       (off)
     Controls printing of closed export bases.

--print_constraints                                      (off)
     Print ReML effect constraints when printing region and
     effect variables.

--print_control_abbrev_layout, -abbrev                    (on)
     Abbreviate layout of multiplicity expressions and call-
     explicit expressions. For instance, do not show at-
     annotations for top-level functions, do not show at-
     annotations for immediate constants, do not show region-
     bindings for zero-size regions that are associated only
     with immediate constants, do not show empty formal and
     actual region parameter lists, do not show 'funcall' and
     'fncall' annotations, do not show 'id' casts on base values,
     do not show unique id for explicit region variables or
     explicit effect variables.

--print_control_prefix_infix                             (off)
     Prefix infix operations with module identifier to further
     indicate the type of the operation.

--print_drop_regions_expression, -Pdre                   (off)
     Print Region Expression after dropping word regions and
     region arguments with only get-effects.

--print_drop_regions_expression_with_storage_modes, -Pdresm (off)
     Print Region Expression after dropping word regions and
     region arguments with only get-effects. Also print
     atbot and attop annotations resulting from storage mode
     analysis.

--print_effects, -Peffects                               (off)
     Print effects in region types.

--print_excon_name                                       (off)
     Print underlying unique name when printing excons.

--print_export_bases, -Peb                               (off)
     Controls printing of export bases.

--print_fetch_and_flush_program                          (off)
     Print program with instructions for activation
     record fetching and flushing.

--print_linearised_program                               (off)
     Print a linearlised representation of the
     program unit.

--print_lvar_name                                        (off)
     Print underlying unique name when printing lvars.

--print_normalized_program                               (off)
     Print Region Expression after K-normalisation.

--print_opt_lambda_expression, -Pole                     (off)
     Print Lambda Expression after optimisation.

--print_physical_size_inference_expression, -Ppse        (off)
     Print Region Expression after physical size inference.

--print_post_elab_ast, -Ppeast                           (off)
     Print ast after elaboration.

--print_region_flow_graph, -Prfg                         (off)
     Print a region flow graph for the program fragment
     and generate a .vcg-file, which can be viewed using
     the xvcg program.

--print_region_inferred_program, -Prip                   (off)
     Print region-inferred program.

--print_region_spreaded_program, -Prsp                   (off)
     Print region-spreaded program.

--print_region_static_env0, -Prse0                       (off)
     Print imported region static environment prior to
     region inference.

--print_regions, -Pregions                                (on)
     Print region variables in types and expressions.

--print_register_allocated_program                       (off)

--print_rho_levels                                       (off)
     Print levels of region and effect variables in types and
     intermediate forms. Levels control quantification of
     region and effect variables.

--print_rho_protection, -Prho_protection                 (off)
     Print protectedness of region variables if set (P or U).

--print_rho_types                                        (off)
     Print region types of region variables in types and
     intermediate forms. Possible region types are:
         p  Type of regions containing pairs.
         a  Type of regions containing arrays.
         r  Type of regions containing references.
         t  Type of regions containing triples.
         s  Type of regions containing strings.
         T  Type of regions containing other than the above
            kinds of values.

--print_simplified_program                               (off)
     Print simplified program after register
     allocation.

--print_storage_mode_expression, -Psme                   (off)
     Print Region Expression after storage mode analysis

--print_type_name_stamps, -Ptypestamps                   (off)
     Print type name stamps and their attributes in types
     and expressions.

--print_types, -Ptypes                                   (off)
     Print types when printing intermediate forms. For Lambda
     Expressions, ordinary ML types are printed, whereas for
     Region Expressions, region types are printed.

--quotation, -quot                                       (off)
     Enable support for quotations and anti-quotations.
     When enabled, the datatype
        datatype 'a frag = QUOTE of string
                         | ANTIQUOTE 'a
     is available in the initial environment. Moreover,
     values of this datatype may be constructed using
     the quotation/antiquotation syntax:
        val s = "world"
        val a : string frag list = `hello ^s - goodbye`

--raggedRight                                             (on)
     Use ragged right margin in pretty-printing of
     expressions and types.

--recompile_basislib, -scratch                           (off)
     Recompile basis library from scratch. This option
     is useful together with other options that control
     code generation.

--region_inference, -ri                                   (on)
     With this flag disabled, all values are allocated in
     global regions.

--region_profiling, -prof                                (off)
     Enable region profiling. Object code stemming
     from compiling a program with region profiling enabled
     is instrumented with profiling information. When a program
     compiled with region profiling enabled is run, the program
     produces a profile file run.rp, which can then be read
     by the profiling tool rp2ps that comes with the MLKit to
     produce profiling graphs of various forms.

--regionvar N                                             (~1)
     Uses the provided number as the id of the first
     generated region variable. When this option is
     provided together with the -c option, a file f.rv
     is written in the MLB/ directory with two numbers
     in it: the id for the first region variable
     generated and the id for the last region variable
     generated. The number given must be greater than
     any id for a top-level region/effect variable (>9).

--register_allocation                                     (on)
     Perform register allocation. Without register allocation
     enabled, programs run somewhat slower--but they run and
     you save about 15 percent on compile time.

--reml                                                   (off)
     ReML is Standard ML with support for programming with
     explicit regions, explicit effects, and effect
     constraints. With ReML, atomic effects also include
     mutation effects. Whereas ReML includes parallel
     thread support, currently, ReML does not support
     integration with reference-tracing garbage collection.

--report_boxities                                        (off)
     Report for every datatype declaration the inferred boxity
     (representation) of its value constructors.

--report_file_sig, -sig                                  (off)
     Report signatures for each file read.

--repository, -rep                                        (on)
     Use in-memory repository to avoid unnecessary
     recompilation. This flag should be disabled when
     compiling mlb-files, which make use of the file system
     as a repository.

--safeLinkTimeElimination                                (off)
     Treat this module as a library in the sense that
     the code can be eliminated if it is not used,
     even if the code has side effects.

--specialize_recursive_functions                          (on)
     Specialise recursive functions. Use the option
     maximum_specialise_size to control which functions
     are specialised. If this flag is on, functions that are
     applied only once are specialised, no matter the setting
     of --maximum_specialise_size (Lambda Expression Optimiser).

--statistics_after_optimisation, -stats_opt              (off)
     Report optimisation statistics after optimisation of
     Lambda Expression.

--statistics_spurious, -stats_spurious                   (off)
     Report statistics on spurious functions and instantiations
     of spurious type variable. This flag is relevant only when
     garbage collection is enabled.

--strip                                                  (off)
     If enabled, MLKit strips the generated executable.

--tag_pairs                                              (off)
     Use a tagged representation of pairs for garbage
     collection. Garbage collection works fine with a
     tag-free representation of pairs, so this option
     is here for measurement purposes.

--tag_values, -tag                                        (on)
     Enable tagging of values as used when garbage
     collection is enabled for implementing pointer
     traversal.

--type_check_lambda                                       (on)
     Type check lambda expression prior to performing region
     inference. Type checking is very fast and for normal use
     you should not disable this option. Type checking
     intermediate forms is very powerful for eliminating bugs
     in the compiler.

--unbox_funargs                                           (on)
     Unbox arguments to fix-bound functions, for which the
     argument 'a' is used only in contexts '#i a'. All call
     sites are transformed to match the new function (Lambda
     Expression Optimiser).

--unbox_real_funargs                                      (on)
     Unbox arguments of type real to fix-bound functions, for which
     the argument 'a' is used only in contexts that unboxes 'a'. All
     call sites are transformed to match the new function. This
     optimisation has effect only when the flags '-unbox_funargs' and
     '-unbox_reals' are enabled (Lambda Expression Optimiser).

--unbox_reals                                             (on)
     Unbox real values and computations on real values inside
     functions. Real values stored in data structures and
     passed to functions are still boxed.

--uncurrying, -uncurry                                    (on)
     Enable uncurrying of curried functions. The uncurried
     function takes its arguments unboxed in registers or
     on the stack. For partial applications and non-
     application uses of the function, appropriate eta-
     expansions are applied.

--values_64bit                                            (on)
     Support 64-bit values. Should be enabled for
     backends supporting 64-bit integers and words.

--warn_on_escaping_puts                                  (off)
     Enable the compiler to issue a warning whenever a
     region type scheme contains a put effect on a region
     that is not quantified.

--warn_on_parallel_puts                                  (off)
     Enable the compiler to issue a warning whenever a
     par-construct is passed functions with intersecting
     put effects.

--warn_spurious                                          (off)
     Warn on the presence of a spurious type variable. This
     flag is relevant only when garbage collection is enabled.

--width N, -w N                                          (100)
     Column width used when pretty printing intermediate code.
\end{scriptcode}

\newpage
\index{live variable analysis|see{variable}}
\index{endomorphism|see{region endomorphism}}
\index{exomorphism|see{region exomorphism}}
\index{tuple|see{record}}
\index{$\mu$|see{type and place}}
\index{rDesc|see{region descriptor}}
\index{example programs|see{{\tt kitdemo} directory}}
\index{value declaration|see{declaration}}
\printindex

\newpage
\begin{center}
\bf Global Regions
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
\boxml{r1}&Holds values of type {\tt top}, including records, exceptions, reals, and closures.\cr
\boxml{r2}&Holds values of type {\tt bot}. Because no values has type
{\tt bot}, this region contains no values. Region variables with region type {\tt bot} are used with
so-called explicit regions, which are not covered in this report.\cr
\boxml{r3}&Holds values of type {\tt string}.\cr
\boxml{r4}&Holds values of type $\tau_1 \times \tau_2$, for any types $\tau_1$ and $\tau_2$.\cr
\boxml{r5}&Holds values of type $\tau~\kw{array}$ and $\tau~\kw{vector}$, for any type $\tau$.\cr
\boxml{r6}&Holds values of type $\tau~\kw{ref}$, for any type $\tau$.\cr
\boxml{r7}&Holds values of $\tau_1 \times \tau_2 \times \tau_3$, for any types $\tau_1$, $\tau_2$, and $\tau_3$.\cr
}
\hrule
\bigskip
\end{document}
